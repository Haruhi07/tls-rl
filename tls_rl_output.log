 
 University of Bristol ACRC HPC Bluepebble Service
 -------------------------------------------------
 Job tls_rl, jobid 3600107.bp1, username hs20307 - started execution at 22:51:35 Tue 31/08/21 on node bp1-gpu00017.data.bp.acrc.priv
 
adding bpoil_bbc into dataset...
topic:  ('bpoil_bbc',)
env initialized...

Before training:  23.2% (2552 out of 11019)
{'input_ids': tensor([[[  110,   105,  3893, 15737,  1034,  8255,   464, 16036,   134,   109,
           1816,  2447,   139,  1816,  2447,   649,   126,   117,  4562,   112,
          16036,   118,   203,   337,   983,   762,   121,  2134,  5626,   148,
            174, 12832,   279,   156,   113,   109,  1816,  2447,  1034,   116,
          18072,   141, 10162, 18232,   126,   112,   370,   203, 10971,   818,
            122, 16036,   110,   107,   139,  4635, 41588,   110,   108, 50595,
          81452, 60490,   457,   131,   304,   110,   108,   117,   114,  4055,
          17225,   113,   114,   883,   693,   111, 28286,   111,   117,   160,
           6155,   231,   459,   110,   107,   202,   456,   568,  7200,  9221,
           3893,  2777,   165,   109,  8255,   110,   107,   202,   984,  8255,
           4635, 20678,  4329,   115,  1185,   110,   107,   139,  1816,  2447,
            243,   109,  5626,  1065,   140, 39059,   110,   108,   162,   196,
            146,  3954,   109,  4976,  2098, 11976,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 23.2% (2552 out of 11019)

Everytime after generating next logits 24.7% (2718 out of 11019)

Everytime after generating next logits 24.7% (2720 out of 11019)

Everytime after generating next logits 24.7% (2720 out of 11019)

Everytime after generating next logits 24.7% (2720 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 24.9% (2740 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.0% (2760 out of 11019)

Everytime after generating next logits 25.2% (2772 out of 11019)

Everytime after generating next logits 25.3% (2784 out of 11019)

Everytime after generating next logits 25.3% (2784 out of 11019)

Everytime after generating next logits 25.3% (2784 out of 11019)

Everytime after generating next logits 25.3% (2784 out of 11019)
Haka Hoa Hoa Hoa Hoa Haka Haka Haka called a giant protest to the British Culture . Campaigners called the British Island sponsorship to the British Culture .
iter = 0 reward = 5
final_logits =  tensor([[[ 0.0000,  3.6580,  0.5854,  ..., -2.1995,  1.3356, -2.8146],
         [ 0.0000,  4.4621, -0.0904,  ..., -1.8895, -0.5902, -2.9494],
         [ 0.0000,  4.6797, -0.1028,  ..., -2.3253, -0.9177, -3.1843],
         ...,
         [ 0.0000,  4.3877, -0.3404,  ..., -3.4207,  0.0982, -1.2656],
         [ 0.0000,  3.3689,  0.0333,  ..., -1.4281,  0.0344,  0.0885],
         [ 0.0000, 11.5623,  0.1148,  ..., -1.7734,  0.8034, -0.4692]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.2476, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.3572, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)
Protesters called British Culture sponsorship to the British Island . An protest called the British Culture is called a June Hoa Hoa Hoa Hoa Hoa . sponsorship .
iter = 1 reward = 7
final_logits =  tensor([[[-0.0745,  4.7459,  0.9539,  ..., -4.9281,  3.5069, -0.2545],
         [-0.0642,  4.5611,  1.4266,  ..., -4.9390,  2.5325,  1.4437],
         [-0.0475,  3.3850, -0.3299,  ..., -3.7128, -1.2755, -2.9817],
         ...,
         [-0.0644,  4.5319, -0.5044,  ..., -1.4425,  1.2362, -2.3293],
         [-0.0337,  4.9759, -0.0904,  ..., -1.1775, -0.0188, -0.7818],
         [-0.0672, 11.9875, -0.3577,  ..., -1.0601,  1.7198, -2.9056]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-360.5794, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(151673.9844, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.7% (4262 out of 11019)

Everytime after generating next logits 38.7% (4262 out of 11019)

Everytime after generating next logits 38.7% (4262 out of 11019)

Everytime after generating next logits 38.7% (4262 out of 11019)

Everytime after generating next logits 38.7% (4262 out of 11019)

Everytime after generating next logits 38.8% (4276 out of 11019)

Everytime after generating next logits 38.8% (4276 out of 11019)

Everytime after generating next logits 38.8% (4276 out of 11019)
The giant protest called a June protest called a June protest called a June protest called a June protest . A statue at the British Museum has been damaged with the substance .
iter = 2 reward = 10
final_logits =  tensor([[[-5.6745e-03,  5.2606e+00,  8.5718e-01,  ..., -3.5220e+00,
           1.5634e+00, -3.5128e-01],
         [-7.4260e-03,  3.2613e+00,  5.5446e-01,  ..., -6.0384e+00,
           2.0101e+00, -2.0712e+00],
         [ 2.1273e-03,  3.0145e+00,  1.3998e-01,  ..., -2.8252e+00,
           2.6224e+00, -2.0180e+00],
         ...,
         [-8.0497e-03,  3.6743e+00, -6.8382e-01,  ..., -2.3853e+00,
          -9.1154e-01, -9.0119e-01],
         [-7.4435e-03,  4.0813e+00, -5.5675e-02,  ..., -1.6203e+00,
           1.5520e-02, -4.5227e-01],
         [-8.2173e-03,  1.1980e+01, -3.3794e-01,  ..., -2.9658e+00,
          -1.3856e+00, -2.0495e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-21.3678, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(874.0716, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.9% (4284 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)
Hoa Hoa Haka sponsorship targeted by giant June sponsorship targeted . Oil activists called a protest called Britain's Oil Island . Oil is a 'like substance' and it is a 'like substance'
iter = 3 reward = 6
final_logits =  tensor([[[ 4.8118e-02,  3.8405e+00,  8.3098e-01,  ..., -3.1077e+00,
           1.2671e+00, -3.8738e-01],
         [ 3.2884e-02,  4.8909e+00,  7.3792e-02,  ..., -1.8813e+00,
          -4.9659e-01, -2.2627e+00],
         [ 3.4840e-02,  3.7354e+00,  1.3864e-02,  ..., -1.9285e+00,
           1.1502e-01, -2.5266e+00],
         ...,
         [ 1.8367e-02,  4.8586e+00, -8.4008e-02,  ..., -1.7634e+00,
           9.6542e-01, -4.7962e-01],
         [ 9.5386e-03,  4.2092e+00, -5.5276e-01,  ..., -2.1833e+00,
          -3.4724e-01, -7.2097e-01],
         [ 2.5875e-02,  1.0743e+01, -7.9500e-01,  ..., -3.8311e+00,
          -6.7479e-01, -2.9762e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(37.1422, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1173.2699, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.7% (4266 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)
Hoa Hoa Haka sponsorship targeted by giant June sponsorship targeted by a giant June sponsorship targeted . Oil is a 'like substance' and is a 'nana' substance, which is a human relic .
iter = 4 reward = 3
final_logits =  tensor([[[ 8.0982e-02,  2.7158e+00,  8.0174e-01,  ..., -4.2613e+00,
           9.0663e-01, -9.7041e-01],
         [ 6.0645e-02,  4.7493e+00,  7.4678e-02,  ..., -2.3224e+00,
          -1.7329e-01, -2.3686e+00],
         [ 6.2741e-02,  3.4236e+00,  1.0969e-02,  ..., -2.2154e+00,
           1.3008e-01, -2.7089e+00],
         ...,
         [ 2.2830e-02,  3.3688e+00, -7.0451e-01,  ..., -2.9260e+00,
          -4.7860e-01, -1.8003e+00],
         [ 2.2123e-02,  3.4194e+00, -1.3538e-01,  ..., -1.2025e+00,
           2.2558e-01,  1.6547e-01],
         [ 4.4591e-02,  1.1038e+01, -2.8300e-01,  ..., -3.1389e+00,
          -1.3870e-01, -9.8270e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(39.3730, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1022.9466, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  3
3
{'input_ids': tensor([[[ 4123,   113,   219,  6234,   195,  6908,   115,   109, 75158,  1153,
           3893,  1419, 16036,   148,  6305,  3906,   142, 10580,   805,   113,
            203,  7175,   113,  3064,   762, 14567,  1407,  1104,   124,   203,
            387,   110,   107,   139,  1082,   110,   108,  1155,   204,   109,
           1339,   110,   108,   939,  1841,   115,   683,   113,   114,  1679,
            113,   461,  6234, 10361,  1055,   113,   203,  3954,   210,   124,
            109,  1917,  1030,   110,   107, 16036,  9619,  3582,  7217,   243,
            120,   339,  6234,   195,  6908,   115,   109,   856,  1153,   111,
          10390,   680,   196,   174,   263,   112,   535,  1055,   110,   107,
            139, 10580,   805,   140,  3530,   122,   109,   856,   244,   114,
            787,  9024,  8666,   126,   110,   107,  1263,  7217,   243,   109,
           4787,   170,   635,   109,  1153,   140, 10361,   169,   766,   122,
          10390,   680,   111,   186,   140,   220,  5313,  6596,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)
Dean Dean spotted three Photoshop workers have replaced a blank blank photo with three Photoshop workers .
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0402,  4.6382,  0.5702,  ..., -4.0275, -1.0112,  2.6190],
         [ 0.0445,  3.8803, -0.0160,  ..., -3.9832, -1.3409,  0.3361],
         [ 0.0411,  3.1036, -0.0953,  ..., -3.0560, -2.4735,  0.6750],
         ...,
         [ 0.0433,  4.6963, -0.4061,  ..., -1.0868, -0.7131,  0.0741],
         [ 0.0345,  4.4248, -0.0728,  ..., -0.3890, -0.3482,  0.1883],
         [ 0.0345, 13.2365,  0.0554,  ..., -1.7850, -1.9739,  1.7287]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(8.6377, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(97.0173, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)
Dean Dean spotted three Photoshop workers replaced three Photoshop workers .
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0449,  4.7321,  0.5447,  ..., -3.8002, -0.5982,  2.2830],
         [ 0.0538,  4.3284, -0.0510,  ..., -4.7039, -2.0612, -0.0597],
         [ 0.0481,  3.5701, -0.1516,  ..., -3.2568, -2.6665, -0.2371],
         ...,
         [ 0.0579,  4.5719, -0.3402,  ..., -0.7065, -0.7123, -0.7795],
         [ 0.0443,  4.0428,  0.2927,  ..., -1.0202, -0.6102,  0.3993],
         [ 0.0374, 12.5456,  0.1071,  ..., -1.4966, -1.6577,  0.9351]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7794, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.3527, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)
Dean Dean posted a blank picture of a blank picture on the site of the Gulf oil spill .
iter = 2 reward = 3
final_logits =  tensor([[[ 5.8242e-02,  4.1856e+00,  6.7079e-01,  ..., -3.3023e+00,
           2.9050e-01,  2.4968e+00],
         [ 5.3798e-02,  3.8927e+00, -1.0885e-01,  ..., -4.6205e+00,
          -2.7486e+00, -1.6142e-03],
         [ 4.7556e-02,  3.3613e+00, -2.5819e-01,  ..., -3.6017e+00,
          -3.0880e+00, -5.3762e-01],
         ...,
         [ 6.4930e-02,  4.8348e+00, -7.8564e-01,  ..., -2.9602e+00,
          -2.0345e+00, -6.3453e-01],
         [ 4.6509e-02,  4.0900e+00, -1.9415e-01,  ..., -9.7514e-01,
          -1.0197e+00,  2.4958e-02],
         [ 4.9018e-02,  1.3507e+01,  7.8772e-02,  ..., -1.7568e+00,
          -1.2928e+00,  7.8295e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4375, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.8422, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)
Three Photoshop workers replaced big Photoshop workers .
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0611,  4.1746,  0.7247,  ..., -2.7006,  0.3769,  2.3548],
         [ 0.0345,  3.3717,  0.6217,  ..., -4.0109,  0.2353, -2.0702],
         [ 0.0295,  3.3999,  0.4788,  ..., -4.2577, -1.1336, -0.6634],
         ...,
         [ 0.0746,  4.8869, -0.2505,  ..., -0.7784, -0.6589, -0.6119],
         [ 0.0492,  5.4112,  0.9799,  ..., -1.0579, -0.5780,  0.6528],
         [ 0.0578, 12.9505,  0.1305,  ..., -2.3718, -0.5086,  0.3667]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.0541, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(33.3099, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
Three Photoshop workers altered Photoshop workers have been spotted altered Photoshop workers .
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0651,  4.2060,  0.7459,  ..., -2.9154, -0.0342,  2.1147],
         [ 0.0348,  3.6425,  0.5784,  ..., -4.0239, -0.1813, -2.2581],
         [ 0.0340,  3.5461,  0.4615,  ..., -3.9763, -0.9764, -1.0598],
         ...,
         [ 0.0785,  9.4023, -0.4136,  ..., -1.2075, -0.7947, -0.9910],
         [ 0.0628,  8.4663,  0.1371,  ..., -0.6225, -1.2169,  0.1215],
         [ 0.0601, 13.5901, -0.0196,  ..., -2.2942, -0.9086, -0.0782]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.0879, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.3607, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[599, 960, 110,  ..., 109, 804,   1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.3% (4218 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 40.0% (4410 out of 11019)

Everytime after generating next logits 40.0% (4410 out of 11019)

Everytime after generating next logits 40.0% (4410 out of 11019)

Everytime after generating next logits 40.0% (4410 out of 11019)

Everytime after generating next logits 40.0% (4410 out of 11019)
Ad Kent Kent installs a giant giant giant giant .
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0639,  1.2223,  0.8880,  ..., -4.0502,  1.6779,  1.6469],
         [ 0.0683,  3.8403,  0.6756,  ..., -0.8760, -1.9744,  0.4337],
         [ 0.0568,  2.7789,  0.2952,  ..., -4.0672, -1.0475, -1.4580],
         ...,
         [ 0.0843,  4.7089,  0.0461,  ..., -2.5611, -0.8893, -0.3435],
         [ 0.0644,  7.7554,  0.9180,  ..., -3.0721, -0.6891,  2.6359],
         [ 0.0537, 12.5306, -0.1193,  ..., -1.0213, -0.5154,  0.3169]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2387, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.3859, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4242 out of 11019)

Everytime after generating next logits 39.1% (4306 out of 11019)

Everytime after generating next logits 39.1% (4306 out of 11019)

Everytime after generating next logits 39.1% (4306 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)

Everytime after generating next logits 39.7% (4370 out of 11019)
Ad Kent Kent Kent installs a new oil giant oil giant .
iter = 1 reward = 3
final_logits =  tensor([[[ 0.0674,  1.4026,  0.8250,  ..., -3.9397,  1.0080,  1.8467],
         [ 0.0675,  3.7244,  0.5141,  ..., -1.0067, -1.6368, -0.6987],
         [ 0.0659,  4.3796,  0.1922,  ..., -3.6690, -2.1132, -1.9995],
         ...,
         [ 0.1095,  6.0148, -0.3124,  ..., -3.0796, -0.7485, -1.2058],
         [ 0.0884, 10.9122,  0.3469,  ..., -2.5821, -0.6877,  1.7086],
         [ 0.0623, 13.0003, -0.0482,  ..., -0.9931, -0.4505,  0.1101]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9467, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.4282, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4266 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)
BP has been told to stop the cap to the flow of the oil spill .
iter = 2 reward = 5
final_logits =  tensor([[[ 0.0764,  1.0477,  0.9359,  ..., -3.1521,  0.1453,  2.7774],
         [ 0.0950,  2.3831, -0.3363,  ..., -0.6811, -2.0133, -2.2083],
         [ 0.0790,  1.6207,  0.1153,  ...,  0.3343, -0.9495, -0.4695],
         ...,
         [ 0.0863,  6.9933, -0.9001,  ..., -0.9885, -0.8886, -0.4271],
         [ 0.0809,  9.1295, -0.0606,  ..., -1.6912, -0.3173,  0.8719],
         [ 0.0632, 12.0941, -0.3946,  ..., -0.7239, -0.5502, -0.0400]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.0539, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.2290, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4248 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)
US government has halted capping capping the cap to
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0912,  2.4074,  0.7451,  ..., -3.0819, -0.3707,  3.1395],
         [ 0.1286,  2.7061,  0.1820,  ...,  1.5654, -0.9001, -2.5922],
         [ 0.1206,  4.2196,  0.0175,  ...,  0.7759, -0.9104, -1.6107],
         ...,
         [ 0.0911,  9.7111,  0.0248,  ..., -1.3569,  1.3469,  2.0094],
         [ 0.0991,  5.8451, -0.5439,  ..., -0.3421, -0.0205,  1.8846],
         [ 0.0697, 11.6947, -0.3673,  ..., -0.3041, -0.3692,  1.5087]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.3423, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.2133, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
US has gained a cap linking the cap to
iter = 4 reward = 2
final_logits =  tensor([[[ 0.1052,  3.1383,  0.6629,  ..., -3.5701,  0.1420,  2.1522],
         [ 0.1457,  4.0813,  0.0687,  ...,  1.2271, -0.2907, -2.0945],
         [ 0.1118,  2.3154,  0.3987,  ..., -0.2753, -0.8973, -0.2482],
         ...,
         [ 0.0989,  7.4147,  0.0439,  ..., -2.3009,  0.9769,  2.1120],
         [ 0.0996,  4.5076, -0.5373,  ..., -0.5668, -0.7766,  2.7490],
         [ 0.0902, 12.0505, -0.2854,  ..., -0.6441, -0.2819,  1.4570]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.8845, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8531, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[6174,  692,  110,  ...,  526,  115,    1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 40.4% (4450 out of 11019)

Everytime after generating next logits 41.6% (4582 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 44.0% (4850 out of 11019)

Everytime after generating next logits 45.2% (4986 out of 11019)

Everytime after generating next logits 45.2% (4986 out of 11019)

Everytime after generating next logits 45.2% (4986 out of 11019)

Everytime after generating next logits 45.2% (4986 out of 11019)

Everytime after generating next logits 46.5% (5126 out of 11019)

Everytime after generating next logits 47.8% (5266 out of 11019)

Everytime after generating next logits 47.8% (5266 out of 11019)

Everytime after generating next logits 47.8% (5266 out of 11019)

Everytime after generating next logits 47.8% (5266 out of 11019)

Everytime after generating next logits 49.1% (5410 out of 11019)

Everytime after generating next logits 50.4% (5554 out of 11019)

Everytime after generating next logits 50.4% (5554 out of 11019)

Everytime after generating next logits 50.4% (5554 out of 11019)

Everytime after generating next logits 50.4% (5554 out of 11019)

Everytime after generating next logits 50.4% (5554 out of 11019)

Everytime after generating next logits 51.7% (5702 out of 11019)

Everytime after generating next logits 53.1% (5850 out of 11019)

Everytime after generating next logits 53.1% (5850 out of 11019)

Everytime after generating next logits 53.1% (5850 out of 11019)

Everytime after generating next logits 53.1% (5850 out of 11019)

Everytime after generating next logits 54.5% (6002 out of 11019)

Everytime after generating next logits 55.8% (6154 out of 11019)

Everytime after generating next logits 55.8% (6154 out of 11019)

Everytime after generating next logits 55.8% (6154 out of 11019)

Everytime after generating next logits 55.8% (6154 out of 11019)

Everytime after generating next logits 55.8% (6154 out of 11019)

Everytime after generating next logits 57.3% (6310 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 60.1% (6626 out of 11019)

Everytime after generating next logits 61.6% (6786 out of 11019)

Everytime after generating next logits 61.6% (6786 out of 11019)

Everytime after generating next logits 61.6% (6786 out of 11019)

Everytime after generating next logits 61.6% (6786 out of 11019)

Everytime after generating next logits 61.6% (6786 out of 11019)

Everytime after generating next logits 63.1% (6950 out of 11019)

Everytime after generating next logits 64.6% (7114 out of 11019)

Everytime after generating next logits 64.6% (7114 out of 11019)

Everytime after generating next logits 64.6% (7114 out of 11019)

Everytime after generating next logits 64.6% (7114 out of 11019)

Everytime after generating next logits 66.1% (7282 out of 11019)

Everytime after generating next logits 67.6% (7450 out of 11019)

Everytime after generating next logits 67.6% (7450 out of 11019)

Everytime after generating next logits 67.6% (7450 out of 11019)

Everytime after generating next logits 67.6% (7450 out of 11019)

Everytime after generating next logits 67.6% (7450 out of 11019)

Everytime after generating next logits 69.2% (7622 out of 11019)

Everytime after generating next logits 70.7% (7794 out of 11019)

Everytime after generating next logits 70.7% (7794 out of 11019)

Everytime after generating next logits 70.7% (7794 out of 11019)

Everytime after generating next logits 70.7% (7794 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 73.9% (8146 out of 11019)

Everytime after generating next logits 73.9% (8146 out of 11019)

Everytime after generating next logits 73.9% (8146 out of 11019)

Everytime after generating next logits 73.9% (8146 out of 11019)

Everytime after generating next logits 73.9% (8146 out of 11019)

Everytime after generating next logits 75.6% (8326 out of 11019)

Everytime after generating next logits 77.2% (8506 out of 11019)

Everytime after generating next logits 77.2% (8506 out of 11019)

Everytime after generating next logits 77.2% (8506 out of 11019)

Everytime after generating next logits 77.2% (8506 out of 11019)

Everytime after generating next logits 78.9% (8690 out of 11019)

Everytime after generating next logits 80.5% (8874 out of 11019)

Everytime after generating next logits 80.5% (8874 out of 11019)

Everytime after generating next logits 80.5% (8874 out of 11019)

Everytime after generating next logits 80.5% (8874 out of 11019)

Everytime after generating next logits 82.2% (9062 out of 11019)

Everytime after generating next logits 83.9% (9250 out of 11019)

Everytime after generating next logits 83.9% (9250 out of 11019)

Everytime after generating next logits 83.9% (9250 out of 11019)

Everytime after generating next logits 83.9% (9250 out of 11019)

Everytime after generating next logits 83.9% (9250 out of 11019)

Everytime after generating next logits 85.7% (9442 out of 11019)

Everytime after generating next logits 87.4% (9634 out of 11019)

Everytime after generating next logits 87.4% (9634 out of 11019)

Everytime after generating next logits 87.4% (9634 out of 11019)

Everytime after generating next logits 87.4% (9634 out of 11019)

Everytime after generating next logits 89.2% (9830 out of 11019)

Everytime after generating next logits 91.0% (10026 out of 11019)

Everytime after generating next logits 91.0% (10026 out of 11019)

Everytime after generating next logits 91.0% (10026 out of 11019)

Everytime after generating next logits 91.0% (10026 out of 11019)

Everytime after generating next logits 91.0% (10026 out of 11019)

Everytime after generating next logits 92.8% (10226 out of 11019)

Everytime after generating next logits 94.6% (10426 out of 11019)

Everytime after generating next logits 94.6% (10426 out of 11019)

Everytime after generating next logits 94.6% (10426 out of 11019)

Everytime after generating next logits 94.6% (10426 out of 11019)

Everytime after generating next logits 96.5% (10630 out of 11019)

Everytime after generating next logits 98.3% (10834 out of 11019)

Everytime after generating next logits 98.3% (10834 out of 11019)

Everytime after generating next logits 98.3% (10834 out of 11019)

Everytime after generating next logits 98.3% (10834 out of 11019)

Everytime after generating next logits 98.3% (10834 out of 11019)

Everytime after generating next logits 42.2% (4654 out of 11019)

Everytime after generating next logits 44.1% (4862 out of 11019)

Everytime after generating next logits 44.1% (4862 out of 11019)

Everytime after generating next logits 44.1% (4862 out of 11019)

Everytime after generating next logits 44.1% (4862 out of 11019)

Everytime after generating next logits 46.0% (5074 out of 11019)

Everytime after generating next logits 48.0% (5286 out of 11019)

Everytime after generating next logits 48.0% (5286 out of 11019)

Everytime after generating next logits 48.0% (5286 out of 11019)

Everytime after generating next logits 48.0% (5286 out of 11019)

Everytime after generating next logits 48.0% (5286 out of 11019)

Everytime after generating next logits 49.9% (5502 out of 11019)

Everytime after generating next logits 51.9% (5718 out of 11019)

Everytime after generating next logits 51.9% (5718 out of 11019)

Everytime after generating next logits 51.9% (5718 out of 11019)

Everytime after generating next logits 51.9% (5718 out of 11019)

Everytime after generating next logits 53.9% (5938 out of 11019)

Everytime after generating next logits 55.9% (6158 out of 11019)

Everytime after generating next logits 55.9% (6158 out of 11019)

Everytime after generating next logits 55.9% (6158 out of 11019)

Everytime after generating next logits 55.9% (6158 out of 11019)

Everytime after generating next logits 55.9% (6158 out of 11019)

Everytime after generating next logits 57.9% (6382 out of 11019)

Everytime after generating next logits 60.0% (6606 out of 11019)

Everytime after generating next logits 60.0% (6606 out of 11019)

Everytime after generating next logits 60.0% (6606 out of 11019)

Everytime after generating next logits 60.0% (6606 out of 11019)

Everytime after generating next logits 62.0% (6834 out of 11019)

Everytime after generating next logits 64.1% (7062 out of 11019)

Everytime after generating next logits 64.1% (7062 out of 11019)

Everytime after generating next logits 64.1% (7062 out of 11019)

Everytime after generating next logits 64.1% (7062 out of 11019)

Everytime after generating next logits 66.2% (7294 out of 11019)

Everytime after generating next logits 68.3% (7526 out of 11019)

Everytime after generating next logits 68.3% (7526 out of 11019)

Everytime after generating next logits 68.3% (7526 out of 11019)

Everytime after generating next logits 68.3% (7526 out of 11019)

Everytime after generating next logits 68.3% (7526 out of 11019)

Everytime after generating next logits 70.4% (7762 out of 11019)

Everytime after generating next logits 72.6% (7998 out of 11019)

Everytime after generating next logits 72.6% (7998 out of 11019)

Everytime after generating next logits 72.6% (7998 out of 11019)

Everytime after generating next logits 72.6% (7998 out of 11019)

Everytime after generating next logits 74.8% (8238 out of 11019)

Everytime after generating next logits 76.9% (8478 out of 11019)

Everytime after generating next logits 76.9% (8478 out of 11019)

Everytime after generating next logits 76.9% (8478 out of 11019)

Everytime after generating next logits 76.9% (8478 out of 11019)

Everytime after generating next logits 76.9% (8478 out of 11019)

Everytime after generating next logits 79.2% (8722 out of 11019)

Everytime after generating next logits 81.4% (8966 out of 11019)

Everytime after generating next logits 81.4% (8966 out of 11019)

Everytime after generating next logits 81.4% (8966 out of 11019)

Everytime after generating next logits 81.4% (8966 out of 11019)

Everytime after generating next logits 83.6% (9214 out of 11019)

Everytime after generating next logits 85.9% (9462 out of 11019)

Everytime after generating next logits 85.9% (9462 out of 11019)

Everytime after generating next logits 85.9% (9462 out of 11019)

Everytime after generating next logits 85.9% (9462 out of 11019)

Everytime after generating next logits 85.9% (9462 out of 11019)

Everytime after generating next logits 88.2% (9714 out of 11019)

Everytime after generating next logits 90.4% (9966 out of 11019)

Everytime after generating next logits 90.4% (9966 out of 11019)

Everytime after generating next logits 90.4% (9966 out of 11019)

Everytime after generating next logits 90.4% (9966 out of 11019)

Everytime after generating next logits 92.8% (10222 out of 11019)

Everytime after generating next logits 95.1% (10478 out of 11019)

Everytime after generating next logits 95.1% (10478 out of 11019)

Everytime after generating next logits 95.1% (10478 out of 11019)

Everytime after generating next logits 95.1% (10478 out of 11019)

Everytime after generating next logits 95.1% (10478 out of 11019)

Everytime after generating next logits 97.4% (10738 out of 11019)

Everytime after generating next logits 99.8% (10998 out of 11019)

Everytime after generating next logits 99.8% (10998 out of 11019)

Everytime after generating next logits 99.8% (10998 out of 11019)

Everytime after generating next logits 99.8% (10998 out of 11019)

Everytime after generating next logits 43.3% (4766 out of 11019)

Everytime after generating next logits 45.6% (5030 out of 11019)

Everytime after generating next logits 45.6% (5030 out of 11019)

Everytime after generating next logits 45.6% (5030 out of 11019)

Everytime after generating next logits 45.6% (5030 out of 11019)

Everytime after generating next logits 45.6% (5030 out of 11019)

Everytime after generating next logits 48.1% (5298 out of 11019)

Everytime after generating next logits 50.5% (5566 out of 11019)

Everytime after generating next logits 50.5% (5566 out of 11019)

Everytime after generating next logits 50.5% (5566 out of 11019)

Everytime after generating next logits 50.5% (5566 out of 11019)

Everytime after generating next logits 53.0% (5838 out of 11019)

Everytime after generating next logits 55.4% (6110 out of 11019)

Everytime after generating next logits 55.4% (6110 out of 11019)

Everytime after generating next logits 55.4% (6110 out of 11019)

Everytime after generating next logits 55.4% (6110 out of 11019)

Everytime after generating next logits 58.0% (6386 out of 11019)

Everytime after generating next logits 60.5% (6662 out of 11019)

Everytime after generating next logits 60.5% (6662 out of 11019)

Everytime after generating next logits 60.5% (6662 out of 11019)

Everytime after generating next logits 60.5% (6662 out of 11019)

Everytime after generating next logits 60.5% (6662 out of 11019)

Everytime after generating next logits 63.0% (6942 out of 11019)

Everytime after generating next logits 65.5% (7222 out of 11019)

Everytime after generating next logits 65.5% (7222 out of 11019)

Everytime after generating next logits 65.5% (7222 out of 11019)

Everytime after generating next logits 65.5% (7222 out of 11019)

Everytime after generating next logits 68.1% (7506 out of 11019)

Everytime after generating next logits 70.7% (7790 out of 11019)

Everytime after generating next logits 70.7% (7790 out of 11019)

Everytime after generating next logits 70.7% (7790 out of 11019)

Everytime after generating next logits 70.7% (7790 out of 11019)

Everytime after generating next logits 70.7% (7790 out of 11019)

Everytime after generating next logits 73.3% (8078 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 78.6% (8658 out of 11019)

Everytime after generating next logits 81.2% (8950 out of 11019)

Everytime after generating next logits 81.2% (8950 out of 11019)

Everytime after generating next logits 81.2% (8950 out of 11019)

Everytime after generating next logits 81.2% (8950 out of 11019)

Everytime after generating next logits 81.2% (8950 out of 11019)

Everytime after generating next logits 83.9% (9246 out of 11019)

Everytime after generating next logits 86.6% (9542 out of 11019)

Everytime after generating next logits 86.6% (9542 out of 11019)

Everytime after generating next logits 86.6% (9542 out of 11019)

Everytime after generating next logits 86.6% (9542 out of 11019)

Everytime after generating next logits 89.3% (9842 out of 11019)

Everytime after generating next logits 92.0% (10142 out of 11019)

Everytime after generating next logits 92.0% (10142 out of 11019)

Everytime after generating next logits 92.0% (10142 out of 11019)

Everytime after generating next logits 92.0% (10142 out of 11019)

Everytime after generating next logits 92.0% (10142 out of 11019)

Everytime after generating next logits 94.8% (10446 out of 11019)

Everytime after generating next logits 97.6% (10750 out of 11019)

Everytime after generating next logits 97.6% (10750 out of 11019)

Everytime after generating next logits 97.6% (10750 out of 11019)

Everytime after generating next logits 97.6% (10750 out of 11019)

Everytime after generating next logits 44.1% (4854 out of 11019)

Everytime after generating next logits 46.8% (5162 out of 11019)

Everytime after generating next logits 46.8% (5162 out of 11019)

Everytime after generating next logits 46.8% (5162 out of 11019)

Everytime after generating next logits 46.8% (5162 out of 11019)

Everytime after generating next logits 46.8% (5162 out of 11019)

Everytime after generating next logits 49.7% (5474 out of 11019)

Everytime after generating next logits 52.5% (5786 out of 11019)

Everytime after generating next logits 52.5% (5786 out of 11019)

Everytime after generating next logits 52.5% (5786 out of 11019)

Everytime after generating next logits 52.5% (5786 out of 11019)

Everytime after generating next logits 55.4% (6102 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 61.1% (6738 out of 11019)

Everytime after generating next logits 64.1% (7058 out of 11019)

Everytime after generating next logits 64.1% (7058 out of 11019)

Everytime after generating next logits 64.1% (7058 out of 11019)

Everytime after generating next logits 64.1% (7058 out of 11019)

Everytime after generating next logits 64.1% (7058 out of 11019)

Everytime after generating next logits 67.0% (7382 out of 11019)

Everytime after generating next logits 69.9% (7706 out of 11019)

Everytime after generating next logits 69.9% (7706 out of 11019)

Everytime after generating next logits 69.9% (7706 out of 11019)

Everytime after generating next logits 69.9% (7706 out of 11019)

Everytime after generating next logits 72.9% (8034 out of 11019)

Everytime after generating next logits 75.9% (8362 out of 11019)

Everytime after generating next logits 75.9% (8362 out of 11019)

Everytime after generating next logits 75.9% (8362 out of 11019)

Everytime after generating next logits 75.9% (8362 out of 11019)

Everytime after generating next logits 75.9% (8362 out of 11019)

Everytime after generating next logits 78.9% (8694 out of 11019)

Everytime after generating next logits 81.9% (9026 out of 11019)

Everytime after generating next logits 81.9% (9026 out of 11019)

Everytime after generating next logits 81.9% (9026 out of 11019)

Everytime after generating next logits 81.9% (9026 out of 11019)

Everytime after generating next logits 85.0% (9362 out of 11019)

Everytime after generating next logits 88.0% (9698 out of 11019)

Everytime after generating next logits 88.0% (9698 out of 11019)

Everytime after generating next logits 88.0% (9698 out of 11019)

Everytime after generating next logits 88.0% (9698 out of 11019)

Everytime after generating next logits 88.0% (9698 out of 11019)

Everytime after generating next logits 91.1% (10038 out of 11019)

Everytime after generating next logits 94.2% (10378 out of 11019)

Everytime after generating next logits 94.2% (10378 out of 11019)

Everytime after generating next logits 94.2% (10378 out of 11019)

Everytime after generating next logits 94.2% (10378 out of 11019)

Everytime after generating next logits 97.3% (10722 out of 11019)

Everytime after generating next logits 44.7% (4930 out of 11019)

Everytime after generating next logits 44.7% (4930 out of 11019)

Everytime after generating next logits 44.7% (4930 out of 11019)

Everytime after generating next logits 44.7% (4930 out of 11019)

Everytime after generating next logits 44.7% (4930 out of 11019)

Everytime after generating next logits 47.9% (5278 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 54.3% (5978 out of 11019)

Everytime after generating next logits 57.4% (6330 out of 11019)

Everytime after generating next logits 57.4% (6330 out of 11019)

Everytime after generating next logits 57.4% (6330 out of 11019)

Everytime after generating next logits 57.4% (6330 out of 11019)

Everytime after generating next logits 57.4% (6330 out of 11019)

Everytime after generating next logits 60.7% (6686 out of 11019)

Everytime after generating next logits 63.9% (7042 out of 11019)

Everytime after generating next logits 63.9% (7042 out of 11019)

Everytime after generating next logits 63.9% (7042 out of 11019)

Everytime after generating next logits 63.9% (7042 out of 11019)

Everytime after generating next logits 67.2% (7402 out of 11019)

Everytime after generating next logits 70.4% (7762 out of 11019)

Everytime after generating next logits 70.4% (7762 out of 11019)

Everytime after generating next logits 70.4% (7762 out of 11019)

Everytime after generating next logits 70.4% (7762 out of 11019)

Everytime after generating next logits 73.7% (8126 out of 11019)

Everytime after generating next logits 77.0% (8490 out of 11019)

Everytime after generating next logits 77.0% (8490 out of 11019)

Everytime after generating next logits 77.0% (8490 out of 11019)

Everytime after generating next logits 77.0% (8490 out of 11019)

Everytime after generating next logits 77.0% (8490 out of 11019)

Everytime after generating next logits 80.4% (8858 out of 11019)

Everytime after generating next logits 83.7% (9226 out of 11019)

Everytime after generating next logits 83.7% (9226 out of 11019)

Everytime after generating next logits 83.7% (9226 out of 11019)

Everytime after generating next logits 83.7% (9226 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 90.5% (9970 out of 11019)

Everytime after generating next logits 90.5% (9970 out of 11019)

Everytime after generating next logits 90.5% (9970 out of 11019)

Everytime after generating next logits 90.5% (9970 out of 11019)

Everytime after generating next logits 90.5% (9970 out of 11019)

Everytime after generating next logits 93.9% (10346 out of 11019)

Everytime after generating next logits 97.3% (10722 out of 11019)

Everytime after generating next logits 97.3% (10722 out of 11019)

Everytime after generating next logits 97.3% (10722 out of 11019)
Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh Hugh
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1460,  3.2154,  1.1860,  ..., -4.3549,  0.3214,  1.9498],
         [ 0.1136,  2.6625,  1.0873,  ..., -2.7938, -0.3987,  3.3636],
         [ 0.1200,  2.8422,  0.8791,  ..., -2.3378, -0.3422,  3.6072],
         ...,
         [ 0.1240,  8.0720,  0.0245,  ..., -5.0886, -1.2229,  0.5388],
         [ 0.1240,  8.0316,  0.0256,  ..., -5.0848, -1.2120,  0.5389],
         [ 0.1240,  8.0118,  0.0256,  ..., -5.0814, -1.2090,  0.5299]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.0248, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8149, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)

Everytime after generating next logits 50.0% (5512 out of 11019)
BP BP's Deepwater Horizon Horizon will be
iter = 1 reward = 4
final_logits =  tensor([[[ 0.1073,  3.6130,  0.9610,  ..., -5.1502, -1.6403,  1.3188],
         [ 0.1270,  1.3432, -0.4270,  ..., -4.0263, -1.9902, -3.3307],
         [ 0.1231,  1.1016, -0.4597,  ..., -4.2952, -1.5510, -2.5481],
         ...,
         [ 0.1118,  2.8702, -0.3760,  ..., -3.1353, -2.2127, -0.5037],
         [ 0.0760, 10.3820, -0.2431,  ...,  0.3293, -0.5705,  0.5530],
         [ 0.1094, 12.1965, -0.1739,  ..., -2.0882, -0.9061,  0.0442]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.5620, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.8748, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)
BBC'
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1032,  3.7565,  1.0597,  ..., -5.3589, -1.0562,  1.0040],
         [ 0.1049,  6.7038,  0.0334,  ..., -4.0469, -3.0081, -1.3861],
         [ 0.0753, 11.1763,  0.1905,  ..., -1.3637, -1.3199, -0.5135]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8557, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4204, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
BBC News:
iter = 3 reward = 1
final_logits =  tensor([[[ 0.1311,  4.2587,  1.2191,  ..., -4.0828, -0.1355,  2.0565],
         [ 0.1210,  6.7518,  0.1131,  ..., -3.2169, -2.5203, -1.8786],
         [ 0.1414,  6.2486,  0.0819,  ..., -1.8405, -2.8542, -1.9319],
         [ 0.0954, 10.3464,  0.2646,  ..., -1.9517, -0.5909,  0.0150]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4008, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9583, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)
BBC and BBC correspondent Ed
iter = 4 reward = 2
final_logits =  tensor([[[ 0.1559,  3.1266,  1.1615,  ..., -3.8879,  0.4505,  2.2639],
         [ 0.1220,  7.3236,  0.0292,  ..., -3.5841, -2.4829, -2.1841],
         [ 0.1215,  5.6419,  0.0889,  ..., -3.0084, -1.0005, -0.4936],
         [ 0.0970,  4.0973, -0.0750,  ..., -3.7175, -2.1470, -2.2306],
         [ 0.0606,  7.3719, -0.3387,  ..., -3.7770, -3.2595, -1.3063],
         [ 0.0872,  9.9097,  0.2060,  ..., -0.6864, -0.4850,  0.1171]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8295, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.9830, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  139,  5543,  9254,   320,  3702,   142,   865,   728,   113,   109,
          16036,   762, 14567,   110,   107,  8916,   114,  1713,   113,  5012,
            122,   662,   503, 32908,   110,   108,   330,   278,  2668,   116,
            122,  4605, 35522,   110,   108,   109,   177,  3378,   113, 16036,
            111,  6061, 32886,   110,   108,   169, 15978,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)
Head of the head of the new head of the oil spill, Bob .
iter = 0 reward = 2
final_logits =  tensor([[[ 0.0928,  4.2207,  0.5046,  ..., -2.1770,  2.1336, -1.9242],
         [ 0.0862,  4.3025,  0.0528,  ..., -5.3443, -0.6275,  0.2849],
         [ 0.0831,  3.8002, -0.2831,  ..., -4.2277, -0.3749, -0.2299],
         ...,
         [ 0.0908,  6.7300, -0.2232,  ..., -2.8171, -1.1690, -1.4872],
         [ 0.0929, 11.0474,  0.1408,  ..., -1.1627, -0.4789, -0.3374],
         [ 0.0720, 13.3781, -0.4485,  ..., -0.2852, -1.2135, -1.1316]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1296, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4127, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)
Head of the head of the BP head Tony Hayward and the host of the oil spill .
iter = 1 reward = 4
final_logits =  tensor([[[ 0.0979,  4.4084,  0.4656,  ..., -2.2457,  1.8665, -2.0167],
         [ 0.0885,  3.9896,  0.0422,  ..., -5.3822, -0.5907,  0.3279],
         [ 0.0896,  3.4170, -0.2639,  ..., -4.4327, -0.7262, -0.0782],
         ...,
         [ 0.1290,  8.6796, -0.9657,  ..., -3.1344, -1.7281, -2.2970],
         [ 0.1050, 11.1373, -0.1990,  ..., -1.4654, -1.2287, -1.0798],
         [ 0.0745, 13.0405, -0.3562,  ..., -0.6924, -1.2213, -1.1642]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.9533, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.8929, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)

Everytime after generating next logits 38.6% (4258 out of 11019)
Head of the head of the BP head Tony Hayward and the host of the oil spill .
iter = 2 reward = 4
final_logits =  tensor([[[ 0.1006,  4.4280,  0.4407,  ..., -2.4306,  1.9735, -2.3517],
         [ 0.0902,  5.2006,  0.0560,  ..., -5.2523, -0.5078,  0.2316],
         [ 0.0885,  6.9146, -0.3289,  ..., -3.8177, -0.6903, -0.7081],
         ...,
         [ 0.1187,  9.3166, -0.9577,  ..., -2.5973, -1.5048, -2.1176],
         [ 0.1032, 12.1472, -0.1957,  ..., -1.1238, -1.2804, -0.8949],
         [ 0.0697, 13.5002, -0.2998,  ..., -0.5144, -1.1640, -0.8479]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1285, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.7584, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)

Everytime after generating next logits 38.6% (4254 out of 11019)
Head of the head of the BP oil spill, Bob .
iter = 3 reward = 2
final_logits =  tensor([[[ 0.0955,  4.3936,  0.4368,  ..., -2.0034,  1.8961, -2.1162],
         [ 0.0808,  4.0296,  0.0906,  ..., -5.2571, -0.3007,  0.2619],
         [ 0.0744,  3.1840, -0.2610,  ..., -4.5820, -0.4907, -0.1624],
         ...,
         [ 0.0869,  5.3025, -0.4323,  ..., -2.8225, -1.4143, -1.6782],
         [ 0.0917,  9.5944, -0.0548,  ..., -1.3481, -0.7787, -0.4959],
         [ 0.0763, 13.0020, -0.5634,  ..., -1.0120, -1.3013, -1.7209]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1496, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.3611, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Head of the Dudley Dudley and host of the oil spill, Bob .
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0982,  4.2276,  0.4386,  ..., -1.9179,  2.1083, -2.0851],
         [ 0.0822,  4.4508,  0.1223,  ..., -5.2704, -0.0519,  0.0806],
         [ 0.0723,  4.3496, -0.2804,  ..., -4.3900, -0.1654, -0.4290],
         ...,
         [ 0.0975,  7.2494, -0.4401,  ..., -2.5198, -1.2060, -1.5564],
         [ 0.0913, 12.1861,  0.0432,  ..., -1.0080, -0.8189, -0.1330],
         [ 0.0730, 13.4588, -0.4031,  ..., -0.4429, -0.9566, -0.9414]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.9995, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.0875, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 1084, 18756,   110,  ...,  5135,   378,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.3% (4330 out of 11019)

Everytime after generating next logits 39.9% (4394 out of 11019)
BP's chief executive will
iter = 0 reward = 1
final_logits =  tensor([[[ 1.5236e-01,  1.8710e+00,  1.2022e+00,  ..., -4.3869e+00,
           7.5803e-01,  3.6081e-01],
         [ 1.1489e-01,  3.5312e+00, -1.1289e-01,  ..., -2.8589e+00,
          -7.5740e-01, -2.7680e+00],
         [ 1.0462e-01,  1.1012e+01, -3.1231e-03,  ..., -1.1389e+00,
          -6.0323e-01, -1.1619e+00],
         ...,
         [ 1.3531e-01,  5.8331e+00,  1.7297e-02,  ..., -3.8109e+00,
          -7.8325e-01, -8.8051e-01],
         [ 1.0232e-01,  6.5592e+00, -3.8687e-01,  ..., -2.2015e+00,
          -2.2673e+00,  9.5780e-02],
         [ 9.7460e-02,  1.1272e+01, -2.6516e-01,  ...,  6.8627e-01,
          -5.3382e-01,  3.4915e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.1306, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.3488, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4230 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)
The Gulf Coast Coast Coast Coast Coast is being held to
iter = 1 reward = 6
final_logits =  tensor([[[ 0.0974,  3.4266,  0.7752,  ..., -3.0156, -0.2112, -0.8039],
         [ 0.0847,  2.5991,  0.1222,  ..., -4.3484,  0.1200, -1.7514],
         [ 0.0745,  1.1372,  0.7452,  ..., -8.4911, -2.6972, -1.5230],
         ...,
         [ 0.1231,  8.0667,  0.2995,  ..., -2.8989, -0.2606, -1.8366],
         [ 0.1356,  9.4225, -0.2944,  ..., -0.1426, -0.9010, -0.8644],
         [ 0.0841, 11.8203, -0.2793,  ..., -0.2017, -0.3604, -0.1309]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.2128, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.3894, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4262 out of 11019)

Everytime after generating next logits 39.3% (4326 out of 11019)

Everytime after generating next logits 39.3% (4326 out of 11019)

Everytime after generating next logits 39.3% (4326 out of 11019)
Hundreds of
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1185,  3.4001,  0.8577,  ..., -2.7135, -0.1448, -0.1776],
         [ 0.0730,  8.8702, -0.2715,  ..., -1.9519, -1.3288, -1.6220],
         [ 0.0988, 11.0941, -0.1359,  ..., -2.0353, -0.5041, -0.9780]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4352, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.0269, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
Anonymous box that could be used to be used to
iter = 3 reward = 3
final_logits =  tensor([[[ 0.1050,  2.4692,  0.7982,  ..., -4.0010,  0.1712, -0.1375],
         [ 0.1274,  2.5990,  0.3058,  ..., -3.1753,  0.9703, -2.4660],
         [ 0.1129,  4.0913, -0.4231,  ..., -1.6326, -3.2616, -1.8285],
         ...,
         [ 0.0989,  7.0231,  0.1217,  ..., -2.8815, -1.9575, -1.4345],
         [ 0.1005,  6.5118, -0.5738,  ..., -1.1360, -0.4059, -0.9336],
         [ 0.0762, 10.4305, -0.1822,  ..., -1.9957, -1.0549,  0.0558]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3997, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5146, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4240 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)
BP will have to be laid off to a box to help contain a well-
iter = 4 reward = 4
final_logits =  tensor([[[ 1.2359e-01,  3.4361e+00,  7.9615e-01,  ..., -5.3390e+00,
           3.5867e-01,  2.3661e-01],
         [ 1.1708e-01,  1.7153e+00, -2.3015e-01,  ..., -3.4094e+00,
          -1.2413e+00, -3.7450e+00],
         [ 5.2890e-02,  1.2322e+00,  8.7589e-03,  ..., -1.7631e+00,
           7.7173e-01, -4.4816e-01],
         ...,
         [ 5.7315e-02,  9.3509e+00, -3.5901e-02,  ..., -3.4092e+00,
           9.5299e-01,  1.1618e+00],
         [ 9.1244e-02,  6.6752e+00, -1.0919e-01,  ..., -2.3265e+00,
          -1.8370e+00,  1.8882e-01],
         [ 4.0146e-02,  1.1682e+01,  7.8581e-01,  ..., -8.7952e-01,
          -2.4547e+00, -8.4388e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7912, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2634, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  4
4
{'input_ids': tensor([[[16036,   243,   186,  ...,   111,  2684,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.5% (4246 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)
BP'
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1934,  4.8659,  0.7514,  ..., -2.2310,  4.5052, -0.9017],
         [ 0.1465,  5.0887, -0.1499,  ..., -1.8804,  1.3692, -2.8052],
         [ 0.0967, 11.5498,  0.0836,  ..., -0.2701, -0.0258, -0.2263]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.2262, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.4598, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
US Gulf giant US Gulf giant US Gulf
iter = 1 reward = 3
final_logits =  tensor([[[ 1.5642e-01,  4.2935e+00,  2.9249e-01,  ..., -3.1531e+00,
           2.6701e+00,  8.2229e-01],
         [ 1.4456e-01,  3.9407e+00,  1.9253e-01,  ..., -4.3547e-01,
           1.1771e+00, -2.0124e+00],
         [ 1.2506e-01,  3.2889e+00,  1.7141e-01,  ..., -2.1801e+00,
           3.1393e-01, -4.7771e-02],
         ...,
         [ 1.4429e-01,  8.4242e+00, -3.2647e-01,  ..., -3.0731e+00,
           1.5785e+00, -8.0176e-01],
         [ 1.5262e-01,  9.3204e+00,  9.3906e-02,  ..., -6.9081e-01,
           1.0118e+00, -1.9771e+00],
         [ 1.2539e-01,  1.2895e+01,  1.0457e-03,  ..., -1.0334e+00,
          -8.0349e-01, -5.5209e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5099, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7835, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4232 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)
US Gulf giant US Gulf giant US Gulf
iter = 2 reward = 3
final_logits =  tensor([[[ 0.1648,  3.8769,  0.3329,  ..., -2.2680,  2.5570,  0.2401],
         [ 0.1473,  3.7925,  0.1495,  ..., -0.3094,  1.0139, -2.0353],
         [ 0.1271,  3.2558,  0.1849,  ..., -2.2397, -0.0626, -0.3123],
         ...,
         [ 0.1431,  8.0442, -0.3492,  ..., -2.9667,  1.0478, -1.2201],
         [ 0.1524,  8.6797,  0.0748,  ..., -0.7192,  0.7188, -2.3173],
         [ 0.1209, 12.3949,  0.0771,  ..., -0.9818, -1.0776, -0.7625]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3708, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7243, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4232 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)
US Gulf giant US Gulf giant US Gulf
iter = 3 reward = 3
final_logits =  tensor([[[ 1.7443e-01,  4.4599e+00,  2.8893e-01,  ..., -2.0813e+00,
           2.8481e+00, -2.0134e-01],
         [ 1.5128e-01,  3.9017e+00,  1.0722e-01,  ..., -2.6675e-01,
           1.0761e+00, -1.9242e+00],
         [ 1.3061e-01,  3.7153e+00,  1.0576e-01,  ..., -1.7959e+00,
          -2.4404e-02,  1.0981e-02],
         ...,
         [ 1.4600e-01,  9.0793e+00, -3.5531e-01,  ..., -2.3697e+00,
           1.1590e+00, -1.0939e+00],
         [ 1.5327e-01,  1.0138e+01,  8.4850e-03,  ..., -4.7874e-01,
           6.1194e-01, -1.9570e+00],
         [ 1.1970e-01,  1.3034e+01, -2.8809e-02,  ..., -7.6597e-01,
          -1.0840e+00, -4.6789e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6055, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.0949, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4232 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)

Everytime after generating next logits 39.6% (4360 out of 11019)
US Gulf giant US Gulf giant US
iter = 4 reward = 2
final_logits =  tensor([[[ 0.1735,  4.5387,  0.4194,  ..., -3.1597,  2.9055, -0.7414],
         [ 0.1653,  4.2049,  0.2041,  ...,  0.1881,  1.6063, -1.4512],
         [ 0.1360,  3.9392,  0.1416,  ..., -1.8725, -0.2808,  0.1298],
         ...,
         [ 0.1342,  9.7945,  0.0584,  ..., -1.1888, -0.6545, -0.2695],
         [ 0.1557, 10.0858, -0.2651,  ..., -1.8066,  1.2656, -0.7555],
         [ 0.1718, 11.3272,  0.0385,  ...,  0.1209,  0.8436, -1.4628]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2614, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3053, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[16036, 35640,   116,  ...,  3598, 32220,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.4% (4230 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)
Gulf Gulf Coast Coast Coast Coast
iter = 0 reward = 6
final_logits =  tensor([[[ 0.1199,  2.9859,  1.0370,  ..., -2.3534, -0.5931, -0.9250],
         [ 0.1122,  6.8361,  0.5406,  ..., -2.9908, -1.9884, -0.9919],
         [ 0.1101,  5.9526,  0.4931,  ..., -3.2758, -2.1569, -1.0872],
         ...,
         [ 0.1038,  8.9259, -0.1429,  ..., -2.2427, -2.9385, -1.7052],
         [ 0.1049,  8.5875, -0.1548,  ..., -2.2475, -2.7648, -1.7372],
         [ 0.1057,  8.7612, -0.1557,  ..., -2.1921, -2.5482, -1.7354]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3507, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4085, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)

Everytime after generating next logits 39.4% (4338 out of 11019)
Gulf Gulf Gulf Coast Coast Coast Coast Coast
iter = 1 reward = 8
final_logits =  tensor([[[ 0.1609,  4.7065,  1.2709,  ..., -2.1500,  0.5451,  0.8409],
         [ 0.1680,  6.4259,  0.9640,  ..., -2.1104, -1.3346,  1.5422],
         [ 0.1648,  5.8092,  0.9398,  ..., -2.1632, -1.5208,  1.3280],
         ...,
         [ 0.1649,  9.5716,  0.4256,  ..., -1.9995, -1.5253,  0.1003],
         [ 0.1625, 10.0008,  0.3997,  ..., -2.0115, -1.4687, -0.0211],
         [ 0.1589, 10.7885,  0.3763,  ..., -1.9659, -1.3468, -0.1247]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.7730, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.8347, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4236 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)
US Gulf Gulf Coast Coast Coast Coast Coast Coast
iter = 2 reward = 8
final_logits =  tensor([[[ 0.1511,  4.4127,  1.2926,  ..., -2.5710,  1.1209, -0.7136],
         [ 0.1689,  5.1483,  0.6179,  ..., -0.4544,  1.9352, -1.7463],
         [ 0.1464,  4.5414,  0.9472,  ..., -1.3446, -1.0976, -0.3150],
         ...,
         [ 0.1414,  9.2388,  0.2479,  ..., -2.6701, -0.5602, -1.4961],
         [ 0.1396, 10.2622,  0.2321,  ..., -2.5212, -0.4519, -1.4978],
         [ 0.1392, 10.9715,  0.1983,  ..., -2.5850, -0.4165, -1.6190]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7493, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.5318, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
56,000 tonnes of a pipe pipe that
iter = 3 reward = 2
final_logits =  tensor([[[ 0.1595,  4.2872,  1.3778,  ..., -2.6293,  0.7762, -0.7085],
         [ 0.1633,  4.3542,  1.0765,  ..., -2.2002, -2.1412, -0.8910],
         [ 0.0951,  6.7177,  0.5306,  ..., -2.0277, -1.6250,  0.5165],
         ...,
         [ 0.1372,  8.5514, -0.0189,  ..., -0.5021, -0.8034,  1.2174],
         [ 0.1372,  9.3015, -0.0546,  ..., -0.4076, -1.0659,  1.2517],
         [ 0.1294, 12.7368,  0.3680,  ...,  1.2470, -0.2924,  0.8469]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.1595, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.0989, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4236 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

iter = 4 reward = 0
final_logits =  tensor([[[ 0.1688,  4.6297,  1.3408,  ..., -2.4258,  0.4298,  0.1921],
         [ 0.1676,  6.3793,  1.6635,  ..., -2.3504,  0.4371,  2.2214],
         [ 0.1648,  6.2357,  1.5880,  ..., -2.1011,  0.4081,  2.0177],
         ...,
         [ 0.1571,  8.4162,  1.2489,  ..., -1.8678,  0.3595,  1.5134],
         [ 0.1567,  9.0861,  1.1854,  ..., -1.8465,  0.3218,  1.3617],
         [ 0.1551, 10.0176,  1.1077,  ..., -1.7504,  0.2508,  1.2259]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.0373, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.8721, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787,  1276, 12998,  3531,   148,  4486, 18205, 53857,  7028,   112,
          15079,   109,  3662,   599, 10970,   233, 20447,   788,   121,  1768,
          43304,   110, 10970,   233, 16567,   788,   121,  2617,   120, 16036,
            148,   323,   164,   112, 13889,  4807,   113,   109,  7175,   113,
           3064,   762, 14567,   110,   107,  1263, 53857,  7028,   148,   306,
            115,   253,  2887,   110,   151,   178,  3120,   109,  4807,  1034,
           1844,  2617,   323,   164,   115,   109,  4619,   113,   109,  1073,
           1338,  6687,  3613,   115,   351,   859,   111,  1741,   110,   107,
            285,   148,   243,   178,   117,   146, 10237,   122,   109,   657,
            132, 16036,   111,   138, 15079,   109,  2617,  7539,   110,   107,
           2632,   138,   719,  3916,   135,   109,  2617,   110,   152,   139,
            762, 14567,   148,  2145, 12071,   466,   109,   787,  7175,  3500,
            110,   108,  7271,  3070,   111,  5569,   111, 65047,   181,  4758,
            111, 44650, 18205, 53857,  7028, 35571,  3916,   118,  4807,   113,
            109,  1073,  1338,   110,   108,  6687,  3613,  7922,  8749, 18205,
          53857,  7028, 18097, 16915,   918,   111,   243,  2784,   192,   129,
            154,  5263,   197,   274,   120,   192,   129,  3366,   141,   114,
           1462,   110,   107,   343,   178,   243,   274,  2486,  3916,   355,
            361,   164,   153,   268,   112, 17984, 16036,   110,   107,   139,
           2617,   117,   112, 34262,  7175,   113,  3064,  1836,   111,  1098,
            118,  1166,  9125,   111,  5471,   111,   118,   510,  3207,   111,
           1003,   121,   768,   110,   108,   790,   176,  2242,   110,   107,
          16036,   148,   506,  1389,  3662,   110, 37622,   208,   115,  2242,
            381,   109,   960, 14567,   110,   107,   139,   762, 14567,   110,
            108,   162,  1219,   599,   960,   122,   109, 11335,   113,   109,
          16036,   121, 38539,   252, 81065, 18308,  9600, 13773,   110,   108,
           2145,  8010, 12071,   466,   109,   787,  7175,  3500, 18205, 53857,
           7028, 35571,  3916,   118,  4807,   113,   109,  1073,  1338,   110,
            108,  6687,  3613,   139,  8749,   113,   114,  3662,   599, 10970,
            233, 20447,   788,   121,  1768, 31197,   110, 10970,   233, 16567,
            788,   121,  2617,   112, 13889,  4807,   113,   109, 16036,   762,
          14567,   148,   243,   186,   117,   110,   105,   220,  2767, 16837,
            120, 15931,  2242,   127,   142,   797,   110,   107, 18205, 53857,
           7028, 18097,   112,   129, 24915,   204,   170,   915,  2784,   112,
           1480,   109,  4959,   113,   109,  2617,   110,   107,  3440,  3662,
          12622,   110, 10970,   148,   506,   174,  1389,   165,   115,  2280,
           2784,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)

Everytime after generating next logits 38.4% (4232 out of 11019)
US has paid Gulf residents and
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1203,  4.0079,  0.8922,  ..., -3.3471,  2.5613,  0.4202],
         [ 0.1817,  4.4359,  0.3868,  ...,  0.2248,  2.8795, -0.8765],
         [ 0.1337,  2.9706,  0.1480,  ..., -2.0897,  1.1870, -0.6478],
         ...,
         [ 0.1338,  6.5417,  0.2734,  ..., -2.1119,  0.6754, -0.4730],
         [ 0.1240,  5.4162, -0.4286,  ..., -2.3535,  2.9967, -0.8064],
         [ 0.1127, 11.4540, -0.0940,  ..., -2.2268,  1.2279, -0.3804]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.9170, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(15.2828, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
Fein Feinberg has already already already
iter = 1 reward = 0
final_logits =  tensor([[[ 1.2778e-01,  3.9616e+00,  7.0247e-01,  ..., -5.8942e-01,
           1.7931e+00, -3.4023e-01],
         [ 1.1530e-01,  6.1859e+00,  5.1263e-01,  ...,  1.4443e+00,
          -1.5486e+00,  1.4134e+00],
         [ 1.1227e-01,  6.6771e+00,  3.9720e-01,  ...,  1.2175e+00,
          -1.6346e+00,  9.5619e-01],
         ...,
         [ 1.1843e-01,  7.4115e+00,  2.5545e-02,  ..., -2.0345e-02,
           8.7597e-01, -1.4001e+00],
         [ 1.1927e-01,  9.2219e+00,  3.8536e-03,  ...,  4.1971e-02,
           8.8704e-01, -1.3910e+00],
         [ 1.2166e-01,  1.2519e+01, -1.2429e-01,  ..., -1.4635e-01,
           8.2843e-01, -1.2135e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.6480, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.9515, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Fein Fein Fein Fein Fein Fein
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1329,  4.2668,  0.7153,  ..., -0.7893,  1.7192, -0.6542],
         [ 0.1338,  6.5026,  0.4697,  ...,  0.6417, -0.4174,  0.8121],
         [ 0.1272,  7.0686,  0.3509,  ...,  0.6363, -0.3831,  0.6298],
         ...,
         [ 0.1246,  8.7750,  0.2629,  ...,  0.6618, -0.4039,  0.1979],
         [ 0.1232,  9.2232,  0.2604,  ...,  0.6982, -0.4365,  0.1223],
         [ 0.1214,  9.7105,  0.2479,  ...,  0.7244, -0.4858,  0.0460]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3459, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2103, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
Fund Fund
iter = 3 reward = 2
final_logits =  tensor([[[ 0.1456,  5.1402,  0.7310,  ..., -0.4649,  1.8515, -0.4090],
         [ 0.1305,  9.0650, -0.1898,  ..., -0.8346,  2.8263, -0.3977],
         [ 0.1241, 10.6501, -0.2571,  ..., -0.9505,  2.8453, -0.2681]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(13.3215, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(40.5735, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
BP administrator
iter = 4 reward = 1
final_logits =  tensor([[[ 0.1335,  4.1240,  0.8211,  ..., -1.0328,  0.7567, -0.2034],
         [ 0.1619,  5.5619, -0.1159,  ..., -4.5814, -0.7306, -3.2073],
         [ 0.1507, 11.6926, -0.2385,  ..., -2.5790, -1.4357, -1.1317]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7216, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6293, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  787,   762, 14567,   110,   151, 15265,  7788,   110,   105,   124,
            109,  2143,  1034,  1027,  3070,  6375,   127,   239,   270,   263,
            112,   225, 16036,   562,   109, 15737,  2584, 51128,   116, 10928,
           1034,   116,  3070,  2414,   148,  7646,   339,   698, 26680,   233,
          37399,   110,   108, 35493,   111, 23363,   110,   107,   110,   105,
            600,   480,   140, 12144,   110,   108,   155,   265,  7646,   110,
            108, 16837,   178,   649,   110,   108,  1132,   109,  2414,   114,
           4081, 15115,   110,   107,   343,  1263, 51128,   116, 10928,  7719,
            180,   138,  4428,   169,  1162,  3070,   260,   559,   111,   118,
            149,   117,   146,   114,   710,  5135,   110,   108,   155,   114,
            729,   121,  4109,   156,   110,   107,   202,   729,  1034,   116,
            419,   112,   133,   114,   715,   110,   108,   181,   660,   113,
            523,   134,   109,   370,   113,   109,  8483, 16837,  4645, 16848,
           2584, 51128,   116, 10928,  7915, 25996,   110,   105,  2184,  6021,
            134,   214,   173,   145,   416,   136,   762, 14567,   256,   129,
           3150,   197, 23363,   110,   108,   155,   145,   114,   457,  3178,
            131,   144, 34742,   110,   108, 16837,   178,   649,   110,   107,
            398,   178, 41593,   164,   114,  1124,  2944,   113,  9606,  6545,
            115,   109,  2414,  1034,   116,  7270,   110,   108,  2584,   649,
            178,   117,  5238,   120,   109, 14567,   138,   129,   289, 13502,
            118,   223,   200,   115,   136,  3820,   121, 23623,  3070,   427,
            113, 38584,  1946, 11958,   144,   216,   110,   108,  7915, 29546,
           3070,   148,   174,  7162,   115,  7915,   262,   113,   109, 14567,
          10250,  1034,   116,  1750,   110,   108,  1946, 74523,   110,   108,
           5765,   122,   342,   111,  2779,   112,  7904,   110,   107,   110,
            105, 15265,   117,   169,   271,   110,   108,   347,   126,   178,
            358,  3178,   131,   144,   235,   742,   997,   110,   108, 16837,
            265,   649,   110,   107,   110,   105,   285,  1034,   116, 13735,
            110,   107,   285,  1034,   116,  7432,   134,   488,   110,   107,
            285,  1034,   116,   146,   109,   310, 29546,   420, 15538, 90155,
            110,   151,   110,   105,   168,   978,   172,   114, 10447,  1120,
            279,   264, 16837, 16036,   148, 20350,  5478,   113, 63981,  7881,
            333,   109,  7175,   113,  3064,   762, 14567,   110,   108,   155,
            186,   127,   274,   170,   127,  1192,   126,  2773,  7427,   118,
            109,   201,   126,   117,   557,   110,   108,  6260,   109,  6442,
           1034,   116,  6869,  3544,   115,  7915,   110,   107, 46095,   126,
            110,   108,   155, 16036,   117,   146,   114,  6749,  1172,   264,
            115,   109,  6805,  1120,   113,  7026, 63116, 58439,   110,   107,
            222,   109, 10601,  1034,   116,   629,   110,   108, 14515,   429,
            115,   114,  1120,  4511,   120,   117,   239,   163,   238,   112,
          16036,  1034,   116,   648,   115,   136,   297,   113,  7915,   110,
            108,   623,   391,  1725,  2051,   279,   115,  4555,   523,  1490,
          21955,  8802,   110,   107,   110,   105,   184,  1034,   216,   146,
            314,   785,   118,  1609,   126,   110,   108,   155,   264, 16036,
           1034,   116,   557,   234,   110,   108, 16837,   156,   649,   110,
            107,   353,  1034,   116,   956,  2158,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)
Louisiana has a huge gulf gulf between the Gulf Coast and
iter = 0 reward = 4
final_logits =  tensor([[[ 0.1179,  4.0788,  0.6431,  ..., -1.6537, -0.9916, -2.4612],
         [ 0.1218,  2.1941, -0.1341,  ..., -1.4500, -1.0753, -1.1696],
         [ 0.1301,  1.8795, -0.0505,  ..., -2.7238, -1.3685, -1.9501],
         ...,
         [ 0.1192,  4.5746,  0.1730,  ..., -4.8402, -3.3114, -0.3339],
         [ 0.1044,  5.3085, -0.3687,  ..., -3.5266, -1.8384, -0.7518],
         [ 0.1101,  8.6366, -0.3855,  ..., -3.6609, -2.0783, -1.3114]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.1329, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.0530, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1606,  9.1595,  0.9955,  ..., -1.1811, -1.0561,  0.1751],
         [ 0.1414,  9.7414,  0.4870,  ..., -2.2795, -1.3602, -0.6163]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.0464, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.9122, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Whisper Whisper Whisper Whisper Whisper
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1181,  4.8559,  1.2145,  ..., -2.4863,  1.5579, -0.6866],
         [ 0.0829, 13.2519,  0.2776,  ..., -0.9599,  1.6665, -1.1049],
         [ 0.0830, 13.3712,  0.1959,  ..., -0.7730,  1.3364, -0.7332],
         [ 0.0826, 13.3307,  0.1422,  ..., -0.4910,  0.6762, -0.2473],
         [ 0.0821, 13.3685,  0.1105,  ..., -0.4232,  0.4684, -0.0937],
         [ 0.0812, 13.4039,  0.0882,  ..., -0.3663,  0.3214,  0.0577]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4058, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.9474, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1306,  8.3350,  1.0719,  ..., -2.5294, -1.2100, -0.3602],
         [ 0.1260,  9.9209,  0.5165,  ..., -3.6868, -1.6045, -1.1139]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.2071, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.0840, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1411,  9.1284,  0.9253,  ..., -3.1177, -1.8877,  0.7126],
         [ 0.1264,  8.6102,  0.4840,  ..., -3.9710, -1.7509,  0.1790]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-7.6563, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.6915, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  608,  1338,  2652,  2882,  2033,   134,   305, 91516, 17403,  4596,
            202,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   115,   109,  7175,   113,  3064,   110,   108, 16036,
            649,   110,   107,   983,  3244,  2777,   165,   141, 16036,   649,
            126,   140,  1470,   115,   297,   118,   109,  5135,   110,   108,
            155,   163,  1262,   181,  6511,   124,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,   608,
           1338,  2652,  2882,  2033,   134, 71437, 17403,  4596, 16036,   148,
           1788,   114,  1933,   545,   162,   939,   109,   301,  1034,   116,
            700,   113,   702,   964,   164,   112,   109,  7175,   113,  3064,
            762, 14567,   110,   107,  2973,   112,   109,   301,   110,   108,
            114,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   110,   107,   983,  3244,  2777,   165,   141, 16036,
            243,   120,   126,   140,  1470,   115,   297,   118,   109,  5135,
            110,   108,   155,   126,   163, 17188,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4140 out of 11019)

Everytime after generating next logits 37.6% (4142 out of 11019)

Everytime after generating next logits 37.6% (4142 out of 11019)
Last September
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1260,  4.9044,  0.8092,  ..., -3.0412, -2.0595, -0.6981],
         [ 0.1201,  6.7714,  0.0148,  ..., -0.8458, -0.5378, -0.0181],
         [ 0.1080, 12.7545, -0.3025,  ..., -0.6991, -1.0929, -1.2506]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1232, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(14.1589, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
Last September
iter = 1 reward = 0
final_logits =  tensor([[[ 1.3460e-01,  6.2914e+00,  7.3575e-01,  ..., -2.7234e+00,
          -1.0977e+00, -2.7516e-01],
         [ 1.3603e-01,  7.2653e+00,  1.9930e-01,  ..., -2.8632e+00,
          -8.4189e-01, -7.1287e-04],
         [ 1.2375e-01,  1.1228e+01, -2.3575e-01,  ..., -2.1712e+00,
          -1.1548e+00, -1.1595e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.7164, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.8309, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
Gulf
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1245,  4.0223,  0.5478,  ..., -3.4115, -2.6143, -0.6343],
         [ 0.1292, 10.2299, -0.0366,  ..., -2.3466, -2.9427, -0.0122]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2213, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7991, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Last September
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1356,  5.7678,  0.7700,  ..., -2.7775, -1.8761, -0.3052],
         [ 0.1341,  6.7823,  0.0448,  ..., -0.9682, -1.3917, -0.6341],
         [ 0.1301, 12.1494, -0.2000,  ..., -0.8470, -2.4748, -1.6736]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0003, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6526, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
Last September
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1420,  6.5731,  0.9361,  ..., -1.8548, -0.8033,  0.0913],
         [ 0.1358,  6.4356,  0.0781,  ..., -0.8280, -1.5721, -0.4951],
         [ 0.1398, 10.9174, -0.1492,  ..., -1.1088, -2.5880, -1.9803]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1919, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2051, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  530,  1268,  2651,  2882,  2033,   134, 80621, 17403,  4596, 25688,
            115, 16036,  1963,   902,   124,  1789,  2409,   114,   787,  7501,
           5268, 79701,   109,   762,   301,  1034,   116,  4206,   111, 12856,
            130,   210,   130, 16036,   118,   109,  7175,   113,  3064,   762,
          14567,   110,   107,   139, 11335,   134,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,  1024,   111,  1358,   112,   109,  1368,
            521,  9134,   762,  8186,   110,   107,  4987,   109,  4469,   110,
            108, 16036,  2853,  3947,   607,  2527,   110, 43995,   118,   109,
            211,   166,   381,   913,   289,   232,   110,   107,  6442,   260,
          21089, 80736, 82734,  4278,  3886,   112,  5930, 37313,   110,   108,
            142,   762,  8962,   122, 85411,   116,  1714,   208, 59297, 20185,
            110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
Last Thursday,
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1505,  4.7523,  0.9985,  ..., -2.3235,  2.0744, -0.3492],
         [ 0.1380,  6.2008,  0.2557,  ...,  0.4750,  1.5786, -0.9096],
         [ 0.1627,  5.1277, -0.0781,  ..., -2.3140,  0.7482, -1.8354],
         [ 0.1472,  9.3367,  0.2985,  ..., -1.0110,  0.6589, -1.4738]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1083, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8618, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)
Last Thursday, Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater 500 shares were up
iter = 1 reward = 8
final_logits =  tensor([[[ 0.1683,  4.8041,  1.1930,  ..., -2.3988,  1.8744,  0.4060],
         [ 0.1414,  2.7286,  0.3215,  ...,  0.1564,  1.8390, -1.0591],
         [ 0.1684,  1.4342,  0.0395,  ..., -2.3546,  1.3637, -2.0558],
         ...,
         [ 0.1298,  9.0017, -0.4856,  ..., -1.0037,  0.5598, -0.2958],
         [ 0.0941, 10.0462, -0.1292,  ..., -1.4384,  1.2881,  0.7053],
         [ 0.0929, 11.7336, -0.3542,  ..., -0.8461,  0.9534,  0.5822]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(13.3877, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(48.6135, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)
Last Thursday, Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater Deepwater oil spill killed contractors
iter = 2 reward = 15
final_logits =  tensor([[[ 1.4660e-01,  5.3417e+00,  1.1613e+00,  ..., -1.8341e+00,
           1.2970e+00,  1.7258e+00],
         [ 1.4186e-01,  2.9758e+00,  2.4043e-01,  ...,  9.2333e-03,
           1.6575e+00, -4.1561e-01],
         [ 1.5385e-01,  1.8210e+00, -5.2808e-02,  ..., -2.9255e+00,
           8.3116e-01, -1.5145e+00],
         ...,
         [ 1.3350e-01,  6.8071e+00, -3.3810e-01,  ..., -1.6639e+00,
           7.5245e-01, -1.0566e+00],
         [ 1.0490e-01,  8.7242e+00, -3.4843e-02,  ..., -1.7728e+00,
           1.2204e+00, -1.0100e+00],
         [ 1.3702e-01,  1.1679e+01, -2.1172e-01,  ..., -8.9767e-01,
          -2.8823e-01,  1.8779e-02]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(14.7408, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(82.8113, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.5% (4238 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.6% (4250 out of 11019)

Everytime after generating next logits 38.7% (4264 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 38.8% (4278 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.3% (4328 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.4% (4346 out of 11019)

Everytime after generating next logits 39.6% (4366 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
Gulf shares share share share up up up up up up up up up up up up up up up to up to up to up to the last January January, after the last last last last last last last last last last last last January, up up to 
iter = 3 reward = 1
final_logits =  tensor([[[ 0.1627,  6.4714,  1.3420,  ..., -2.2532,  0.8392,  1.0282],
         [ 0.0842,  5.1049,  0.3556,  ..., -2.8611, -0.7342, -1.6023],
         [ 0.1217,  4.8908,  0.1196,  ..., -2.2231, -2.0304, -1.5154],
         ...,
         [ 0.0932,  7.2223, -0.3704,  ..., -2.2515,  1.1024, -0.4549],
         [ 0.0804,  7.1851,  0.0109,  ..., -2.6967,  1.8153, -0.7239],
         [ 0.1021, 10.3585,  0.7154,  ..., -2.5206,  1.8020,  0.4926]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3473, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1752, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)

Everytime after generating next logits 39.0% (4292 out of 11019)
BBC correspondent Maryam Bentley led Gulf contractors up up to
iter = 4 reward = 2
final_logits =  tensor([[[ 1.3480e-01,  5.2514e+00,  1.1358e+00,  ..., -3.1566e+00,
           1.3173e+00,  3.6140e-01],
         [ 7.7880e-02,  3.6586e+00,  3.2897e-01,  ..., -3.7331e+00,
          -7.9316e-01, -2.8945e+00],
         [ 9.3276e-02,  4.4190e+00,  9.5479e-02,  ..., -3.0530e+00,
          -9.4551e-01, -4.1618e-01],
         ...,
         [ 5.7722e-02,  6.5000e+00,  2.9660e-02,  ..., -9.0017e-01,
          -7.5598e-01,  6.1429e-01],
         [ 6.0946e-02,  7.6540e+00, -1.8044e-03,  ..., -6.6394e-01,
          -3.9796e-01,  6.1799e-01],
         [ 7.7242e-02,  1.1024e+01,  6.8339e-02,  ..., -6.3351e-01,
           6.5777e-01, -3.7229e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.6810, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.0189, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[ 3788,   110,   108,   258,   111,  1183,   109,  4193,   120,  5887,
            119,  3788, 22017,  3249,  2309,   114,  4340,   132,  2162,   110,
            108,   132,   989,  6502,   115,   150,   545,  1771,  6180,   114,
           4340,   493,   126,   586,   112,   258,   165,   241,   111,   173,
            157,   133,  6502,   110,   107, 14845,   127,  1661,   115,   156,
            295,   110,   108,  2063,   119,  1235,   111,   400,   489,   110,
            107, 21556,   116,  4170, 16036,   762, 14567,  1736,   651,  1265,
           1185,  2652,   110,   108,  3013,   111,  9792,  5297,  5299,  2346,
           3601,  2567,  7499,   114,  1736,   266,  1678,   115,   109, 11319,
            124,   109, 16036,   762, 14567,   110,   107,  2346,  3601,  2567,
            898,  6949,   120,   142,  8635,   933,   113,  1647,   196,   506,
            174,  9889,   110,   108,   155,   701, 51098,   192,   129,   656,
            130,  6031,  1219,   115,  4190,  6500,  3381,   113, 43278,   110,
            107,   139,   657,   148, 18097,   112,   110,   105,   543,   109,
           2919,   113,   219,  6209,   702, 16837,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
Lordland has pledged to a deeper vigilance and
iter = 0 reward = 0
final_logits =  tensor([[[ 1.7621e-01,  6.2893e+00,  1.2814e+00,  ...,  1.1417e+00,
           4.6898e-02,  1.8890e+00],
         [ 1.3143e-01,  4.8679e+00,  6.2908e-01,  ..., -2.8328e-01,
          -1.6753e+00,  1.8460e+00],
         [ 1.3860e-01,  4.0433e+00,  8.0009e-03,  ..., -9.7015e-01,
          -2.8795e+00,  2.0860e+00],
         ...,
         [ 5.1968e-02,  6.5848e+00,  2.2344e-01,  ...,  9.5230e-01,
          -1.4575e+00,  1.7457e+00],
         [ 9.6578e-02,  9.1373e+00, -4.7091e-01,  ..., -1.1351e+00,
          -2.0567e+00,  1.2319e+00],
         [ 8.4600e-02,  1.0520e+01, -1.6756e-01,  ..., -1.0155e-01,
          -2.3603e+00,  5.6801e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.2595, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.9682, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
June June June June June June June Lords Lords Lords
iter = 1 reward = 7
final_logits =  tensor([[[ 0.2105,  5.3527,  1.4098,  ...,  0.7675,  1.1907,  0.3315],
         [ 0.1732,  5.7562,  0.7609,  ...,  1.7645,  0.3316, -0.6899],
         [ 0.1728,  5.9204,  0.7222,  ...,  1.5834,  0.1018, -0.9528],
         ...,
         [ 0.1707, 10.6070,  0.5535,  ...,  0.9776, -0.8958, -1.0605],
         [ 0.1678, 11.5790,  0.4517,  ...,  0.8879, -1.0427, -1.0931],
         [ 0.1647, 12.2337,  0.3723,  ...,  0.8681, -1.1391, -1.0653]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.7580, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.6952, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Climate
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1904,  2.6640,  1.0867,  ..., -0.3233,  2.0531,  0.4540],
         [ 0.1168, 12.5676,  0.1704,  ...,  0.3347, -1.4317,  0.4753]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.5453, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(13.3864, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
On
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1698,  2.2505,  0.9688,  ..., -1.0699,  1.7535, -0.4580],
         [ 0.1480, 10.3077,  0.1543,  ..., -2.2922,  0.2371, -1.4935]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.9255, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.7033, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
On
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1861,  3.2844,  1.1207,  ...,  0.5973,  2.3363,  0.9440],
         [ 0.1548, 10.4741,  0.1182,  ..., -1.6853,  0.3829, -1.0792]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.9733, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(42.8167, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1428,  1307,  2652,  2882,  2033,   134, 84838,   726, 17403,  4596,
          16036,   148,  1939,   114,   177, 14464,  3889,   124,   109, 14154,
           7175,   113,  3064,   762,   210,   110,   108,   301,  2662,   416,
            110,   107,   168,   117,  8549,   109,   177,  3889,   138,   923,
            109,  8186,   111,  3155,   109,   762,   269,   154,   113,   126,
            137,  6218,   190,   109,  1917,   155,   126,   256,   129,   372,
            228,   390,   269, 16036,   235,   682,   109,   807,  2353,   117,
           1147,   110,   107,   139, 11335,   113,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,   200,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Gulf
iter = 0 reward = 1
final_logits =  tensor([[[ 0.0975,  4.7293,  0.8230,  ..., -3.3952,  1.5850,  1.3055],
         [ 0.0932, 10.5596, -0.0182,  ..., -2.2779, -0.3864, -0.5782]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-10.0469, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(44.2155, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Last Gulf Gulf has killed killed killed killed killed
iter = 1 reward = 2
final_logits =  tensor([[[ 0.1336,  7.9587,  1.2320,  ..., -2.9277,  0.5563,  2.1565],
         [ 0.1411,  6.7336,  0.3347,  ..., -1.3360,  0.8582,  1.5854],
         [ 0.1410,  8.5241,  0.0426,  ..., -1.8804, -0.7410,  0.4272],
         ...,
         [ 0.1328,  8.6379,  0.1105,  ..., -2.3218,  0.9938,  1.1025],
         [ 0.1302,  9.3443,  0.0921,  ..., -2.4875,  1.0295,  1.0750],
         [ 0.1283, 10.0681,  0.0795,  ..., -2.5058,  0.9957,  1.0576]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4233, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2388, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Last Gulf 13 people have killed killed in the last stop to
iter = 2 reward = 1
final_logits =  tensor([[[ 9.4461e-02,  4.4295e+00,  8.0577e-01,  ..., -3.5023e+00,
           7.4523e-01,  1.1169e+00],
         [ 8.6830e-02,  3.2065e+00,  2.8780e-02,  ..., -2.7463e+00,
           8.2768e-01,  5.6242e-01],
         [ 7.4645e-02,  3.2702e+00,  5.9206e-02,  ..., -2.4136e+00,
          -1.7853e+00, -4.1908e-01],
         ...,
         [ 1.2135e-01,  6.6181e+00, -2.3505e-01,  ..., -1.5256e+00,
           1.4158e+00,  7.4331e-01],
         [ 9.4926e-02,  4.0971e+00, -5.6868e-01,  ..., -1.9265e+00,
           5.6125e-03,  3.9032e-01],
         [ 8.9783e-02,  9.4828e+00, -2.3523e-01,  ..., -1.3802e+00,
           7.8087e-01,  1.1046e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7835, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4610, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
Last last last
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1395,  8.1024,  1.0641,  ..., -2.6714,  0.1238,  0.2753],
         [ 0.1406,  7.9663,  0.1866,  ..., -2.3433,  1.1047,  0.7063],
         [ 0.1306,  8.5852, -0.0505,  ..., -2.9118,  0.3926,  0.3126],
         [ 0.1300,  9.4818, -0.1143,  ..., -2.7900,  0.3321,  0.1474]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4110, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3765, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
Last July
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1434,  7.9195,  1.0612,  ..., -2.1163,  0.5763, -0.1289],
         [ 0.1493,  7.6962,  0.1836,  ..., -1.6592,  1.2585,  0.5337],
         [ 0.1240, 11.1006, -0.0937,  ..., -1.0143,  0.1128, -0.4732]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.1020, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4382, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   762, 14567,   114,   711,   113,   110,   105,  2111,  1057,
            395,  1034,   139, 21549, 16036,   762, 14567,   115,   109,  7175,
            113,  3064,   148, 50233,   109,  4170,   160,  3079,   644,  2175,
            110,   108,   155,   109,  1319,  1977,   113, 11461,   649,   109,
          14567,   140,   109,   711,   113,  1025, 46366,   110,   107,  1084,
          44907, 41534,   140,  1977,   113, 11461,  1034,   116,   655,   260,
            135,  5109,   112,  3390,   111,   148,   243,   223,   644,   524,
            632,   112,   823,   114,   110,   105, 30493,   824,   113,   109,
           2379,   110,   107, 16837,   125,   116,  1086,   734,   112,   145,
           1321,  1110,   299,   114,   300,   121,  1704,  6030,   112, 11881,
          13922,   110,   152,   325,   117,   461,   762,   297,   113,   109,
            951,   110,   108,   132,   109,   575,   110,   152,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1722,  6.0989,  0.7069,  ..., -2.8728,  0.4151, -2.3906],
         [ 0.1449, 12.7451,  0.1806,  ..., -2.1777,  0.1661, -2.2933]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8250, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3472, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
The 2008
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1837,  5.7905,  0.5724,  ..., -2.3102,  0.6617, -2.2771],
         [ 0.1600,  9.4786,  0.2008,  ..., -2.5049,  0.3057, -1.9280],
         [ 0.1637, 13.1899, -0.1113,  ..., -2.3393, -0.0485, -1.7513]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7123, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2321, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The 2008
iter = 2 reward = 0
final_logits =  tensor([[[ 0.2466,  7.3786,  1.0089,  ..., -2.3481,  0.4631, -0.8022],
         [ 0.2036, 10.2946,  0.5711,  ..., -3.3498,  1.1528, -1.4255],
         [ 0.2170, 12.7973,  0.2765,  ..., -2.5305,  0.0965, -1.2655]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.5536, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.3560, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The 2008
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1612,  6.2527,  0.7837,  ..., -2.8286, -0.2976, -0.7169],
         [ 0.1396,  6.7405,  0.2736,  ..., -3.1421, -0.0241, -0.8903],
         [ 0.1350,  9.0459,  0.0668,  ..., -2.6837,  0.0505, -0.7137]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3521, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8691, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
2008 
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1550,  6.0383,  0.8981,  ..., -4.0691,  0.2692, -0.9052],
         [ 0.1056,  8.3359, -0.0685,  ..., -2.8607, -0.3237, -1.8967],
         [ 0.1188, 13.0190,  0.3423,  ..., -2.4543, -1.0238,  0.0748]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1379, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8043, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1346,  6661,   118,   762, 14567,   945,   139,  2800,  1728,   112,
           2555,   110,   105, 41638, 16837,  1003,   121,   768,  1739,   120,
            133,   174,   263,   115,   109,  7175,   113,  3064,   139,  1346,
           6661,  2800,   110,   108,   229,   606,   118,  6957,   109,   808,
          70959,   503,   110,   108,   148,  2365,   114,  3662, 13602,   604,
            762,  1003,   121,   768,  1459,   110,   107,   139,  2800,   110,
            108,   162,  1653,   120,   203,  1962,  2560,   117,   110,   105,
            112,   650,   160,  8695, 33237,   118,   109,  1280,   113,  7633,
          16837,  1487,   203,   807,  4086,   134,   114,  1833,  1792,   115,
           1741,  3710,   110,   107,   182,   117,   203,  6932,   110,   105,
            698,  9501,  1702, 16837,   110,   107,  1810,  1518,   137,  2337,
            118,   109,  1702,   430,   960,  2651,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
X-
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0855,  5.2064,  0.8785,  ..., -2.3480, -0.6576, -3.1449],
         [ 0.0698,  7.0813, -0.0305,  ..., -2.2261, -1.5993, -2.7344],
         [ 0.0675,  9.7074,  0.4299,  ..., -0.6260, -1.3410, -2.6697]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2591, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.6753, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
X-up
iter = 1 reward = 0
final_logits =  tensor([[[ 9.0042e-02,  4.9283e+00,  6.7525e-01,  ..., -2.0430e+00,
           4.3166e-02, -3.4342e+00],
         [ 3.6865e-02,  6.8356e+00, -4.5966e-02,  ..., -3.5077e+00,
          -2.3592e+00, -2.4247e+00],
         [ 7.5810e-03,  8.8810e+00,  4.5509e-01,  ..., -1.9395e+00,
          -1.7156e+00, -1.6308e+00],
         [ 7.1182e-02,  1.1365e+01, -4.2473e-01,  ..., -1.4718e+00,
          -2.1676e+00, -3.3909e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3184, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.1151, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)
X-up
iter = 2 reward = 0
final_logits =  tensor([[[ 8.7837e-02,  4.8892e+00,  6.6334e-01,  ..., -2.1636e+00,
          -3.6052e-02, -2.8121e+00],
         [ 3.9697e-02,  6.3458e+00, -5.8144e-04,  ..., -3.3047e+00,
          -2.3319e+00, -1.7227e+00],
         [-9.2135e-04,  7.9892e+00,  4.1612e-01,  ..., -2.1410e+00,
          -1.8885e+00, -5.4993e-01],
         [ 6.7319e-02,  1.0309e+01, -4.7552e-01,  ..., -1.6758e+00,
          -2.4485e+00, -2.7340e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3743, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6064, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)
X-up
iter = 3 reward = 0
final_logits =  tensor([[[ 8.9086e-02,  4.9239e+00,  6.5118e-01,  ..., -2.0977e+00,
           2.2991e-01, -2.6650e+00],
         [ 4.1823e-02,  5.9025e+00,  4.7650e-02,  ..., -3.1478e+00,
          -2.2189e+00, -1.3912e+00],
         [-4.8991e-03,  7.3511e+00,  4.5713e-01,  ..., -2.1330e+00,
          -1.9679e+00, -2.1769e-01],
         [ 6.8565e-02,  9.2502e+00, -5.2718e-01,  ..., -2.0088e+00,
          -2.5673e+00, -2.5884e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1722, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5585, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)
X-up is the X-
iter = 4 reward = 0
final_logits =  tensor([[[ 8.5008e-02,  4.3421e+00,  5.4634e-01,  ..., -2.1970e+00,
           3.6787e-01, -2.6518e+00],
         [ 4.2861e-02,  5.1651e+00,  6.5751e-02,  ..., -3.0532e+00,
          -2.0218e+00, -1.4742e+00],
         [-7.5646e-03,  6.4820e+00,  4.4275e-01,  ..., -2.4972e+00,
          -2.1157e+00, -3.8236e-01],
         ...,
         [ 6.1828e-02,  8.3347e+00, -3.5131e-01,  ..., -1.0964e+00,
          -7.4442e-01, -1.5088e+00],
         [ 5.9507e-02,  6.8159e+00, -1.6098e-01,  ..., -2.8786e+00,
          -1.4414e+00, -1.4586e+00],
         [ 1.0825e-02,  9.9123e+00,  7.4792e-02,  ..., -1.7754e+00,
          -1.6586e+00, -1.1080e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3845, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5630, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3211,  1307,  2652,  2882,  2033,   134,   280, 85536, 17403,  4596,
            398, 16036,  1034,   116, 11599,  2664,   109,   519,   113,   114,
           6033,   124,  9134,  9600,   110,   108,   109, 12220,   113, 14645,
           9727,   135,   109,   762, 14567,   115,   109,  7175,   113,  3064,
            148,  9380,   164,   115,   114,  2043, 22369,   115, 10792,   110,
            107,   353,  1761,  7690,   355,  1854,   199,   109, 18191,   113,
          14645,   246,   129,  8626,   122,   110,   107,  9903, 90966,  1574,
            135,   351,   859,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1750,  7.1331,  1.2758,  ...,  2.3103,  0.0640,  1.4189],
         [ 0.1218,  9.7410,  0.6983,  ...,  0.6985, -0.0437,  0.5534]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.6190, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.2842, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Lawsuit
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1333,  5.1571,  1.1641,  ...,  1.3578, -0.9541,  2.0378],
         [ 0.0975, 12.1510,  0.0911,  ...,  1.0911, -0.0715, -0.5094]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.9033, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.6254, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Lawsuit
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1763,  6.6245,  1.4681,  ...,  1.8820, -0.7655,  2.1083],
         [ 0.1132, 11.8036,  0.2892,  ...,  1.0852,  0.2190,  0.8556]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.0434, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.1750, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1531,  7.8954,  1.1620,  ...,  1.8380,  0.1831,  1.5582],
         [ 0.1073, 10.2862,  0.6435,  ...,  0.8113,  0.4456,  0.9067]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.4633, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.1836, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1590,  8.4765,  1.0783,  ...,  1.8844,  0.5496,  2.1531],
         [ 0.1115, 10.3628,  0.5209,  ...,  1.0495,  0.5828,  0.7637]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.0634, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.8724, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 2571,  1508,  2652,  2882,  2033,   134,   305, 49218, 17403,  4596,
            222,  6358,   109, 40522, 34524,  4820,   164,   299,  4027,  1034,
            116, 62223,   454,  3682,  3793,   156,   113,   109,   278,  1034,
            116,  3741,   762, 12802,   110,   107,  1478,   115,   109,  5569,
            110,   108,  3070,   111,   176,  3217, 17659,   109,  1322,   192,
            394,  5097,   110,   107,   343, 62223,   148,   174, 71731,   115,
            109,  1965, 43983,   231,   110,   108,   112,   253,   142,  4156,
            120,   126,   117,   744,   130,   175,   109,  2648,   394,  2032,
            110,   107,   168,   117,  8549, 62223,  1034,   116,   584,   256,
            319,  2520,   118,   274,   115,   109,  7175,   113,  3064,   170,
            127, 48322,   120,   157,   138,   521,  5097,   135,   109,  2926,
          16036,   762, 14567,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1]]])}

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Galicia
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1167,  6.0848,  0.6134,  ..., -3.9049, -0.1520, -4.0188],
         [ 0.0921, 11.7847,  0.0690,  ..., -2.6468, -2.2968, -3.1814]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.6910, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(13.3524, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
Gulf tourism tourism tourism tourism tourism tourism in
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1607,  7.0360,  1.1747,  ..., -2.7628,  0.0483, -2.5868],
         [ 0.1223,  7.3058,  0.2592,  ..., -3.5209, -2.2084, -1.8673],
         [ 0.1121,  5.6351, -0.2864,  ..., -5.2526, -2.4476, -1.9338],
         ...,
         [ 0.1193,  7.4852, -0.4226,  ..., -4.7126, -2.2178, -2.3362],
         [ 0.1214,  8.0314, -0.4352,  ..., -4.5256, -2.1812, -2.4719],
         [ 0.1114, 11.5426, -0.1472,  ..., -2.3194, -2.0333, -2.0211]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.5456, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.6856, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Gulf tourism tourism tourism tourism tourism tourism tourism
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1634,  6.8170,  1.2375,  ..., -3.0129, -0.2590, -2.4497],
         [ 0.1212,  8.2166,  0.2511,  ..., -3.6764, -2.2190, -1.7169],
         [ 0.1084,  6.7444, -0.2792,  ..., -5.4576, -2.3380, -1.7188],
         ...,
         [ 0.1109,  8.7309, -0.4520,  ..., -4.7830, -2.1004, -1.9902],
         [ 0.1123,  9.2622, -0.4719,  ..., -4.6021, -2.0734, -2.0886],
         [ 0.1141,  9.9321, -0.4881,  ..., -4.3200, -2.0240, -2.1133]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2308, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6687, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Galicia
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1118,  6.1497,  0.8223,  ..., -4.2073, -1.0687, -2.2235],
         [ 0.0930, 11.9277,  0.0543,  ..., -1.5525, -2.0898, -1.9322]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5804, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.3321, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Gulf tourism tourism
iter = 4 reward = 1
final_logits =  tensor([[[ 0.1198,  6.3977,  1.0822,  ..., -3.7462, -1.1227, -1.8300],
         [ 0.0972, 11.0749,  0.3597,  ..., -4.2657, -2.0759, -1.8823],
         [ 0.0953,  9.5725, -0.1788,  ..., -4.9594, -3.1187, -1.7582],
         [ 0.0960, 11.0326, -0.2561,  ..., -4.0989, -2.9273, -1.6634]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.0401, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.1842, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  787, 17984,   116, 16036,   204,  7175,   113,  3064,   762,  5135,
           1195,  1408,  2652,  2882,  2033,   134, 79386,   914, 17403,  4596,
            139,   706,  1013,   117,   112, 17984, 16036,   111,  1965,   176,
            524,   204,   114,  1124,   762, 14567,   115,   109,  7175,   113,
           3064,   110,   107,   139,   657,   243,   126,   192,  1137,   109,
           3358,  1069,  9873,   118,   109, 13353,   113,  2729,  1363,   124,
           1496,   164,   109,  3741,  2249,  5135,   115,   787,   689,   110,
            107, 36347,  1024,  2342,   115,   109, 11335,   124,   109, 81065,
          18308,  9600, 13773,   115,   960,   110,   107,   139,  6442,  1034,
            116, 55065, 66707,  1574,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1]]])}

Before Sampling 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)
Gulf
iter = 0 reward = 1
final_logits =  tensor([[[ 0.0872,  4.7533,  0.8806,  ..., -3.5043,  0.8342,  0.2371],
         [ 0.1007, 12.6077, -0.1312,  ..., -0.9481, -0.5360, -0.8955]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.7628, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.0322, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
BBC
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1088,  5.5908,  0.9621,  ..., -4.1910,  0.2489,  0.3312],
         [ 0.0982, 12.6784,  0.0673,  ..., -0.2395, -0.5548, -0.9533]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2263, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2493, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
BBC
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1157,  5.8095,  0.9803,  ..., -4.4582, -0.0902,  0.2609],
         [ 0.0953, 12.8232,  0.1073,  ..., -0.5600, -0.8135, -0.9540]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2693, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
Iain MacKenzie
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1155,  5.8422,  0.9680,  ..., -4.3205, -0.2330,  0.2563],
         [ 0.0930, 11.6342,  0.0887,  ...,  0.9503, -0.9510, -1.6680],
         [ 0.0891, 12.5291, -0.2227,  ...,  0.4117, -0.9434, -0.2425]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8536, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.7447, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
Eleven Eleven
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0983,  5.5976,  0.9090,  ..., -3.9636, -0.8072,  0.4925],
         [ 0.0700, 11.5332,  0.2255,  ..., -2.5580, -1.4695, -0.8073],
         [ 0.0686, 12.3036,  0.1750,  ..., -2.3514, -1.1962, -0.8313]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.3495, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.5565, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 7915, 26939,  4355,  1194,   244, 16036,   762, 14567,  5823,  8437,
            117,   364,   109, 19954,   113,   109,  7175,   113,  3064,   235,
            149,   314,   210,   110,   107,   139,   908,   317,  6299,   111,
           1174,   117,  8988,   153, 19347,   578,   110,   107,   343,   136,
            232,   205,   113,   109, 27736,   127,  2609,   110,   107,   139,
          27736,   127,   146,  1622,   115,   762,   110,   108,   130,   109,
           6442,  1034,   116,  2040,  9518,  1574,   135,  7915,   110,   108,
            155,  3040,   299,   141,  2926, 21615, 22611,   116,   120,   195,
           2443,   112,  2512,   109, 15737,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1128,  5.6901,  1.0196,  ..., -0.8286, -0.4417, -0.7300],
         [ 0.1019, 12.5118,  0.4742,  ..., -1.3954, -1.1272, -1.2530]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.6598, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.0144, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Louisiana
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1134,  5.2486,  0.9437,  ..., -1.3734, -1.8815, -0.5672],
         [ 0.1309, 13.1374,  0.1414,  ..., -0.9901, -2.1508, -0.9890]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2368, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.4559, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
The Louisiana
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1356,  6.1462,  1.0575,  ..., -2.2795,  0.0633, -0.1191],
         [ 0.1253, 10.5135,  0.8031,  ..., -2.4487, -0.5320, -0.0350],
         [ 0.1415, 12.8185,  0.3611,  ..., -1.2507, -1.1880, -0.9009]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4389, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3878, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4176 out of 11019)

Everytime after generating next logits 37.9% (4176 out of 11019)

Everytime after generating next logits 37.9% (4176 out of 11019)

Everytime after generating next logits 37.9% (4176 out of 11019)
The Louisiana
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1332,  5.9312,  0.9573,  ..., -2.2563, -0.2680, -0.3574],
         [ 0.1205, 10.3744,  0.7410,  ..., -2.0252, -0.5686, -0.1503],
         [ 0.1383, 12.9871,  0.2871,  ..., -1.0377, -1.2448, -1.3153]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0939, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5685, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)
Paul
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1353,  5.2149,  0.8529,  ..., -2.0613, -0.7578, -0.5327],
         [ 0.1307, 12.7022,  0.1288,  ...,  0.0917, -1.4533, -0.6422]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8318, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.0577, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
topic:  ('bpoil_bbc',)
env initialized...

Before training:  37.7% (4152 out of 11019)
{'input_ids': tensor([[[  110,   105,  3893, 15737,  1034,  8255,   464, 16036,   134,   109,
           1816,  2447,   139,  1816,  2447,   649,   126,   117,  4562,   112,
          16036,   118,   203,   337,   983,   762,   121,  2134,  5626,   148,
            174, 12832,   279,   156,   113,   109,  1816,  2447,  1034,   116,
          18072,   141, 10162, 18232,   126,   112,   370,   203, 10971,   818,
            122, 16036,   110,   107,   139,  4635, 41588,   110,   108, 50595,
          81452, 60490,   457,   131,   304,   110,   108,   117,   114,  4055,
          17225,   113,   114,   883,   693,   111, 28286,   111,   117,   160,
           6155,   231,   459,   110,   107,   202,   456,   568,  7200,  9221,
           3893,  2777,   165,   109,  8255,   110,   107,   202,   984,  8255,
           4635, 20678,  4329,   115,  1185,   110,   107,   139,  1816,  2447,
            243,   109,  5626,  1065,   140, 39059,   110,   108,   162,   196,
            146,  3954,   109,  4976,  2098, 11976,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
The substance was
iter = 0 reward = 0
final_logits =  tensor([[[ 2.3254e-01,  4.8401e+00,  9.3587e-01,  ..., -2.6784e+00,
           9.5224e-01,  1.3639e+00],
         [ 1.2783e-01,  9.3722e+00,  3.9185e-01,  ..., -3.2678e+00,
          -5.7065e-01,  8.4906e-01],
         [ 1.2349e-01,  1.0900e+01, -3.1341e-01,  ..., -2.6188e-01,
          -1.5232e+00, -2.2991e-01],
         [ 1.0419e-01,  1.1747e+01, -2.1387e-01,  ..., -1.0323e+00,
           1.0056e-02,  6.8075e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1956, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.2796, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)
The substance was
iter = 1 reward = 0
final_logits =  tensor([[[ 0.2378,  4.8799,  0.9465,  ..., -2.5775,  0.8465,  1.4600],
         [ 0.1277, 10.0276,  0.3847,  ..., -3.1394, -0.6715,  0.7393],
         [ 0.1262, 11.4546, -0.3224,  ..., -0.2741, -1.6651, -0.2896],
         [ 0.1079, 12.4308, -0.2233,  ..., -0.9234, -0.0894,  0.6635]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1078, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.3874, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)
The substance was
iter = 2 reward = 0
final_logits =  tensor([[[ 0.2503,  4.9262,  1.0382,  ..., -2.2711,  0.6653,  1.5322],
         [ 0.1278, 11.4104,  0.3530,  ..., -2.7812, -0.8763,  0.5177],
         [ 0.1249, 12.0909, -0.3321,  ..., -0.4862, -1.9182, -0.2700],
         [ 0.1088, 12.6602, -0.2237,  ..., -0.8148, -0.1851,  0.7310]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2752, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.9194, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
The substance was
iter = 3 reward = 0
final_logits =  tensor([[[ 0.2616,  5.0344,  1.1815,  ..., -2.0297,  0.2836,  1.3952],
         [ 0.1266, 11.6668,  0.3771,  ..., -2.6618, -1.0447,  0.4389],
         [ 0.1220, 12.0979, -0.3366,  ..., -0.6033, -2.0953, -0.2435],
         [ 0.1062, 12.6268, -0.2202,  ..., -0.8025, -0.2600,  0.7262]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2293, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.3412, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Hoa
iter = 4 reward = 0
final_logits =  tensor([[[ 0.2628,  5.1170,  1.2445,  ..., -1.9919, -0.1349,  1.4114],
         [ 0.1918, 13.2225,  0.6915,  ..., -0.1895, -1.1021,  0.0153]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0014, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3759, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 4123,   113,   219,  6234,   195,  6908,   115,   109, 75158,  1153,
           3893,  1419, 16036,   148,  6305,  3906,   142, 10580,   805,   113,
            203,  7175,   113,  3064,   762, 14567,  1407,  1104,   124,   203,
            387,   110,   107,   139,  1082,   110,   108,  1155,   204,   109,
           1339,   110,   108,   939,  1841,   115,   683,   113,   114,  1679,
            113,   461,  6234, 10361,  1055,   113,   203,  3954,   210,   124,
            109,  1917,  1030,   110,   107, 16036,  9619,  3582,  7217,   243,
            120,   339,  6234,   195,  6908,   115,   109,   856,  1153,   111,
          10390,   680,   196,   174,   263,   112,   535,  1055,   110,   107,
            139, 10580,   805,   140,  3530,   122,   109,   856,   244,   114,
            787,  9024,  8666,   126,   110,   107,  1263,  7217,   243,   109,
           4787,   170,   635,   109,  1153,   140, 10361,   169,   766,   122,
          10390,   680,   111,   186,   140,   220,  5313,  6596,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.3% (4216 out of 11019)

Everytime after generating next logits 38.3% (4216 out of 11019)

Everytime after generating next logits 38.3% (4216 out of 11019)
Three Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop
iter = 0 reward = 0
final_logits =  tensor([[[ 6.6734e-02,  5.9056e+00,  5.8412e-01,  ..., -8.7039e-01,
          -1.8398e+00,  1.5537e+00],
         [ 3.3570e-02,  3.9561e+00,  1.7913e-01,  ..., -3.7812e+00,
          -1.4497e+00, -2.6692e-01],
         [ 3.8315e-02,  4.8022e+00,  2.3044e-01,  ..., -1.5678e+00,
          -2.3324e+00, -1.4595e+00],
         ...,
         [ 4.9013e-02,  8.5955e+00,  2.2795e-02,  ..., -3.2911e+00,
          -3.2633e+00, -1.0920e+00],
         [ 4.9070e-02,  8.7007e+00,  1.4676e-02,  ..., -3.3583e+00,
          -3.2869e+00, -1.0781e+00],
         [ 4.9160e-02,  8.7853e+00,  8.7342e-03,  ..., -3.4112e+00,
          -3.3109e+00, -1.0561e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.8141, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.2958, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)
Three Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop
iter = 1 reward = 0
final_logits =  tensor([[[ 5.1324e-02,  5.0352e+00,  5.8752e-01,  ..., -1.5817e+00,
          -1.7136e-03,  1.2696e+00],
         [ 3.0541e-02,  4.7520e+00,  1.5927e-01,  ..., -3.4847e+00,
          -1.5755e+00, -5.7540e-01],
         [ 4.0681e-02,  6.7526e+00,  3.2182e-03,  ..., -2.1518e+00,
          -2.2854e+00, -1.6290e+00],
         ...,
         [ 5.2933e-02,  9.5111e+00, -3.5871e-02,  ..., -2.7224e+00,
          -3.2884e+00, -1.3458e+00],
         [ 5.2495e-02,  9.6077e+00, -3.3187e-02,  ..., -2.7411e+00,
          -3.2973e+00, -1.3341e+00],
         [ 5.1778e-02,  9.7214e+00, -3.7853e-02,  ..., -2.7504e+00,
          -3.3141e+00, -1.3153e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.0069, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.9569, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)

Everytime after generating next logits 38.6% (4248 out of 11019)
Three Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0513,  5.0839,  0.6315,  ..., -1.9897,  0.1571,  1.6866],
         [ 0.0255,  4.7191,  0.1656,  ..., -3.8229, -1.5392, -0.4852],
         [ 0.0306,  6.7291,  0.0343,  ..., -2.4403, -2.2807, -1.7562],
         ...,
         [ 0.0377,  9.4916, -0.0765,  ..., -3.4404, -3.4655, -1.1754],
         [ 0.0377,  9.6082, -0.0853,  ..., -3.4869, -3.4748, -1.1461],
         [ 0.0376,  9.7222, -0.0931,  ..., -3.5254, -3.4819, -1.1280]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1214, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6454, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.7% (4264 out of 11019)

Everytime after generating next logits 38.7% (4264 out of 11019)

Everytime after generating next logits 38.7% (4264 out of 11019)
Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop
iter = 3 reward = 0
final_logits =  tensor([[[ 5.1945e-02,  5.4537e+00,  7.0324e-01,  ..., -1.5108e+00,
           3.2883e-01,  1.8629e+00],
         [ 2.6849e-02,  5.5529e+00,  2.9599e-01,  ..., -2.4543e+00,
          -2.5269e+00, -1.8360e+00],
         [ 2.7419e-02,  5.6130e+00,  2.6334e-01,  ..., -2.5811e+00,
          -2.7030e+00, -1.7673e+00],
         ...,
         [ 2.7525e-02,  1.0085e+01,  2.0902e-02,  ..., -3.4763e+00,
          -3.4678e+00, -1.1408e+00],
         [ 2.7952e-02,  1.0309e+01,  7.7431e-03,  ..., -3.5238e+00,
          -3.4713e+00, -1.1344e+00],
         [ 2.8345e-02,  1.0609e+01, -5.0488e-03,  ..., -3.5659e+00,
          -3.4713e+00, -1.1311e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.2858, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.7576, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)
Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop Photoshop
iter = 4 reward = 0
final_logits =  tensor([[[ 4.8087e-02,  5.4611e+00,  7.4072e-01,  ..., -1.2131e+00,
          -9.4673e-04,  1.5792e+00],
         [ 3.1357e-02,  8.1853e+00,  4.2741e-01,  ..., -2.0061e+00,
          -2.3442e+00, -1.8498e+00],
         [ 2.9670e-02,  8.8312e+00,  3.6626e-01,  ..., -1.9251e+00,
          -2.4661e+00, -1.7165e+00],
         ...,
         [ 3.5100e-02,  1.0719e+01,  1.9736e-01,  ..., -2.0020e+00,
          -2.9705e+00, -1.5364e+00],
         [ 3.5681e-02,  1.1424e+01,  1.6248e-01,  ..., -2.0257e+00,
          -3.0445e+00, -1.5133e+00],
         [ 3.5987e-02,  1.2080e+01,  1.2235e-01,  ..., -2.0974e+00,
          -3.1111e+00, -1.4792e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4464, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.5171, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[599, 960, 110,  ..., 109, 804,   1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 39.3% (4332 out of 11019)

Everytime after generating next logits 39.3% (4332 out of 11019)
President
iter = 0 reward = 1
final_logits =  tensor([[[ 8.7262e-02,  4.3688e+00,  6.6605e-01,  ..., -1.2549e+00,
           3.4981e-01, -1.8072e+00],
         [ 8.0298e-02,  1.1101e+01, -7.2783e-02,  ..., -8.4062e-03,
          -8.5534e-01,  3.0289e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7936, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8528, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[ 0.0867,  3.8688,  0.6934,  ..., -0.7036,  0.1743, -0.5851],
         [ 0.0946, 11.5057, -0.3364,  ...,  0.8579, -1.8021, -2.3975]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8908, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.5053, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0787,  4.0406,  0.6905,  ..., -1.1609,  0.2964, -1.1026],
         [ 0.0969, 11.5588, -0.3380,  ...,  0.5046, -1.7572, -2.4904]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6190, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5919, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0749,  3.9501,  0.7552,  ..., -1.6781,  0.3894, -0.6944],
         [ 0.0909, 12.2565, -0.2930,  ...,  0.4810, -1.4788, -2.2702]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0593, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4295, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0742,  3.9279,  0.7608,  ..., -2.0946,  0.4538, -0.4485],
         [ 0.0837, 12.2936, -0.2552,  ...,  0.3374, -1.1366, -2.2621]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3112, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8170, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[6174,  692,  110,  ...,  526,  115,    1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP BP
iter = 0 reward = 2
final_logits =  tensor([[[ 0.0462,  4.1646,  0.8080,  ..., -4.7461, -1.7248,  0.1739],
         [ 0.0822, 10.7152, -0.2276,  ..., -2.5273, -2.2838, -2.4755],
         [ 0.0730, 11.4093, -0.2910,  ..., -2.2603, -2.7355, -2.1972]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.5493, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8162, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
By the the the number number of the s
iter = 1 reward = 0
final_logits =  tensor([[[ 6.3593e-02,  4.7404e+00,  1.0313e+00,  ..., -4.7979e+00,
          -1.0457e+00,  2.5617e+00],
         [ 8.2265e-02,  4.7624e+00,  4.9357e-03,  ..., -3.9926e+00,
          -1.2236e+00,  1.3937e+00],
         [ 6.2761e-02,  4.7154e+00,  5.2525e-02,  ..., -4.2840e+00,
          -7.5821e-01,  7.0128e-01],
         ...,
         [ 5.3934e-02,  5.6352e+00, -7.0854e-02,  ..., -4.3620e+00,
          -2.0329e-01,  4.4404e-01],
         [ 5.7607e-02,  8.7182e+00,  6.2468e-01,  ..., -2.7220e+00,
          -2.0539e+00,  6.4678e-01],
         [ 3.4893e-02,  8.7341e+00, -6.4563e-02,  ..., -2.7921e+00,
          -2.1324e+00, -1.3506e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.5752, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5840, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4260 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)
Environment:
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0616,  3.3543,  0.9870,  ..., -4.9300, -1.5088,  1.9953],
         [ 0.0452,  7.6816, -0.1321,  ..., -1.1431, -4.3420, -1.2550],
         [ 0.0384,  9.3502,  0.1091,  ..., -2.9854, -2.2717, -0.8411]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-8.1505, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.9769, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
A
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1133,  4.8844,  1.0825,  ..., -0.5667,  1.3812,  1.4985],
         [ 0.0969, 11.4498,  0.6540,  ..., -2.0332, -0.3775, -1.3397]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7514, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5283, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Oil
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0960,  3.6618,  1.0427,  ..., -2.1124, -0.4084,  0.6191],
         [ 0.0640, 10.8689,  0.1511,  ..., -2.0589, -0.5458, -0.5475]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.7279, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.3680, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  139,  5543,  9254,   320,  3702,   142,   865,   728,   113,   109,
          16036,   762, 14567,   110,   107,  8916,   114,  1713,   113,  5012,
            122,   662,   503, 32908,   110,   108,   330,   278,  2668,   116,
            122,  4605, 35522,   110,   108,   109,   177,  3378,   113, 16036,
            111,  6061, 32886,   110,   108,   169, 15978,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)
Features
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0846,  4.9703,  0.7027,  ..., -1.3096,  0.7973, -0.5055],
         [ 0.0896, 11.8599, -0.2505,  ..., -2.4010, -2.9502, -2.4084]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6544, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.0040, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Features exclusive exclusive exclusive team team team team inside inside inside
iter = 1 reward = 3
final_logits =  tensor([[[ 0.0803,  4.9537,  0.6592,  ..., -1.8216,  0.7673, -0.1651],
         [ 0.0769,  7.7016, -0.3115,  ..., -4.3704, -3.1394, -2.5961],
         [ 0.0737,  6.0419, -0.1736,  ..., -5.2568, -2.3838, -1.6753],
         ...,
         [ 0.0273,  9.0327, -0.3530,  ..., -3.6299, -2.9779, -0.7860],
         [ 0.0258, 10.1400, -0.3280,  ..., -3.3741, -2.8374, -0.9599],
         [ 0.0299, 10.9386, -0.3019,  ..., -3.1148, -2.6903, -1.1799]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1464, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2461, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
Features exclusive exclusive exclusive team team team inside inside inside
iter = 2 reward = 3
final_logits =  tensor([[[ 0.0978,  4.8503,  0.7511,  ..., -2.0375,  0.6777, -0.1158],
         [ 0.0801,  7.5387, -0.2511,  ..., -4.8414, -3.1759, -2.8100],
         [ 0.0775,  6.0115, -0.1118,  ..., -5.7076, -2.2407, -1.7379],
         ...,
         [ 0.0344,  8.1076, -0.2806,  ..., -4.4399, -2.4599, -1.2597],
         [ 0.0355,  9.2703, -0.2141,  ..., -4.2997, -2.2336, -1.3882],
         [ 0.0392, 10.1926, -0.2119,  ..., -4.0001, -2.0984, -1.5910]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6134, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6548, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
Features
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0967,  5.0240,  0.7494,  ..., -1.9802,  0.1629,  0.2444],
         [ 0.0914, 12.0708, -0.2321,  ..., -2.3522, -2.6711, -2.0434]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8106, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5368, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Features exclusive exclusive exclusive exclusive team inside inside inside inside
iter = 4 reward = 4
final_logits =  tensor([[[ 0.1003,  4.7556,  0.6682,  ..., -2.5086,  0.2376, -0.1405],
         [ 0.0784,  8.5758, -0.2752,  ..., -4.2258, -3.0896, -2.3788],
         [ 0.0703,  6.9335, -0.1507,  ..., -4.7887, -2.1182, -1.5411],
         ...,
         [ 0.0388,  9.0358, -0.1765,  ..., -3.7420, -1.8644, -1.4494],
         [ 0.0405, 10.1235, -0.1809,  ..., -3.5718, -1.7933, -1.4954],
         [ 0.0447, 10.9751, -0.1930,  ..., -3.3420, -1.7407, -1.6324]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5973, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.4026, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  4
4
{'input_ids': tensor([[[ 1084, 18756,   110,  ...,  5135,   378,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)
Interior Secretary
iter = 0 reward = 0
final_logits =  tensor([[[ 1.0983e-01,  2.0911e+00,  9.8038e-01,  ..., -6.1718e+00,
           9.5436e-01,  1.4918e+00],
         [ 6.3510e-02,  9.2906e+00,  1.5645e-01,  ..., -9.8919e-01,
           3.7747e-01, -1.3443e+00],
         [ 8.2282e-02,  1.2451e+01,  8.7722e-03,  ...,  1.3293e-01,
          -2.8831e-01, -1.1061e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.6589, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.6217, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Interior Secretary
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0859,  2.5823,  0.7289,  ..., -4.8146,  0.4290,  1.6079],
         [ 0.0626,  7.9814,  0.2513,  ..., -1.2533,  0.0216, -0.8541],
         [ 0.0803, 12.7641,  0.0259,  ..., -0.4510, -0.9509, -0.9913]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4228, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.6293, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Interior Secretary
iter = 2 reward = 0
final_logits =  tensor([[[ 1.0026e-01,  3.2328e+00,  7.1628e-01,  ..., -2.9637e+00,
           7.8013e-01,  6.1255e-01],
         [ 7.0404e-02,  9.1489e+00,  4.1936e-01,  ..., -1.0414e+00,
          -8.4525e-02, -1.3025e+00],
         [ 8.1157e-02,  1.3018e+01,  1.1904e-01,  ..., -1.1185e-02,
          -8.6129e-01, -1.1147e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2465, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4448, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Interior Secretary
iter = 3 reward = 0
final_logits =  tensor([[[ 9.4084e-02,  3.3685e+00,  5.9093e-01,  ..., -1.5050e+00,
           4.3410e-01, -1.2217e-02],
         [ 7.5124e-02,  9.4074e+00,  3.1684e-01,  ..., -4.9995e-01,
          -3.5252e-01, -1.7780e+00],
         [ 8.9158e-02,  1.2975e+01,  5.4486e-02,  ...,  7.0284e-01,
          -6.5459e-01, -1.4218e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0905, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0662, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Salazar
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0716,  3.1418,  0.6464,  ..., -1.1227, -0.3541,  0.5442],
         [ 0.0929, 12.2880, -0.0653,  ..., -0.1873, -1.8723, -0.0260]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4631, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6153, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   243,   186,  ...,   111,  2684,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1527,  5.4148,  0.9732,  ..., -0.6049,  4.3380,  0.9269],
         [ 0.1121, 11.8617,  0.1585,  ..., -1.3750,  1.1964, -0.0185]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9557, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.2153, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Investor
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1344,  5.5953,  0.8772,  ..., -1.4317,  4.1524,  1.0694],
         [ 0.0854, 11.2582, -0.1176,  ..., -0.7192, -0.9056, -0.6499]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.4873, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.8964, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
RRRRRRRRRR on the
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1526,  5.5422,  1.1883,  ..., -2.4256,  0.7031,  1.5473],
         [ 0.1176,  9.3840,  0.0613,  ..., -3.2931, -2.6261, -1.9362],
         [ 0.1236,  9.7581, -0.0707,  ..., -3.3845, -2.3390, -1.6522],
         ...,
         [ 0.1325, 10.1502, -0.2635,  ..., -3.1825, -1.9562, -1.2378],
         [ 0.1253, 10.7761, -0.1568,  ..., -1.8402,  0.1811,  0.7709],
         [ 0.1184, 11.5299, -0.1954,  ..., -2.6671,  0.2319,  0.5328]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4393, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.3518, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4234 out of 11019)

Everytime after generating next logits 39.0% (4298 out of 11019)

Everytime after generating next logits 39.0% (4298 out of 11019)

Everytime after generating next logits 39.0% (4298 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)

Everytime after generating next logits 39.6% (4362 out of 11019)
RRRRRRRRRRRRRR on the
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1373,  6.1699,  0.9980,  ..., -1.2961,  1.3968,  1.6978],
         [ 0.0864,  8.5254,  0.0430,  ..., -2.3519, -3.1706, -2.5760],
         [ 0.0954,  9.0239, -0.0543,  ..., -2.5610, -2.9289, -2.2664],
         ...,
         [ 0.1209, 10.4695, -0.3282,  ..., -2.9286, -2.1925, -1.7306],
         [ 0.1135, 10.9846, -0.2235,  ..., -2.1566,  0.3196,  0.3998],
         [ 0.1082, 11.6632, -0.2225,  ..., -2.7689,  0.3463,  0.2428]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1053, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.8008, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)
RRRRRRRRRR
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1637,  5.2291,  1.1504,  ..., -1.5694, -0.2861,  0.7772],
         [ 0.1354, 10.4226,  0.0157,  ..., -2.1157, -2.0906, -2.0018],
         [ 0.1333, 10.3855, -0.0794,  ..., -1.9724, -1.9331, -1.5918],
         [ 0.1313, 10.3621, -0.1204,  ..., -1.8103, -1.9025, -1.2090],
         [ 0.1307, 10.3996, -0.1640,  ..., -1.8310, -1.8737, -1.0733],
         [ 0.1295, 10.4722, -0.2041,  ..., -1.8156, -1.8629, -1.0064]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.1371, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.1058, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036, 35640,   116,  ...,  3598, 32220,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1040,  4.0474,  0.9587,  ..., -3.8745, -0.5245,  0.8307],
         [ 0.1045,  9.7762, -0.1708,  ..., -1.9238, -1.9087, -2.4875]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9401, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4904, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1070,  3.7006,  1.2368,  ..., -1.8803, -0.3400,  2.3709],
         [ 0.1147, 10.8797, -0.0379,  ..., -0.7585, -2.1970, -1.5724]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.8862, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1275, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
A dozen
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1676,  5.3658,  1.3119,  ...,  0.7641,  0.4158,  1.7036],
         [ 0.1684,  6.6852,  1.1378,  ..., -0.0417,  1.1222,  0.9979],
         [ 0.1380, 13.1129,  0.5996,  ..., -0.4004,  0.5507,  0.8326]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.9545, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.0331, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
A dozen
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1502,  3.4647,  1.2641,  ..., -2.5733, -0.6659,  2.0394],
         [ 0.1436,  7.7229,  0.9749,  ..., -1.4968, -0.3808,  0.4584],
         [ 0.1069, 12.3039,  0.3194,  ..., -1.6864, -0.6540,  0.7044]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.0696, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4352, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
A dozen
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1602,  3.3516,  1.1119,  ..., -1.0548, -1.5902,  2.3223],
         [ 0.1685,  6.0810,  1.2125,  ..., -1.0024, -0.4560,  0.3563],
         [ 0.1292, 12.5634,  0.4794,  ..., -0.9358, -0.8088,  0.3860]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4265, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6093, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787,  1276, 12998,  3531,   148,  4486, 18205, 53857,  7028,   112,
          15079,   109,  3662,   599, 10970,   233, 20447,   788,   121,  1768,
          43304,   110, 10970,   233, 16567,   788,   121,  2617,   120, 16036,
            148,   323,   164,   112, 13889,  4807,   113,   109,  7175,   113,
           3064,   762, 14567,   110,   107,  1263, 53857,  7028,   148,   306,
            115,   253,  2887,   110,   151,   178,  3120,   109,  4807,  1034,
           1844,  2617,   323,   164,   115,   109,  4619,   113,   109,  1073,
           1338,  6687,  3613,   115,   351,   859,   111,  1741,   110,   107,
            285,   148,   243,   178,   117,   146, 10237,   122,   109,   657,
            132, 16036,   111,   138, 15079,   109,  2617,  7539,   110,   107,
           2632,   138,   719,  3916,   135,   109,  2617,   110,   152,   139,
            762, 14567,   148,  2145, 12071,   466,   109,   787,  7175,  3500,
            110,   108,  7271,  3070,   111,  5569,   111, 65047,   181,  4758,
            111, 44650, 18205, 53857,  7028, 35571,  3916,   118,  4807,   113,
            109,  1073,  1338,   110,   108,  6687,  3613,  7922,  8749, 18205,
          53857,  7028, 18097, 16915,   918,   111,   243,  2784,   192,   129,
            154,  5263,   197,   274,   120,   192,   129,  3366,   141,   114,
           1462,   110,   107,   343,   178,   243,   274,  2486,  3916,   355,
            361,   164,   153,   268,   112, 17984, 16036,   110,   107,   139,
           2617,   117,   112, 34262,  7175,   113,  3064,  1836,   111,  1098,
            118,  1166,  9125,   111,  5471,   111,   118,   510,  3207,   111,
           1003,   121,   768,   110,   108,   790,   176,  2242,   110,   107,
          16036,   148,   506,  1389,  3662,   110, 37622,   208,   115,  2242,
            381,   109,   960, 14567,   110,   107,   139,   762, 14567,   110,
            108,   162,  1219,   599,   960,   122,   109, 11335,   113,   109,
          16036,   121, 38539,   252, 81065, 18308,  9600, 13773,   110,   108,
           2145,  8010, 12071,   466,   109,   787,  7175,  3500, 18205, 53857,
           7028, 35571,  3916,   118,  4807,   113,   109,  1073,  1338,   110,
            108,  6687,  3613,   139,  8749,   113,   114,  3662,   599, 10970,
            233, 20447,   788,   121,  1768, 31197,   110, 10970,   233, 16567,
            788,   121,  2617,   112, 13889,  4807,   113,   109, 16036,   762,
          14567,   148,   243,   186,   117,   110,   105,   220,  2767, 16837,
            120, 15931,  2242,   127,   142,   797,   110,   107, 18205, 53857,
           7028, 18097,   112,   129, 24915,   204,   170,   915,  2784,   112,
           1480,   109,  4959,   113,   109,  2617,   110,   107,  3440,  3662,
          12622,   110, 10970,   148,   506,   174,  1389,   165,   115,  2280,
           2784,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Obama
iter = 0 reward = 1
final_logits =  tensor([[[ 0.0767,  5.1217,  0.6186,  ..., -0.4101,  3.1088,  0.9580],
         [ 0.1024, 10.7394, -0.2088,  ..., -0.4587, -0.1134, -1.6736]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9167, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.9550, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Feinberg
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0872,  4.3274,  0.6686,  ..., -0.8362,  1.4907,  0.3595],
         [ 0.0935,  8.0163,  0.2039,  ..., -0.9862, -1.7642,  0.0360],
         [ 0.0594, 11.2031, -0.0904,  ..., -1.2816, -0.9871,  0.2375]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2288, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5302, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
Fein Fein Fein
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0845,  4.6517,  0.5824,  ..., -1.6018,  2.2535, -0.3333],
         [ 0.0855,  8.2925,  0.2796,  ..., -0.3710, -0.3537, -0.1099],
         [ 0.0824,  8.9724,  0.1922,  ..., -0.4264, -0.0981, -0.6704],
         [ 0.0805,  9.6708,  0.1201,  ..., -0.4097,  0.0582, -1.0710]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.0444, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.1858, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
Obama
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0825,  5.4184,  0.5177,  ..., -0.0637,  3.9214,  0.1227],
         [ 0.1085, 10.7268, -0.0664,  ..., -0.4500,  0.1924, -2.2564]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.9995, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.9885, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
Feinberg'
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0772,  4.8645,  0.3838,  ..., -1.1166,  3.7741, -0.2435],
         [ 0.0713,  5.8970,  0.3877,  ...,  0.3856, -1.2366,  0.5161],
         [ 0.0519,  6.2394, -0.0970,  ..., -1.8627, -1.0974, -0.9582],
         [ 0.0435, 12.2933, -0.1104,  ..., -0.3939,  0.1712, -2.2065]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.3955, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.6080, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787,   762, 14567,   110,   151, 15265,  7788,   110,   105,   124,
            109,  2143,  1034,  1027,  3070,  6375,   127,   239,   270,   263,
            112,   225, 16036,   562,   109, 15737,  2584, 51128,   116, 10928,
           1034,   116,  3070,  2414,   148,  7646,   339,   698, 26680,   233,
          37399,   110,   108, 35493,   111, 23363,   110,   107,   110,   105,
            600,   480,   140, 12144,   110,   108,   155,   265,  7646,   110,
            108, 16837,   178,   649,   110,   108,  1132,   109,  2414,   114,
           4081, 15115,   110,   107,   343,  1263, 51128,   116, 10928,  7719,
            180,   138,  4428,   169,  1162,  3070,   260,   559,   111,   118,
            149,   117,   146,   114,   710,  5135,   110,   108,   155,   114,
            729,   121,  4109,   156,   110,   107,   202,   729,  1034,   116,
            419,   112,   133,   114,   715,   110,   108,   181,   660,   113,
            523,   134,   109,   370,   113,   109,  8483, 16837,  4645, 16848,
           2584, 51128,   116, 10928,  7915, 25996,   110,   105,  2184,  6021,
            134,   214,   173,   145,   416,   136,   762, 14567,   256,   129,
           3150,   197, 23363,   110,   108,   155,   145,   114,   457,  3178,
            131,   144, 34742,   110,   108, 16837,   178,   649,   110,   107,
            398,   178, 41593,   164,   114,  1124,  2944,   113,  9606,  6545,
            115,   109,  2414,  1034,   116,  7270,   110,   108,  2584,   649,
            178,   117,  5238,   120,   109, 14567,   138,   129,   289, 13502,
            118,   223,   200,   115,   136,  3820,   121, 23623,  3070,   427,
            113, 38584,  1946, 11958,   144,   216,   110,   108,  7915, 29546,
           3070,   148,   174,  7162,   115,  7915,   262,   113,   109, 14567,
          10250,  1034,   116,  1750,   110,   108,  1946, 74523,   110,   108,
           5765,   122,   342,   111,  2779,   112,  7904,   110,   107,   110,
            105, 15265,   117,   169,   271,   110,   108,   347,   126,   178,
            358,  3178,   131,   144,   235,   742,   997,   110,   108, 16837,
            265,   649,   110,   107,   110,   105,   285,  1034,   116, 13735,
            110,   107,   285,  1034,   116,  7432,   134,   488,   110,   107,
            285,  1034,   116,   146,   109,   310, 29546,   420, 15538, 90155,
            110,   151,   110,   105,   168,   978,   172,   114, 10447,  1120,
            279,   264, 16837, 16036,   148, 20350,  5478,   113, 63981,  7881,
            333,   109,  7175,   113,  3064,   762, 14567,   110,   108,   155,
            186,   127,   274,   170,   127,  1192,   126,  2773,  7427,   118,
            109,   201,   126,   117,   557,   110,   108,  6260,   109,  6442,
           1034,   116,  6869,  3544,   115,  7915,   110,   107, 46095,   126,
            110,   108,   155, 16036,   117,   146,   114,  6749,  1172,   264,
            115,   109,  6805,  1120,   113,  7026, 63116, 58439,   110,   107,
            222,   109, 10601,  1034,   116,   629,   110,   108, 14515,   429,
            115,   114,  1120,  4511,   120,   117,   239,   163,   238,   112,
          16036,  1034,   116,   648,   115,   136,   297,   113,  7915,   110,
            108,   623,   391,  1725,  2051,   279,   115,  4555,   523,  1490,
          21955,  8802,   110,   107,   110,   105,   184,  1034,   216,   146,
            314,   785,   118,  1609,   126,   110,   108,   155,   264, 16036,
           1034,   116,   557,   234,   110,   108, 16837,   156,   649,   110,
            107,   353,  1034,   116,   956,  2158,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
BP has
iter = 0 reward = 1
final_logits =  tensor([[[ 0.0586,  2.5939,  0.3334,  ..., -2.8913, -2.6908, -1.5309],
         [ 0.0981,  7.9196, -0.4690,  ..., -0.8669, -3.2232, -2.1273],
         [ 0.1131, 11.3118, -0.2915,  ..., -0.2001, -1.6494, -0.7702]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.4590, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.1737, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
BP has
iter = 1 reward = 1
final_logits =  tensor([[[ 0.0698,  3.5248,  0.3593,  ..., -3.9005, -1.5817, -1.6145],
         [ 0.1120,  6.8944, -0.4315,  ..., -1.6471, -3.0324, -2.1364],
         [ 0.1201, 11.9882, -0.2141,  ..., -0.4274, -1.8548, -0.7407]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8463, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.9906, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
BP has
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0924,  3.4348,  0.3875,  ..., -4.0273, -1.0948, -1.6496],
         [ 0.1292,  7.1555, -0.2999,  ..., -0.7820, -2.2964, -1.9369],
         [ 0.1123, 12.5939, -0.2369,  ..., -0.0214, -1.2633, -0.9758]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7704, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.1068, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
BP has
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0976,  3.4467,  0.4138,  ..., -3.9427, -0.6285, -1.5946],
         [ 0.1274,  7.4718, -0.2546,  ..., -0.7654, -2.3274, -2.0115],
         [ 0.1031, 12.8330, -0.2775,  ..., -0.1625, -1.1923, -1.0951]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0466, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6341, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
BP has
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0929,  3.3161,  0.4315,  ..., -4.2466, -0.5457, -1.5805],
         [ 0.1261,  7.9774, -0.3133,  ..., -1.7152, -2.3056, -2.3521],
         [ 0.0996, 12.8564, -0.2705,  ..., -0.2596, -1.1758, -1.0230]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1283, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6338, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  608,  1338,  2652,  2882,  2033,   134,   305, 91516, 17403,  4596,
            202,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   115,   109,  7175,   113,  3064,   110,   108, 16036,
            649,   110,   107,   983,  3244,  2777,   165,   141, 16036,   649,
            126,   140,  1470,   115,   297,   118,   109,  5135,   110,   108,
            155,   163,  1262,   181,  6511,   124,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,   608,
           1338,  2652,  2882,  2033,   134, 71437, 17403,  4596, 16036,   148,
           1788,   114,  1933,   545,   162,   939,   109,   301,  1034,   116,
            700,   113,   702,   964,   164,   112,   109,  7175,   113,  3064,
            762, 14567,   110,   107,  2973,   112,   109,   301,   110,   108,
            114,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   110,   107,   983,  3244,  2777,   165,   141, 16036,
            243,   120,   126,   140,  1470,   115,   297,   118,   109,  5135,
            110,   108,   155,   126,   163, 17188,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
BP is
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1466,  7.5449,  0.7185,  ..., -2.7379,  0.0652,  0.3362],
         [ 0.1311,  8.8275, -0.1226,  ..., -2.7477, -0.3752, -0.9424],
         [ 0.1296, 11.0743, -0.0626,  ..., -2.2738,  0.9361, -0.6978]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.1373, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.2458, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1578,  8.1596,  0.7736,  ..., -2.2691, -0.0996, -0.0841],
         [ 0.1337,  9.8125, -0.0510,  ..., -2.6494, -1.2693, -1.2924]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8385, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.3900, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Last
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1149,  5.7778,  0.7092,  ..., -2.0068, -2.5409,  0.4443],
         [ 0.1060, 11.0460,  0.0513,  ..., -0.8830, -1.8339, -0.2459]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0914, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.9321, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
BP says video
iter = 3 reward = 2
final_logits =  tensor([[[ 0.1408,  7.5796,  0.7000,  ..., -1.9041, -1.0306,  1.0956],
         [ 0.1050,  8.3740,  0.0293,  ..., -3.2371, -1.7277, -1.5504],
         [ 0.1251,  9.8848, -0.2528,  ..., -1.9253, -0.9434, -0.3757],
         [ 0.0917, 11.4538, -0.3537,  ..., -1.9687, -1.9134, -0.4898]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.5310, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.8410, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Last September September claims face face face face face face face face face face face face face face face face face face face face of
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1088,  5.8899,  0.9866,  ..., -1.5356,  1.2893,  1.9636],
         [ 0.1350,  2.5916,  0.1212,  ..., -1.9245, -1.2258,  0.6143],
         [ 0.0939,  2.9489, -0.0312,  ..., -2.8252, -1.2291,  0.5740],
         ...,
         [ 0.0660,  5.2598, -0.4189,  ..., -3.6702,  0.6218, -0.1400],
         [ 0.0668,  5.2409, -0.4115,  ..., -3.6839,  0.5911, -0.1965],
         [ 0.0633, 10.7449, -0.3914,  ..., -3.3128,  0.0644, -0.1794]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.4995, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.6997, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  530,  1268,  2651,  2882,  2033,   134, 80621, 17403,  4596, 25688,
            115, 16036,  1963,   902,   124,  1789,  2409,   114,   787,  7501,
           5268, 79701,   109,   762,   301,  1034,   116,  4206,   111, 12856,
            130,   210,   130, 16036,   118,   109,  7175,   113,  3064,   762,
          14567,   110,   107,   139, 11335,   134,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,  1024,   111,  1358,   112,   109,  1368,
            521,  9134,   762,  8186,   110,   107,  4987,   109,  4469,   110,
            108, 16036,  2853,  3947,   607,  2527,   110, 43995,   118,   109,
            211,   166,   381,   913,   289,   232,   110,   107,  6442,   260,
          21089, 80736, 82734,  4278,  3886,   112,  5930, 37313,   110,   108,
            142,   762,  8962,   122, 85411,   116,  1714,   208, 59297, 20185,
            110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.5% (4246 out of 11019)

Everytime after generating next logits 38.5% (4246 out of 11019)

iter = 0 reward = 0
final_logits =  tensor([[[ 0.1272,  8.7970,  0.8314,  ..., -2.7718,  2.6064,  1.1867]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.2378, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6825, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Bentley
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0968,  5.5979,  0.6200,  ..., -2.6608,  1.8231, -0.4610],
         [ 0.0791, 12.8693, -0.3118,  ..., -1.6243, -0.1467, -1.4440]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.4848, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(23.3668, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1283,  5.0341,  0.4671,  ..., -1.6695,  0.9948, -1.6693],
         [ 0.1032, 12.3202, -0.2199,  ...,  0.2042, -0.6476, -0.1739]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3027, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.7673, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1186,  4.6713,  0.4664,  ..., -1.3305,  0.2521, -1.2718],
         [ 0.0889, 12.3291, -0.2662,  ..., -0.1621, -1.0833,  0.2839]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.6888, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.9140, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1417,  5.5535,  0.4297,  ..., -2.1946,  0.0144, -2.1516],
         [ 0.1133, 12.2936, -0.2373,  ..., -0.1634, -0.7810, -0.3531]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5469, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.1928, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3788,   110,   108,   258,   111,  1183,   109,  4193,   120,  5887,
            119,  3788, 22017,  3249,  2309,   114,  4340,   132,  2162,   110,
            108,   132,   989,  6502,   115,   150,   545,  1771,  6180,   114,
           4340,   493,   126,   586,   112,   258,   165,   241,   111,   173,
            157,   133,  6502,   110,   107, 14845,   127,  1661,   115,   156,
            295,   110,   108,  2063,   119,  1235,   111,   400,   489,   110,
            107, 21556,   116,  4170, 16036,   762, 14567,  1736,   651,  1265,
           1185,  2652,   110,   108,  3013,   111,  9792,  5297,  5299,  2346,
           3601,  2567,  7499,   114,  1736,   266,  1678,   115,   109, 11319,
            124,   109, 16036,   762, 14567,   110,   107,  2346,  3601,  2567,
            898,  6949,   120,   142,  8635,   933,   113,  1647,   196,   506,
            174,  9889,   110,   108,   155,   701, 51098,   192,   129,   656,
            130,  6031,  1219,   115,  4190,  6500,  3381,   113, 43278,   110,
            107,   139,   657,   148, 18097,   112,   110,   105,   543,   109,
           2919,   113,   219,  6209,   702, 16837,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Peer Peer Peer Peer Peer
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1350,  5.1495,  0.7460,  ..., -1.0870, -0.3469, -0.7476],
         [ 0.1319,  8.8848, -0.0285,  ..., -1.8014, -2.1002, -0.7648],
         [ 0.1309,  9.0093, -0.0832,  ..., -1.6564, -1.9822, -0.8134],
         [ 0.1303,  9.3979, -0.1421,  ..., -1.4768, -2.0554, -0.8067],
         [ 0.1304, 10.6191, -0.1672,  ..., -1.0857, -2.0022, -0.8701],
         [ 0.1283, 10.9631, -0.1989,  ..., -0.9415, -1.9840, -0.9120]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.5207, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.8451, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
Peer Peer Peer Peer Peer Peer Peer Peer Peer Peer Peer to
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1207,  5.0268,  0.7728,  ..., -1.9827,  0.1302, -0.8410],
         [ 0.1293,  5.0086, -0.0169,  ..., -1.6038, -2.2821, -0.8836],
         [ 0.1225,  4.9686, -0.0564,  ..., -1.5033, -2.1089, -1.0496],
         ...,
         [ 0.1108,  8.7739, -0.2289,  ..., -0.8630, -1.5046, -1.7559],
         [ 0.1103,  9.0880, -0.2486,  ..., -0.7886, -1.4851, -1.8335],
         [ 0.0966, 11.1904, -0.3529,  ..., -0.9190, -1.4877, -1.5539]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.2282, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.7206, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
Peer Peer Peer Peer Peer Peer Peer Peer Peer Peer Peer
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1223,  5.4571,  0.8148,  ..., -2.4656,  0.2041, -1.1293],
         [ 0.1294,  6.3680,  0.0694,  ..., -1.6899, -2.0886, -0.8237],
         [ 0.1212,  6.3230,  0.0221,  ..., -1.5397, -1.8983, -0.8959],
         ...,
         [ 0.1086, 10.0639, -0.1997,  ..., -0.8458, -1.5336, -1.7053],
         [ 0.1073, 10.4946, -0.2262,  ..., -0.7134, -1.5163, -1.7594],
         [ 0.1060, 10.8092, -0.2527,  ..., -0.6238, -1.5025, -1.8310]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4131, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1797, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Peer Peer Peer Peer
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1371,  5.3277,  0.6328,  ..., -2.9055,  0.1758, -1.4784],
         [ 0.1325, 12.0583, -0.0451,  ..., -1.2291, -0.9826, -0.5802],
         [ 0.1286, 11.9544, -0.0812,  ..., -1.1128, -0.7890, -0.4498],
         [ 0.1246, 11.7893, -0.1138,  ..., -0.8378, -0.5842, -0.3386],
         [ 0.1171, 11.6646, -0.1328,  ..., -0.4485, -0.3095, -0.2435]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4403, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9530, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Peer Peer Peer
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1341,  5.2667,  0.6012,  ..., -3.3663, -0.0413, -1.7738],
         [ 0.1260, 12.3543, -0.0231,  ..., -1.8441, -1.2583, -0.5536],
         [ 0.1230, 12.2145, -0.0646,  ..., -1.6252, -0.9962, -0.4671],
         [ 0.1200, 12.0337, -0.0876,  ..., -1.2178, -0.6971, -0.2917]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1312, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.4899, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1428,  1307,  2652,  2882,  2033,   134, 84838,   726, 17403,  4596,
          16036,   148,  1939,   114,   177, 14464,  3889,   124,   109, 14154,
           7175,   113,  3064,   762,   210,   110,   108,   301,  2662,   416,
            110,   107,   168,   117,  8549,   109,   177,  3889,   138,   923,
            109,  8186,   111,  3155,   109,   762,   269,   154,   113,   126,
            137,  6218,   190,   109,  1917,   155,   126,   256,   129,   372,
            228,   390,   269, 16036,   235,   682,   109,   807,  2353,   117,
           1147,   110,   107,   139, 11335,   113,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,   200,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Last July
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1728,  7.5071,  1.1818,  ..., -1.6784,  2.0803,  1.2267],
         [ 0.2044,  9.8310,  0.4858,  ...,  0.5424,  2.0045,  1.4606],
         [ 0.1875, 11.9614,  0.1819,  ...,  0.6956,  1.3141,  0.5865]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8352, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.9618, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
Last July
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1669,  7.5269,  1.2319,  ..., -1.5738,  2.1966,  1.1303],
         [ 0.2034, 10.0971,  0.4860,  ...,  0.6762,  1.9783,  1.2461],
         [ 0.1841, 12.3630,  0.1857,  ...,  0.7644,  1.2660,  0.4226]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0703, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3825, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Last July
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1562,  7.3570,  1.3350,  ..., -1.4125,  2.4705,  1.2366],
         [ 0.1992, 10.0256,  0.4437,  ...,  0.5819,  2.0616,  0.7801],
         [ 0.1701, 12.3103,  0.1495,  ...,  0.3816,  1.0771,  0.0291]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0975, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1255, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Last July
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1699,  7.4613,  1.4248,  ..., -1.1523,  2.8982,  1.1757],
         [ 0.2009, 10.1498,  0.3724,  ...,  0.6759,  1.8594, -0.0560],
         [ 0.1683, 12.1404,  0.0895,  ...,  0.4184,  0.9616, -0.3456]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1198, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.3935, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Last July July
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1819,  7.4410,  1.4529,  ..., -1.6330,  2.5895,  1.3897],
         [ 0.1968,  6.8946,  0.3561,  ...,  0.1765,  1.7977, -0.5222],
         [ 0.1738,  9.9096,  0.0878,  ..., -0.0783,  1.0723, -0.7207],
         [ 0.1741, 10.7818,  0.0522,  ..., -0.0857,  0.7926, -0.8028]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.8620, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.5621, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   762, 14567,   114,   711,   113,   110,   105,  2111,  1057,
            395,  1034,   139, 21549, 16036,   762, 14567,   115,   109,  7175,
            113,  3064,   148, 50233,   109,  4170,   160,  3079,   644,  2175,
            110,   108,   155,   109,  1319,  1977,   113, 11461,   649,   109,
          14567,   140,   109,   711,   113,  1025, 46366,   110,   107,  1084,
          44907, 41534,   140,  1977,   113, 11461,  1034,   116,   655,   260,
            135,  5109,   112,  3390,   111,   148,   243,   223,   644,   524,
            632,   112,   823,   114,   110,   105, 30493,   824,   113,   109,
           2379,   110,   107, 16837,   125,   116,  1086,   734,   112,   145,
           1321,  1110,   299,   114,   300,   121,  1704,  6030,   112, 11881,
          13922,   110,   152,   325,   117,   461,   762,   297,   113,   109,
            951,   110,   108,   132,   109,   575,   110,   152,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
President
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1216,  3.4322,  0.3829,  ..., -1.8605,  0.2784, -1.1125],
         [ 0.1253, 12.4904, -0.0327,  ..., -0.6297, -1.2847, -0.0899]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4261, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.3717, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
President
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1243,  3.4169,  0.4106,  ..., -1.9160,  0.3050, -1.1984],
         [ 0.1297, 12.5787, -0.0422,  ..., -0.6895, -1.2773, -0.1381]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.1422, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.1297, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
in the
iter = 2 reward = 0
final_logits =  tensor([[[ 1.9820e-01,  6.9594e+00,  7.0307e-01,  ..., -2.5867e+00,
          -7.0672e-02,  2.1947e-01],
         [ 1.9877e-01,  9.1538e+00, -4.9535e-03,  ..., -1.9860e+00,
          -1.5165e+00, -6.5820e-01],
         [ 1.7713e-01,  1.0103e+01, -9.3415e-02,  ..., -2.4241e+00,
          -9.4917e-01, -9.9815e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3978, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4782, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

iter = 3 reward = 0
final_logits =  tensor([[[ 0.2176,  5.8989,  0.7520,  ..., -2.5815, -1.5285,  1.3309],
         [ 0.1924,  8.8146,  0.4199,  ..., -3.3640, -2.2724,  0.1002],
         [ 0.1897,  8.8269,  0.3693,  ..., -3.4288, -2.1547,  0.0268],
         [ 0.1869,  9.7625,  0.2964,  ..., -3.2738, -2.0226,  0.0348]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.1119, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.7776, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
BP says
iter = 4 reward = 2
final_logits =  tensor([[[ 0.1814,  4.9831,  0.3315,  ..., -3.1443, -0.0489, -1.1132],
         [ 0.1740,  9.8972, -0.4199,  ..., -2.6178, -2.0478, -3.2034],
         [ 0.1664, 12.2253, -0.3963,  ..., -1.7316, -0.6014, -0.7645]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.4157, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.3415, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[ 1346,  6661,   118,   762, 14567,   945,   139,  2800,  1728,   112,
           2555,   110,   105, 41638, 16837,  1003,   121,   768,  1739,   120,
            133,   174,   263,   115,   109,  7175,   113,  3064,   139,  1346,
           6661,  2800,   110,   108,   229,   606,   118,  6957,   109,   808,
          70959,   503,   110,   108,   148,  2365,   114,  3662, 13602,   604,
            762,  1003,   121,   768,  1459,   110,   107,   139,  2800,   110,
            108,   162,  1653,   120,   203,  1962,  2560,   117,   110,   105,
            112,   650,   160,  8695, 33237,   118,   109,  1280,   113,  7633,
          16837,  1487,   203,   807,  4086,   134,   114,  1833,  1792,   115,
           1741,  3710,   110,   107,   182,   117,   203,  6932,   110,   105,
            698,  9501,  1702, 16837,   110,   107,  1810,  1518,   137,  2337,
            118,   109,  1702,   430,   960,  2651,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1]]])}

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1896,  7.5627,  0.9893,  ...,  0.1265,  0.0746, -0.2003],
         [ 0.1755, 11.5757,  0.4881,  ...,  0.1111,  0.0275, -0.1274]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.3688, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.2582, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1707,  7.7864,  0.9517,  ...,  0.4253,  0.4045, -0.5811],
         [ 0.1799, 12.6127,  0.4565,  ...,  0.3935, -0.1848,  0.2417]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.9662, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.5417, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.3% (4224 out of 11019)
Gulf X X X X X X X X Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation Foundation
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0932,  4.1904,  0.4541,  ..., -1.7514, -0.4804, -3.4368],
         [ 0.1383,  6.1180,  0.1311,  ..., -2.4089, -3.8392, -0.7702],
         [ 0.1215,  4.6330,  0.1731,  ..., -1.8770, -4.5518, -1.4277],
         ...,
         [ 0.0955,  8.4415, -0.7271,  ..., -2.9132, -2.3975, -2.4448],
         [ 0.0970,  8.8146, -0.7252,  ..., -2.8608, -2.3562, -2.3976],
         [ 0.0991,  9.2709, -0.7161,  ..., -2.7955, -2.3117, -2.3334]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.6776, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.2000, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4252 out of 11019)

Everytime after generating next logits 38.6% (4252 out of 11019)

Everytime after generating next logits 38.6% (4252 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0729,  6.1463,  0.7761,  ..., -2.7964,  0.2595, -1.8351],
         [ 0.1222, 11.7971,  0.2461,  ..., -1.9186, -0.2296, -1.3942]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7914, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3338, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0509,  6.3184,  0.7717,  ..., -2.3568, -0.2312, -1.6019],
         [ 0.1059, 12.8227,  0.1626,  ..., -0.9017, -0.5757, -0.6946]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2207, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1250, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3211,  1307,  2652,  2882,  2033,   134,   280, 85536, 17403,  4596,
            398, 16036,  1034,   116, 11599,  2664,   109,   519,   113,   114,
           6033,   124,  9134,  9600,   110,   108,   109, 12220,   113, 14645,
           9727,   135,   109,   762, 14567,   115,   109,  7175,   113,  3064,
            148,  9380,   164,   115,   114,  2043, 22369,   115, 10792,   110,
            107,   353,  1761,  7690,   355,  1854,   199,   109, 18191,   113,
          14645,   246,   129,  8626,   122,   110,   107,  9903, 90966,  1574,
            135,   351,   859,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
tide
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1322,  6.2951,  1.2935,  ...,  1.6709, -1.0047,  1.3928],
         [ 0.1532, 12.9081, -0.1031,  ..., -0.1386, -0.4248,  0.7711]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0874, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9519, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
tide lawsuits arising from Idaho tide rivals from Idaho
iter = 1 reward = 0
final_logits =  tensor([[[ 1.5646e-01,  5.6304e+00,  1.4301e+00,  ...,  2.2742e+00,
          -1.1265e+00,  9.6748e-03],
         [ 1.4501e-01,  5.6168e+00,  1.5857e-01,  ..., -6.5122e-01,
          -2.3221e-01,  8.6249e-01],
         [ 1.4713e-01,  6.0103e+00,  7.2165e-03,  ..., -2.0282e+00,
          -1.2527e-01,  9.0637e-02],
         ...,
         [ 1.5550e-01,  1.0091e+01, -8.3644e-02,  ..., -6.5882e-01,
          -9.2896e-01, -7.8871e-02],
         [ 1.4711e-01,  1.0857e+01,  1.2610e-01,  ...,  6.3941e-01,
          -1.3564e+00, -1.7974e+00],
         [ 1.7244e-01,  1.2948e+01, -4.0511e-03,  ..., -1.4733e+00,
          -1.4583e+00, -8.0950e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1551, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5975, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Idaho rivals rivals rivals from Idaho
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1831,  4.5619,  1.2115,  ...,  2.5463, -1.1346, -0.4359],
         [ 0.1548,  6.1294,  0.1717,  ..., -2.5033, -1.2786, -0.7042],
         [ 0.1459,  7.2624, -0.0615,  ..., -0.2345, -1.4789, -0.9029],
         ...,
         [ 0.1489,  7.8936, -0.0845,  ...,  0.0498, -1.2823, -1.0072],
         [ 0.1354,  8.5929,  0.0222,  ...,  0.5252, -1.6314, -1.7206],
         [ 0.1667, 11.9715,  0.0367,  ..., -0.8895, -0.7351, -0.4082]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.8588, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2815, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
Lawsuits
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1599,  4.9737,  1.1037,  ...,  2.5320, -0.8532,  0.0954],
         [ 0.1507, 10.8491,  0.1073,  ...,  0.8654, -0.5420, -0.4600],
         [ 0.1573, 12.0449,  0.0218,  ...,  0.4693, -0.9701, -1.2724]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2692, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0813, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Lawsuits
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1700,  5.5825,  0.9807,  ...,  2.8373, -0.8190, -0.3214],
         [ 0.1524, 10.5783,  0.0755,  ...,  1.1303, -0.4560, -0.4410],
         [ 0.1580, 11.9129, -0.0507,  ...,  0.8810, -0.8772, -1.3196]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1323, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 2571,  1508,  2652,  2882,  2033,   134,   305, 49218, 17403,  4596,
            222,  6358,   109, 40522, 34524,  4820,   164,   299,  4027,  1034,
            116, 62223,   454,  3682,  3793,   156,   113,   109,   278,  1034,
            116,  3741,   762, 12802,   110,   107,  1478,   115,   109,  5569,
            110,   108,  3070,   111,   176,  3217, 17659,   109,  1322,   192,
            394,  5097,   110,   107,   343, 62223,   148,   174, 71731,   115,
            109,  1965, 43983,   231,   110,   108,   112,   253,   142,  4156,
            120,   126,   117,   744,   130,   175,   109,  2648,   394,  2032,
            110,   107,   168,   117,  8549, 62223,  1034,   116,   584,   256,
            319,  2520,   118,   274,   115,   109,  7175,   113,  3064,   170,
            127, 48322,   120,   157,   138,   521,  5097,   135,   109,  2926,
          16036,   762, 14567,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1]]])}

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Galician industries broke Galician industries broke
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1317,  5.6786,  0.7516,  ..., -3.4189, -0.7589, -1.8123],
         [ 0.1035,  7.8938, -0.0960,  ..., -3.5328, -2.0258, -1.2614],
         [ 0.1038,  6.7108, -0.1592,  ..., -3.3549, -0.6543, -1.7611],
         ...,
         [ 0.1157,  9.5236, -0.3215,  ..., -3.4642, -0.1458, -1.8873],
         [ 0.1091,  8.5863, -0.5799,  ..., -3.4324, -0.4708, -2.2298],
         [ 0.1273, 10.4919, -0.2676,  ..., -2.2648,  0.5577, -1.5788]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3186, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2214, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Galician industries broke Galician industries broke last
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1328,  5.4992,  0.7640,  ..., -3.6337, -0.8129, -1.7645],
         [ 0.1059,  6.9552, -0.0678,  ..., -3.8223, -2.0472, -1.2241],
         [ 0.0977,  6.0386, -0.1539,  ..., -3.5856, -0.7972, -1.8309],
         ...,
         [ 0.1132,  7.6576, -0.5608,  ..., -3.6850, -0.4423, -2.2304],
         [ 0.1299,  9.3182, -0.2930,  ..., -2.6026,  0.4542, -1.6393],
         [ 0.1606, 11.9049, -0.0974,  ..., -2.2441, -0.5600, -1.3756]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4545, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2556, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galician industries broke Galician industries broke if
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1328,  5.3927,  0.7954,  ..., -3.8780, -0.7480, -1.5821],
         [ 0.1054,  6.7917, -0.0253,  ..., -3.8570, -2.0750, -1.1760],
         [ 0.0949,  5.8467, -0.1139,  ..., -3.7826, -0.7492, -1.9047],
         ...,
         [ 0.1165,  7.3196, -0.5319,  ..., -3.8958, -0.4349, -2.0364],
         [ 0.1306,  8.8617, -0.2856,  ..., -2.6774,  0.3917, -1.5187],
         [ 0.1036,  9.9384, -0.1826,  ..., -2.8078, -0.0568, -1.8087]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2505, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2044, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Galician industries broke Galician industries broke if if
iter = 3 reward = 0
final_logits =  tensor([[[ 1.3045e-01,  5.4263e+00,  8.0224e-01,  ..., -4.0844e+00,
          -8.1726e-01, -1.4395e+00],
         [ 1.0280e-01,  6.7133e+00, -7.6193e-03,  ..., -3.8147e+00,
          -2.0828e+00, -1.1451e+00],
         [ 9.2344e-02,  5.8243e+00, -1.1404e-01,  ..., -3.8547e+00,
          -7.9483e-01, -1.8866e+00],
         ...,
         [ 1.3099e-01,  8.5160e+00, -2.9676e-01,  ..., -2.6845e+00,
           3.9755e-01, -1.4880e+00],
         [ 1.0373e-01,  9.6072e+00, -1.7693e-01,  ..., -2.8905e+00,
           4.6912e-02, -1.8432e+00],
         [ 1.0187e-01,  1.0265e+01, -2.5603e-01,  ..., -2.8399e+00,
          -2.1761e-01, -1.7762e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0619, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1117, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galician industries broke Galician industries broke if if
iter = 4 reward = 0
final_logits =  tensor([[[ 1.2781e-01,  5.3965e+00,  8.0055e-01,  ..., -4.2160e+00,
          -8.7216e-01, -1.3714e+00],
         [ 1.0044e-01,  6.6020e+00,  6.8417e-03,  ..., -3.7901e+00,
          -2.1000e+00, -1.1486e+00],
         [ 9.0316e-02,  5.7572e+00, -1.1666e-01,  ..., -3.8376e+00,
          -8.0745e-01, -1.8393e+00],
         ...,
         [ 1.3173e-01,  8.1639e+00, -3.0958e-01,  ..., -2.6875e+00,
           4.0914e-01, -1.4812e+00],
         [ 1.0409e-01,  9.2469e+00, -1.7108e-01,  ..., -2.9851e+00,
           9.7016e-02, -1.8931e+00],
         [ 1.0357e-01,  9.9327e+00, -2.5063e-01,  ..., -2.9333e+00,
          -1.3166e-01, -1.8240e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1116, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.0576, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787, 17984,   116, 16036,   204,  7175,   113,  3064,   762,  5135,
           1195,  1408,  2652,  2882,  2033,   134, 79386,   914, 17403,  4596,
            139,   706,  1013,   117,   112, 17984, 16036,   111,  1965,   176,
            524,   204,   114,  1124,   762, 14567,   115,   109,  7175,   113,
           3064,   110,   107,   139,   657,   243,   126,   192,  1137,   109,
           3358,  1069,  9873,   118,   109, 13353,   113,  2729,  1363,   124,
           1496,   164,   109,  3741,  2249,  5135,   115,   787,   689,   110,
            107, 36347,  1024,  2342,   115,   109, 11335,   124,   109, 81065,
          18308,  9600, 13773,   115,   960,   110,   107,   139,  6442,  1034,
            116, 55065, 66707,  1574,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
BBC Eleven4
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1507,  5.3881,  1.0348,  ..., -3.9871,  0.4621,  0.2738],
         [ 0.1364, 13.1292,  0.4426,  ..., -2.7588, -1.8216, -1.1326],
         [ 0.1093, 11.3713,  0.3039,  ..., -0.7988, -0.6210, -0.6304],
         [ 0.1552, 12.4211,  0.3259,  ..., -2.6535, -1.9290, -1.0069]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.2316, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(27.5178, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)
BBC
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1028,  4.5390,  0.9343,  ..., -5.3577, -0.0353,  1.0993],
         [ 0.1232, 13.1691,  0.3250,  ..., -2.6228, -1.9318, -0.4896]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.3791, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.6327, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
BBC
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0901,  4.7065,  0.8632,  ..., -5.8192, -0.4009, -0.3163],
         [ 0.1156, 13.1162,  0.3030,  ..., -2.6237, -1.8291, -0.5916]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6148, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5847, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
BBC
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0868,  4.7725,  0.7779,  ..., -5.7643, -0.2367, -0.5122],
         [ 0.1054, 13.1231,  0.2516,  ..., -2.5725, -1.8127, -0.6743]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3448, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8728, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
BBC
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0847,  4.9854,  0.7711,  ..., -5.9228,  0.1054, -0.7554],
         [ 0.1012, 13.0474,  0.2417,  ..., -2.6528, -1.8385, -0.7568]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8335, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.4060, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 7915, 26939,  4355,  1194,   244, 16036,   762, 14567,  5823,  8437,
            117,   364,   109, 19954,   113,   109,  7175,   113,  3064,   235,
            149,   314,   210,   110,   107,   139,   908,   317,  6299,   111,
           1174,   117,  8988,   153, 19347,   578,   110,   107,   343,   136,
            232,   205,   113,   109, 27736,   127,  2609,   110,   107,   139,
          27736,   127,   146,  1622,   115,   762,   110,   108,   130,   109,
           6442,  1034,   116,  2040,  9518,  1574,   135,  7915,   110,   108,
            155,  3040,   299,   141,  2926, 21615, 22611,   116,   120,   195,
           2443,   112,  2512,   109, 15737,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
Adams killed something something something the the the the
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0594,  6.3687,  0.7442,  ..., -1.9600,  0.5431, -2.5059],
         [ 0.0985,  6.7570,  0.0902,  ..., -1.7687, -1.6022, -2.1208],
         [ 0.0771,  6.2269, -0.1522,  ..., -1.8450, -0.4411, -2.1436],
         ...,
         [ 0.1064,  8.8124, -0.0300,  ..., -2.8845, -0.2343, -1.2689],
         [ 0.1084,  8.9737, -0.0260,  ..., -2.9589, -0.2297, -1.2674],
         [ 0.1078,  9.3448, -0.0392,  ..., -2.9187, -0.1627, -1.3055]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.6656, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(21.9177, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
oysters
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0575,  6.9297,  0.9695,  ..., -1.2866,  1.6822, -1.9734],
         [ 0.0901, 11.6385, -0.1121,  ..., -0.3972, -0.8346,  0.3104]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-6.0008, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.6336, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Economic reports reports from the Gulf Gulf Gulf Gulf Gulf oil
iter = 2 reward = 8
final_logits =  tensor([[[ 5.2062e-02,  6.1301e+00,  1.0451e+00,  ..., -1.8134e+00,
           1.1615e+00, -2.4549e+00],
         [ 6.8632e-02,  5.3323e+00,  5.4812e-01,  ..., -2.1045e+00,
           8.5879e-02, -1.7161e+00],
         [ 8.1212e-02,  5.8177e+00,  1.0198e-02,  ..., -3.3892e+00,
          -5.9446e-01, -2.3525e+00],
         ...,
         [ 1.2862e-01,  8.1459e+00, -5.7203e-03,  ..., -4.6210e+00,
          -1.3792e+00, -1.1158e+00],
         [ 1.2448e-01,  9.1910e+00, -2.2729e-02,  ..., -4.6129e+00,
          -1.3089e+00, -1.0112e+00],
         [ 1.0298e-01,  1.0029e+01,  2.3434e-02,  ..., -4.1493e+00,
           3.1903e-01, -2.1057e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.6936, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.2002, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Gulf Gulf Gulf Gulf Gulf Gulf Gulf Gulf Gulf Gulf spill is
iter = 3 reward = 11
final_logits =  tensor([[[ 0.0633,  5.9399,  1.0580,  ..., -2.3608,  1.0976, -2.0838],
         [ 0.1192,  6.5697,  0.1918,  ..., -3.9661, -1.0225, -0.2602],
         [ 0.1175,  6.7952,  0.1598,  ..., -4.1290, -0.8603, -0.4750],
         ...,
         [ 0.1117,  9.5758,  0.1269,  ..., -4.2966, -0.7083, -0.7055],
         [ 0.1443, 10.1122, -0.1147,  ..., -3.2617, -0.9387, -0.4261],
         [ 0.1307, 10.8141, -0.0709,  ..., -2.8988, -0.5640,  0.1895]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(8.9776, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(27.6092, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Gulf Gulf Gulf Gulf Gulf Gulf Gulf Gulf Gulf spill
iter = 4 reward = 10
final_logits =  tensor([[[ 0.0596,  5.6869,  1.0424,  ..., -2.5400,  1.4341, -1.2227],
         [ 0.0917,  7.0610,  0.1075,  ..., -3.7099, -1.1480,  0.3107],
         [ 0.0907,  7.2778,  0.0880,  ..., -3.7665, -0.9574,  0.1566],
         ...,
         [ 0.0935,  9.5890,  0.1003,  ..., -4.0252, -0.6486, -0.3532],
         [ 0.0936, 10.0327,  0.0993,  ..., -3.9809, -0.6860, -0.3823],
         [ 0.1363, 10.6762, -0.1695,  ..., -2.8713, -0.8659, -0.4067]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.5672, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.3389, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  10
10
topic:  ('bpoil_bbc',)
env initialized...

Before training:  38.2% (4204 out of 11019)
{'input_ids': tensor([[[  110,   105,  3893, 15737,  1034,  8255,   464, 16036,   134,   109,
           1816,  2447,   139,  1816,  2447,   649,   126,   117,  4562,   112,
          16036,   118,   203,   337,   983,   762,   121,  2134,  5626,   148,
            174, 12832,   279,   156,   113,   109,  1816,  2447,  1034,   116,
          18072,   141, 10162, 18232,   126,   112,   370,   203, 10971,   818,
            122, 16036,   110,   107,   139,  4635, 41588,   110,   108, 50595,
          81452, 60490,   457,   131,   304,   110,   108,   117,   114,  4055,
          17225,   113,   114,   883,   693,   111, 28286,   111,   117,   160,
           6155,   231,   459,   110,   107,   202,   456,   568,  7200,  9221,
           3893,  2777,   165,   109,  8255,   110,   107,   202,   984,  8255,
           4635, 20678,  4329,   115,  1185,   110,   107,   139,  1816,  2447,
            243,   109,  5626,  1065,   140, 39059,   110,   108,   162,   196,
            146,  3954,   109,  4976,  2098, 11976,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Hoa
iter = 0 reward = 0
final_logits =  tensor([[[ 0.2403,  3.7181,  1.0525,  ..., -1.8989,  0.7850,  0.1094],
         [ 0.3332, 13.5511,  0.8905,  ..., -0.1427, -0.3370, -0.4450]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.0254, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.3979, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
giant
iter = 1 reward = 0
final_logits =  tensor([[[ 0.2784,  2.8316,  1.0973,  ..., -2.2664,  0.2334, -0.3718],
         [ 0.2340, 13.5614,  0.2256,  ..., -0.5269,  0.4953,  0.1627]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.5483, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.7646, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
A
iter = 2 reward = 0
final_logits =  tensor([[[ 0.2726,  4.1288,  1.0418,  ..., -2.4050,  1.0009, -0.4365],
         [ 0.1692, 11.0542,  0.4163,  ..., -1.1988, -0.0723, -0.7228]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-7.9601, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(15.2716, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)
Hoa
iter = 3 reward = 0
final_logits =  tensor([[[ 0.2951,  4.6111,  1.1466,  ..., -3.0573,  0.6512, -0.1370],
         [ 0.2200, 12.0914,  0.2275,  ..., -0.0267, -0.9222,  0.4444]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4791, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3031, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)
Hoa
iter = 4 reward = 0
final_logits =  tensor([[[ 0.3109,  4.6263,  1.1432,  ..., -2.6851,  0.7530, -0.1859],
         [ 0.2225, 12.1025,  0.1951,  ...,  0.1018, -0.9795,  0.3575]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.5523, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.0075, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 4123,   113,   219,  6234,   195,  6908,   115,   109, 75158,  1153,
           3893,  1419, 16036,   148,  6305,  3906,   142, 10580,   805,   113,
            203,  7175,   113,  3064,   762, 14567,  1407,  1104,   124,   203,
            387,   110,   107,   139,  1082,   110,   108,  1155,   204,   109,
           1339,   110,   108,   939,  1841,   115,   683,   113,   114,  1679,
            113,   461,  6234, 10361,  1055,   113,   203,  3954,   210,   124,
            109,  1917,  1030,   110,   107, 16036,  9619,  3582,  7217,   243,
            120,   339,  6234,   195,  6908,   115,   109,   856,  1153,   111,
          10390,   680,   196,   174,   263,   112,   535,  1055,   110,   107,
            139, 10580,   805,   140,  3530,   122,   109,   856,   244,   114,
            787,  9024,  8666,   126,   110,   107,  1263,  7217,   243,   109,
           4787,   170,   635,   109,  1153,   140, 10361,   169,   766,   122,
          10390,   680,   111,   186,   140,   220,  5313,  6596,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)
Scott Dean Dean Dean Dean Dean Dean Dean Dean
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1456,  4.8088,  0.7512,  ..., -4.4065,  0.3606,  2.0356],
         [ 0.0888,  5.5650,  0.1454,  ..., -2.9586, -1.5248, -1.2431],
         [ 0.1175,  5.1463, -0.1838,  ..., -3.7816, -2.1513,  0.1043],
         ...,
         [ 0.1351,  8.9266, -0.3043,  ..., -3.5397, -2.1485, -0.2647],
         [ 0.1362,  9.2584, -0.3051,  ..., -3.5175, -2.2028, -0.3718],
         [ 0.1379,  9.9354, -0.3124,  ..., -3.4431, -2.2414, -0.4829]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.6332, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.1660, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
Scott Dean Dean Dean of
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1574,  5.0956,  0.7261,  ..., -3.4350, -0.2114,  1.7459],
         [ 0.0993,  5.8011,  0.1137,  ..., -2.7707, -1.9525, -0.8480],
         [ 0.1298,  6.6441, -0.2561,  ..., -3.3626, -2.4574,  0.6267],
         [ 0.1278,  7.1939, -0.3085,  ..., -3.3287, -2.5394,  0.6344],
         [ 0.1347,  8.7952, -0.3622,  ..., -3.0965, -2.4573,  0.3741],
         [ 0.1314,  9.8163, -0.3636,  ..., -3.4664, -0.4374, -0.5775]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.2013, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.5747, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Scott
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1569,  5.3012,  0.7288,  ..., -3.6491, -1.6953,  1.1646],
         [ 0.1245, 11.4836,  0.1973,  ..., -2.8876, -2.4491, -1.3991]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8480, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5413, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
Scott Oil screens screens screens
iter = 3 reward = 1
final_logits =  tensor([[[ 0.1431,  5.0761,  0.6490,  ..., -4.9674, -0.7693,  1.6601],
         [ 0.1018,  7.5184,  0.1609,  ..., -4.4447, -2.8834,  1.6520],
         [ 0.1107,  7.6182, -0.1487,  ..., -3.4942, -2.2053,  0.5968],
         [ 0.1167,  9.2905, -0.3410,  ..., -2.8511, -1.9826, -0.3370],
         [ 0.1195,  9.8059, -0.3778,  ..., -2.7250, -2.3508, -0.5267],
         [ 0.1258, 10.4295, -0.3911,  ..., -2.3541, -2.7325, -0.4389]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.3923, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.1841, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Dean
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1253,  5.8523,  0.5909,  ..., -5.4995, -0.4821,  1.0509],
         [ 0.1552, 11.0600, -0.1598,  ..., -3.6896, -2.4659, -0.0841]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.3896, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.1321, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[599, 960, 110,  ..., 109, 804,   1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 39.0% (4296 out of 11019)

Everytime after generating next logits 39.0% (4296 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1974,  2.8132,  0.7626,  ..., -1.1626,  2.1675,  0.1648],
         [ 0.1493, 11.0405, -0.2467,  ...,  0.4060, -0.7210, -0.7282]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.0253, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.9907, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1875,  2.7017,  0.7351,  ..., -1.3481,  1.8929,  0.6374],
         [ 0.1405, 11.3489, -0.3179,  ...,  0.2099, -0.7940, -0.7725]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4830, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.0011, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1722,  2.7016,  0.6429,  ..., -1.5493,  1.6379,  0.7709],
         [ 0.1255, 11.8587, -0.3700,  ...,  0.0323, -0.7554, -0.8914]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6273, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.9639, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[ 0.1549,  2.6438,  0.6328,  ..., -1.6628,  1.8146,  0.6323],
         [ 0.1090, 12.1299, -0.3829,  ...,  0.1300, -0.6897, -0.9373]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0043, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[ 0.1291,  2.2114,  0.6112,  ..., -1.7113,  1.7937,  0.8157],
         [ 0.0952, 12.2857, -0.4110,  ...,  0.1454, -0.7579, -0.9338]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6266, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.5734, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[6174,  692,  110,  ...,  526,  115,    1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1237,  3.4799,  0.6414,  ..., -4.8793, -0.7021,  0.6574],
         [ 0.1679, 10.4131, -0.1915,  ..., -2.0269, -0.7732, -0.8461]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.5489, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.8692, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1681,  7.4911,  0.9204,  ..., -3.6843,  0.0809, -0.5844],
         [ 0.1605, 11.6188, -0.0472,  ..., -3.4419, -0.6173, -0.4364]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.5749, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(13.0519, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1090,  4.0060,  0.6763,  ..., -4.6317,  0.7531,  1.8790],
         [ 0.1184, 12.6915, -0.2373,  ..., -1.2834, -0.3654, -0.8175]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9130, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.9940, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
biggest
iter = 3 reward = 1
final_logits =  tensor([[[ 9.0376e-02,  2.8914e+00,  5.2601e-01,  ..., -4.9567e+00,
          -7.0139e-03, -1.1684e+00],
         [ 7.7072e-02,  1.0263e+01,  1.1173e-01,  ..., -3.8474e+00,
          -1.5626e+00, -1.3214e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-6.3990, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.5402, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
U
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0952,  3.0484,  0.3801,  ..., -5.1313,  0.0871, -0.7964],
         [ 0.1025, 12.6003,  0.4255,  ..., -1.0026, -1.0901, -1.4122]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-8.2908, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(14.3882, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  139,  5543,  9254,   320,  3702,   142,   865,   728,   113,   109,
          16036,   762, 14567,   110,   107,  8916,   114,  1713,   113,  5012,
            122,   662,   503, 32908,   110,   108,   330,   278,  2668,   116,
            122,  4605, 35522,   110,   108,   109,   177,  3378,   113, 16036,
            111,  6061, 32886,   110,   108,   169, 15978,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)
Features
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0591,  3.2817,  0.3585,  ..., -3.1802,  0.4355, -0.1051],
         [ 0.0662, 12.1081, -0.4719,  ..., -2.4108, -2.4090, -1.1310]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.2852, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(35.1149, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Features
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0794,  3.2199,  0.4811,  ..., -2.0490,  0.4687,  0.3350],
         [ 0.0850, 12.3523, -0.3372,  ..., -0.9363, -1.1916, -0.4832]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9408, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(10.5515, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
Features
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0927,  3.2186,  0.4619,  ..., -2.4206,  0.2841,  0.2634],
         [ 0.0920, 12.2645, -0.3367,  ..., -1.0532, -1.3352, -0.5388]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3554, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.9097, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
Features
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1045,  3.2891,  0.4530,  ..., -2.6338,  0.1142,  0.2341],
         [ 0.0991, 12.1477, -0.3355,  ..., -1.2071, -1.5347, -0.6060]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7074, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9715, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
Features
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1124,  3.4937,  0.4588,  ..., -2.5997, -0.1307,  0.1428],
         [ 0.1048, 12.0316, -0.3399,  ..., -1.3462, -1.8317, -0.7249]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.5428, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.3679, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1084, 18756,   110,  ...,  5135,   378,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)
Interior Secretary Secretary Salazar
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1175,  4.2167,  0.6844,  ..., -4.7207,  1.9462,  1.7504],
         [ 0.0705,  5.5534,  0.5976,  ..., -1.9569,  0.4790, -0.5233],
         [ 0.0805,  9.9302,  0.2333,  ..., -1.0696,  0.6883,  0.8915],
         [ 0.0776,  9.7734,  0.2004,  ..., -0.9807,  0.8031,  1.3404],
         [ 0.0633, 12.1073, -0.2341,  ..., -1.3891, -0.5711,  0.0594]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.7541, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.8730, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4162 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 39.5% (4354 out of 11019)
Environment Environment Environment
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1069,  2.3177,  1.0030,  ..., -5.8536,  0.6358,  1.6941],
         [ 0.0380,  8.7271,  0.0664,  ..., -4.0608, -1.5226, -1.6650],
         [ 0.0341, 10.4310, -0.0699,  ..., -3.8419, -1.5842, -2.1239],
         [ 0.0354, 11.8196, -0.1345,  ..., -2.7447, -1.2469, -1.9878]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.4946, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.5245, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)
Environment Environment Environment
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1016,  1.9691,  1.0728,  ..., -5.6214,  1.0827,  0.9047],
         [ 0.0302,  9.4626,  0.0874,  ..., -3.9964, -1.2151, -2.0069],
         [ 0.0296, 11.1460, -0.0497,  ..., -3.7049, -1.2914, -2.4235],
         [ 0.0344, 11.8450, -0.1232,  ..., -2.5796, -1.1360, -2.1372]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.2962, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.7998, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)
Environment Environment Environment Environment Environment Environment Environment Environment
iter = 3 reward = 0
final_logits =  tensor([[[ 7.2961e-02,  2.3159e+00,  8.7212e-01,  ..., -6.3288e+00,
           9.1765e-01,  1.4338e+00],
         [ 1.1366e-02,  3.3049e+00, -2.3460e-02,  ..., -4.5673e+00,
          -1.5768e+00, -1.7760e+00],
         [ 5.3694e-03,  3.7449e+00, -1.1953e-01,  ..., -4.6877e+00,
          -1.7046e+00, -2.3409e+00],
         ...,
         [ 6.6151e-03,  7.6697e+00, -3.2732e-01,  ..., -4.0870e+00,
          -1.8399e+00, -3.5819e+00],
         [ 8.0376e-03,  8.9759e+00, -3.5943e-01,  ..., -3.7502e+00,
          -1.8490e+00, -3.6548e+00],
         [ 1.1744e-02,  1.0461e+01, -3.9150e-01,  ..., -3.2599e+00,
          -1.8356e+00, -3.6251e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5964, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6421, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4236 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)

Everytime after generating next logits 39.6% (4364 out of 11019)
Environment Environment Environment Environment Environment Environment Environment Environment Environment
iter = 4 reward = 0
final_logits =  tensor([[[ 4.9617e-02,  1.6429e+00,  8.3838e-01,  ..., -6.6015e+00,
           1.5044e+00,  1.6054e+00],
         [-8.7866e-03,  2.8973e+00, -7.3524e-02,  ..., -4.3423e+00,
          -1.3825e+00, -1.9544e+00],
         [-1.1989e-02,  3.4543e+00, -1.6462e-01,  ..., -4.5141e+00,
          -1.5275e+00, -2.4518e+00],
         ...,
         [-3.9316e-03,  8.7449e+00, -3.6340e-01,  ..., -3.4947e+00,
          -1.8351e+00, -3.7153e+00],
         [ 1.9439e-04,  1.0251e+01, -3.8838e-01,  ..., -3.0463e+00,
          -1.8403e+00, -3.6941e+00],
         [ 4.6035e-03,  1.1611e+01, -4.2578e-01,  ..., -2.5700e+00,
          -1.8447e+00, -3.6132e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.0305, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3260, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   243,   186,  ...,   111,  2684,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)
There
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1354,  7.7742,  1.0755,  ..., -0.9380,  0.8402,  2.4661],
         [ 0.1096, 12.4011, -0.0347,  ..., -0.9280, -0.3538,  0.7029]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7567, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9661, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1086,  7.9878,  0.8971,  ..., -0.7692,  0.8617,  2.5439],
         [ 0.0992, 12.9594, -0.0513,  ..., -0.6370, -0.1066,  1.0425]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1896, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1581, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1132,  7.6915,  0.8621,  ..., -0.6547,  1.4167,  1.5050],
         [ 0.0906, 13.1499, -0.0791,  ..., -0.2300,  0.3108,  0.4565]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0269, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1954, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1222,  7.0278,  0.8485,  ..., -1.2835,  1.6933,  0.6866],
         [ 0.0806, 13.2268, -0.1028,  ..., -0.2713,  0.1829,  0.1573]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0032, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9754, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1228,  6.1595,  0.7426,  ..., -2.8324,  2.1162, -0.7929],
         [ 0.0684, 13.4370, -0.1379,  ..., -0.4553,  0.1897, -0.0432]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0797, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.4852, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036, 35640,   116,  ...,  3598, 32220,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[ 6.0570e-02,  2.3735e+00,  9.2948e-01,  ..., -2.9360e+00,
           8.6915e-01,  1.9695e+00],
         [ 1.6399e-03,  1.2227e+01, -3.8313e-01,  ...,  9.4238e-02,
          -6.8640e-01, -1.8444e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.0176, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.0052, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Estimate
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0402,  2.0307,  0.9469,  ..., -2.0091,  0.9597,  1.9877],
         [ 0.0229, 11.9223, -0.3662,  ..., -1.2507,  0.3640, -0.4434]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.3078, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.3933, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Ice dome
iter = 2 reward = 2
final_logits =  tensor([[[ 7.2719e-02,  2.1475e+00,  7.3827e-01,  ..., -2.0445e+00,
           1.3391e+00,  1.5783e+00],
         [ 4.5920e-02,  1.1344e+01,  2.3805e-01,  ...,  8.7075e-02,
          -5.0354e-01,  1.4922e+00],
         [ 1.1025e-02,  1.1210e+01, -4.3848e-02,  ...,  2.8879e-01,
          -5.4244e-01,  1.2498e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0916, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.3366, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Ice dome
iter = 3 reward = 2
final_logits =  tensor([[[ 5.0936e-02,  2.2928e+00,  6.8572e-01,  ..., -2.9499e+00,
           8.6293e-01,  1.4176e+00],
         [ 6.0615e-02,  9.2705e+00,  3.0908e-01,  ...,  2.1212e-01,
          -3.1956e-01,  1.6583e+00],
         [ 1.0458e-02,  1.1463e+01, -5.2110e-02,  ...,  2.7719e-01,
          -6.1185e-01,  1.2736e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4023, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.0814, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Ice dome
iter = 4 reward = 2
final_logits =  tensor([[[ 0.0705,  2.1379,  0.7711,  ..., -2.6542,  0.8562,  1.0924],
         [ 0.0749,  6.1965,  0.4465,  ...,  0.7855, -0.2789,  2.4597],
         [ 0.0197, 11.8828,  0.1750,  ...,  0.6117, -0.9895,  1.9042]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3113, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.1643, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  787,  1276, 12998,  3531,   148,  4486, 18205, 53857,  7028,   112,
          15079,   109,  3662,   599, 10970,   233, 20447,   788,   121,  1768,
          43304,   110, 10970,   233, 16567,   788,   121,  2617,   120, 16036,
            148,   323,   164,   112, 13889,  4807,   113,   109,  7175,   113,
           3064,   762, 14567,   110,   107,  1263, 53857,  7028,   148,   306,
            115,   253,  2887,   110,   151,   178,  3120,   109,  4807,  1034,
           1844,  2617,   323,   164,   115,   109,  4619,   113,   109,  1073,
           1338,  6687,  3613,   115,   351,   859,   111,  1741,   110,   107,
            285,   148,   243,   178,   117,   146, 10237,   122,   109,   657,
            132, 16036,   111,   138, 15079,   109,  2617,  7539,   110,   107,
           2632,   138,   719,  3916,   135,   109,  2617,   110,   152,   139,
            762, 14567,   148,  2145, 12071,   466,   109,   787,  7175,  3500,
            110,   108,  7271,  3070,   111,  5569,   111, 65047,   181,  4758,
            111, 44650, 18205, 53857,  7028, 35571,  3916,   118,  4807,   113,
            109,  1073,  1338,   110,   108,  6687,  3613,  7922,  8749, 18205,
          53857,  7028, 18097, 16915,   918,   111,   243,  2784,   192,   129,
            154,  5263,   197,   274,   120,   192,   129,  3366,   141,   114,
           1462,   110,   107,   343,   178,   243,   274,  2486,  3916,   355,
            361,   164,   153,   268,   112, 17984, 16036,   110,   107,   139,
           2617,   117,   112, 34262,  7175,   113,  3064,  1836,   111,  1098,
            118,  1166,  9125,   111,  5471,   111,   118,   510,  3207,   111,
           1003,   121,   768,   110,   108,   790,   176,  2242,   110,   107,
          16036,   148,   506,  1389,  3662,   110, 37622,   208,   115,  2242,
            381,   109,   960, 14567,   110,   107,   139,   762, 14567,   110,
            108,   162,  1219,   599,   960,   122,   109, 11335,   113,   109,
          16036,   121, 38539,   252, 81065, 18308,  9600, 13773,   110,   108,
           2145,  8010, 12071,   466,   109,   787,  7175,  3500, 18205, 53857,
           7028, 35571,  3916,   118,  4807,   113,   109,  1073,  1338,   110,
            108,  6687,  3613,   139,  8749,   113,   114,  3662,   599, 10970,
            233, 20447,   788,   121,  1768, 31197,   110, 10970,   233, 16567,
            788,   121,  2617,   112, 13889,  4807,   113,   109, 16036,   762,
          14567,   148,   243,   186,   117,   110,   105,   220,  2767, 16837,
            120, 15931,  2242,   127,   142,   797,   110,   107, 18205, 53857,
           7028, 18097,   112,   129, 24915,   204,   170,   915,  2784,   112,
           1480,   109,  4959,   113,   109,  2617,   110,   107,  3440,  3662,
          12622,   110, 10970,   148,   506,   174,  1389,   165,   115,  2280,
           2784,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Claims
iter = 0 reward = 0
final_logits =  tensor([[[ 0.2078,  3.4492,  0.8962,  ..., -2.0449,  1.8411,  0.5683],
         [ 0.1006, 12.2328, -0.4205,  ..., -1.0145,  0.5189, -0.5157]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8838, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.7513, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Claims
iter = 1 reward = 0
final_logits =  tensor([[[ 0.2001,  3.6219,  0.8699,  ..., -1.9060,  1.7149,  0.8129],
         [ 0.0925, 12.3387, -0.4113,  ..., -0.9311,  0.5238, -0.5305]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2283, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1889, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Claims
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1929,  3.8162,  0.8615,  ..., -1.7668,  1.6955,  0.8178],
         [ 0.0813, 12.5134, -0.3647,  ..., -0.8164,  0.4003, -0.5075]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2543, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3540, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
Claims
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1800,  4.2304,  0.8151,  ..., -1.7102,  1.5243,  0.2505],
         [ 0.0705, 12.6056, -0.3167,  ..., -0.6642,  0.2738, -0.4077]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9456, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8277, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)

Everytime after generating next logits 37.7% (4158 out of 11019)
April
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1672,  4.8616,  0.8767,  ..., -0.8610,  0.7585, -0.1783],
         [ 0.0309, 12.1306,  0.0765,  ..., -0.8447, -0.8546,  0.0861]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.7770, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.0905, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787,   762, 14567,   110,   151, 15265,  7788,   110,   105,   124,
            109,  2143,  1034,  1027,  3070,  6375,   127,   239,   270,   263,
            112,   225, 16036,   562,   109, 15737,  2584, 51128,   116, 10928,
           1034,   116,  3070,  2414,   148,  7646,   339,   698, 26680,   233,
          37399,   110,   108, 35493,   111, 23363,   110,   107,   110,   105,
            600,   480,   140, 12144,   110,   108,   155,   265,  7646,   110,
            108, 16837,   178,   649,   110,   108,  1132,   109,  2414,   114,
           4081, 15115,   110,   107,   343,  1263, 51128,   116, 10928,  7719,
            180,   138,  4428,   169,  1162,  3070,   260,   559,   111,   118,
            149,   117,   146,   114,   710,  5135,   110,   108,   155,   114,
            729,   121,  4109,   156,   110,   107,   202,   729,  1034,   116,
            419,   112,   133,   114,   715,   110,   108,   181,   660,   113,
            523,   134,   109,   370,   113,   109,  8483, 16837,  4645, 16848,
           2584, 51128,   116, 10928,  7915, 25996,   110,   105,  2184,  6021,
            134,   214,   173,   145,   416,   136,   762, 14567,   256,   129,
           3150,   197, 23363,   110,   108,   155,   145,   114,   457,  3178,
            131,   144, 34742,   110,   108, 16837,   178,   649,   110,   107,
            398,   178, 41593,   164,   114,  1124,  2944,   113,  9606,  6545,
            115,   109,  2414,  1034,   116,  7270,   110,   108,  2584,   649,
            178,   117,  5238,   120,   109, 14567,   138,   129,   289, 13502,
            118,   223,   200,   115,   136,  3820,   121, 23623,  3070,   427,
            113, 38584,  1946, 11958,   144,   216,   110,   108,  7915, 29546,
           3070,   148,   174,  7162,   115,  7915,   262,   113,   109, 14567,
          10250,  1034,   116,  1750,   110,   108,  1946, 74523,   110,   108,
           5765,   122,   342,   111,  2779,   112,  7904,   110,   107,   110,
            105, 15265,   117,   169,   271,   110,   108,   347,   126,   178,
            358,  3178,   131,   144,   235,   742,   997,   110,   108, 16837,
            265,   649,   110,   107,   110,   105,   285,  1034,   116, 13735,
            110,   107,   285,  1034,   116,  7432,   134,   488,   110,   107,
            285,  1034,   116,   146,   109,   310, 29546,   420, 15538, 90155,
            110,   151,   110,   105,   168,   978,   172,   114, 10447,  1120,
            279,   264, 16837, 16036,   148, 20350,  5478,   113, 63981,  7881,
            333,   109,  7175,   113,  3064,   762, 14567,   110,   108,   155,
            186,   127,   274,   170,   127,  1192,   126,  2773,  7427,   118,
            109,   201,   126,   117,   557,   110,   108,  6260,   109,  6442,
           1034,   116,  6869,  3544,   115,  7915,   110,   107, 46095,   126,
            110,   108,   155, 16036,   117,   146,   114,  6749,  1172,   264,
            115,   109,  6805,  1120,   113,  7026, 63116, 58439,   110,   107,
            222,   109, 10601,  1034,   116,   629,   110,   108, 14515,   429,
            115,   114,  1120,  4511,   120,   117,   239,   163,   238,   112,
          16036,  1034,   116,   648,   115,   136,   297,   113,  7915,   110,
            108,   623,   391,  1725,  2051,   279,   115,  4555,   523,  1490,
          21955,  8802,   110,   107,   110,   105,   184,  1034,   216,   146,
            314,   785,   118,  1609,   126,   110,   108,   155,   264, 16036,
           1034,   116,   557,   234,   110,   108, 16837,   156,   649,   110,
            107,   353,  1034,   116,   956,  2158,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Mayor joked he joked he was not not not not not not not not to
iter = 0 reward = 0
final_logits =  tensor([[[ 2.8461e-02,  5.7374e+00,  4.1410e-01,  ..., -3.8747e+00,
          -2.9204e-03, -2.0887e+00],
         [-6.9241e-03,  5.0796e+00, -9.6107e-02,  ..., -3.7265e+00,
          -3.1588e+00, -2.2000e+00],
         [ 3.9499e-02,  7.2016e+00, -3.6479e-01,  ..., -3.4791e+00,
          -2.0191e+00, -2.1725e+00],
         ...,
         [-3.4769e-02,  7.5528e+00, -4.2144e-01,  ..., -4.8233e+00,
          -2.1485e+00, -1.3131e+00],
         [-3.6422e-02,  7.4582e+00, -4.4439e-01,  ..., -5.0183e+00,
          -2.1706e+00, -1.2340e+00],
         [-3.4482e-02,  1.0705e+01, -4.6210e-01,  ..., -3.7933e+00,
          -1.8606e+00, -1.0474e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-18.4578, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(54.0003, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
BP offers BP to
iter = 1 reward = 2
final_logits =  tensor([[[ 0.0549,  2.3859,  0.5931,  ..., -5.2927,  0.0501, -1.8090],
         [-0.0267,  3.8519, -0.6920,  ..., -3.2747, -3.5599, -2.1516],
         [ 0.0337,  8.7031, -0.4566,  ..., -3.9601, -0.8442, -1.1940],
         [ 0.0336,  8.8426, -0.8190,  ..., -2.8350, -1.7906, -1.8577],
         [ 0.0344, 12.4542, -0.4068,  ..., -2.4778, -0.8013,  0.5113]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.2945, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.2103, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)
BP jokes about
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0760,  1.9897,  0.5663,  ..., -5.8911,  0.5614, -1.8106],
         [-0.0131,  4.2527, -0.7200,  ..., -3.9177, -3.6719, -2.4415],
         [ 0.0772,  8.4419, -0.6027,  ..., -3.4133, -1.1189, -2.3499],
         [ 0.0633, 10.2990, -0.4371,  ..., -4.9018, -1.4501, -1.8349]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.9219, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.6549, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP jokes about how we were 
iter = 3 reward = 1
final_logits =  tensor([[[ 9.5557e-02,  1.9001e+00,  5.5168e-01,  ..., -5.8851e+00,
           7.1674e-01, -1.7516e+00],
         [ 4.6220e-03,  4.2735e+00, -6.8724e-01,  ..., -4.1172e+00,
          -3.4669e+00, -2.1374e+00],
         [ 1.0037e-01,  7.5329e+00, -5.9049e-01,  ..., -3.7052e+00,
          -1.2252e+00, -2.4646e+00],
         ...,
         [ 5.7189e-02,  6.7272e+00, -5.4061e-01,  ..., -6.9737e-01,
          -1.3310e+00, -1.5662e+00],
         [ 6.8906e-02,  6.7692e+00, -5.6687e-01,  ..., -4.2323e+00,
          -1.3253e+00, -1.2962e+00],
         [ 7.2793e-02,  1.2667e+01,  8.2371e-02,  ..., -3.1952e+00,
          -9.8091e-01, -4.0179e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.5261, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.1838, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
BP jokes about how we were we was 
iter = 4 reward = 1
final_logits =  tensor([[[ 0.1170,  2.0661,  0.5361,  ..., -5.6187,  1.1920, -1.6133],
         [ 0.0232,  3.4077, -0.6507,  ..., -4.1278, -3.3158, -1.8467],
         [ 0.1196,  4.9611, -0.5922,  ..., -3.7267, -1.0545, -2.3225],
         ...,
         [ 0.0794,  2.9181, -0.5153,  ..., -2.0997, -1.3484, -1.8719],
         [ 0.0865,  3.8229, -0.5912,  ..., -4.3331, -1.2851, -1.0826],
         [ 0.0959,  9.7486,  0.1066,  ..., -3.5021, -1.2347, -0.1267]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.8817, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(13.3659, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  608,  1338,  2652,  2882,  2033,   134,   305, 91516, 17403,  4596,
            202,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   115,   109,  7175,   113,  3064,   110,   108, 16036,
            649,   110,   107,   983,  3244,  2777,   165,   141, 16036,   649,
            126,   140,  1470,   115,   297,   118,   109,  5135,   110,   108,
            155,   163,  1262,   181,  6511,   124,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,   608,
           1338,  2652,  2882,  2033,   134, 71437, 17403,  4596, 16036,   148,
           1788,   114,  1933,   545,   162,   939,   109,   301,  1034,   116,
            700,   113,   702,   964,   164,   112,   109,  7175,   113,  3064,
            762, 14567,   110,   107,  2973,   112,   109,   301,   110,   108,
            114,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   110,   107,   983,  3244,  2777,   165,   141, 16036,
            243,   120,   126,   140,  1470,   115,   297,   118,   109,  5135,
            110,   108,   155,   126,   163, 17188,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
Last year
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1846,  6.9829,  0.8094,  ..., -3.8954,  1.3051,  0.1273],
         [ 0.1117,  7.1902, -0.0431,  ..., -4.2068, -0.4988,  0.8723],
         [ 0.1054,  9.7048, -0.3324,  ..., -3.0104, -1.1107, -0.5415]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.9959, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.5324, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
on September
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1564,  4.8750,  0.1264,  ..., -3.4964, -0.7323, -1.1642],
         [ 0.1806,  7.2506, -0.0681,  ..., -3.2630, -1.1693, -1.2927],
         [ 0.0948, 12.0609, -0.2265,  ..., -0.7140, -1.1507, -0.8445]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.0003, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(15.1097, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
on September
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1444,  4.9338,  0.2531,  ..., -3.4282, -1.0909, -1.3423],
         [ 0.1714,  6.4588, -0.0564,  ..., -3.8543, -1.4547, -1.5202],
         [ 0.0843, 12.1891, -0.2853,  ..., -0.7875, -1.0708, -0.9690]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.7251, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.7140, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
on September
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1308,  4.5568,  0.2736,  ..., -2.7888, -1.3367, -0.5808],
         [ 0.1559,  5.6496,  0.0343,  ..., -3.6614, -1.4884, -1.0522],
         [ 0.0863, 12.2366, -0.2890,  ..., -0.7461, -1.4936, -1.1616]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.4711, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.3858, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
on September
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1170,  4.5128,  0.2805,  ..., -2.2293, -1.9790, -0.2541],
         [ 0.1477,  6.0176,  0.0775,  ..., -2.7980, -1.6621, -0.8106],
         [ 0.0831, 12.2944, -0.2923,  ..., -0.6589, -2.0021, -1.5841]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1897, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.0880, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  530,  1268,  2651,  2882,  2033,   134, 80621, 17403,  4596, 25688,
            115, 16036,  1963,   902,   124,  1789,  2409,   114,   787,  7501,
           5268, 79701,   109,   762,   301,  1034,   116,  4206,   111, 12856,
            130,   210,   130, 16036,   118,   109,  7175,   113,  3064,   762,
          14567,   110,   107,   139, 11335,   134,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,  1024,   111,  1358,   112,   109,  1368,
            521,  9134,   762,  8186,   110,   107,  4987,   109,  4469,   110,
            108, 16036,  2853,  3947,   607,  2527,   110, 43995,   118,   109,
            211,   166,   381,   913,   289,   232,   110,   107,  6442,   260,
          21089, 80736, 82734,  4278,  3886,   112,  5930, 37313,   110,   108,
            142,   762,  8962,   122, 85411,   116,  1714,   208, 59297, 20185,
            110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
Last
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1296,  5.8149,  0.7313,  ...,  0.4970,  0.1931,  0.9781],
         [ 0.0692, 11.2306, -0.0653,  ..., -0.8326,  0.2282,  1.0549]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1456, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0950, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0854,  4.7138,  0.5667,  ...,  0.5775,  0.4911,  0.2207],
         [ 0.0737, 12.4848, -0.1234,  ..., -1.3146, -2.1676, -0.1680]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7000, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1625, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor killed
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0673,  4.3759,  0.3840,  ..., -1.1171,  0.5990,  0.2725],
         [ 0.0382, 12.2524, -0.1981,  ..., -2.1069, -2.2189,  0.3390],
         [ 0.0528, 12.1435, -0.2204,  ...,  0.5441,  0.0764, -0.8789]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.9826, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3812, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
McGregor
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0609,  4.2840,  0.3274,  ..., -1.1165,  0.5999, -0.3242],
         [ 0.0298, 12.1170, -0.2037,  ..., -2.1346, -2.0642,  0.5833]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2114, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2917, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
McGregor opened
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0533,  4.2282,  0.2743,  ..., -0.9799,  0.6103, -0.7212],
         [ 0.0284, 11.6661, -0.2118,  ..., -2.1339, -1.9773,  0.7824],
         [ 0.0279, 12.5332, -0.1269,  ...,  0.3426,  0.6656, -0.2758]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0612, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1210, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3788,   110,   108,   258,   111,  1183,   109,  4193,   120,  5887,
            119,  3788, 22017,  3249,  2309,   114,  4340,   132,  2162,   110,
            108,   132,   989,  6502,   115,   150,   545,  1771,  6180,   114,
           4340,   493,   126,   586,   112,   258,   165,   241,   111,   173,
            157,   133,  6502,   110,   107, 14845,   127,  1661,   115,   156,
            295,   110,   108,  2063,   119,  1235,   111,   400,   489,   110,
            107, 21556,   116,  4170, 16036,   762, 14567,  1736,   651,  1265,
           1185,  2652,   110,   108,  3013,   111,  9792,  5297,  5299,  2346,
           3601,  2567,  7499,   114,  1736,   266,  1678,   115,   109, 11319,
            124,   109, 16036,   762, 14567,   110,   107,  2346,  3601,  2567,
            898,  6949,   120,   142,  8635,   933,   113,  1647,   196,   506,
            174,  9889,   110,   108,   155,   701, 51098,   192,   129,   656,
            130,  6031,  1219,   115,  4190,  6500,  3381,   113, 43278,   110,
            107,   139,   657,   148, 18097,   112,   110,   105,   543,   109,
           2919,   113,   219,  6209,   702, 16837,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Peer Peer Peer
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0369,  4.5693,  0.2750,  ..., -2.8716, -0.9359, -2.7378],
         [ 0.0696,  9.7631, -0.1292,  ..., -2.8957, -2.1600, -1.6485],
         [ 0.0661,  9.9429, -0.2068,  ..., -2.6678, -1.9856, -1.4888],
         [ 0.0699, 10.7326, -0.2174,  ..., -2.3371, -1.8436, -1.4270]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.9449, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(36.3859, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Find Find further further vigilance
iter = 1 reward = 0
final_logits =  tensor([[[ 4.5470e-02,  4.7779e+00,  2.7614e-01,  ..., -2.9154e+00,
          -1.2864e+00, -3.0870e+00],
         [ 1.1165e-01,  6.2299e+00,  1.3770e-02,  ..., -3.1829e+00,
          -4.6838e-01, -2.8681e+00],
         [ 1.1472e-01,  5.9108e+00,  8.5884e-03,  ..., -3.1779e+00,
          -4.6629e-01, -2.7368e+00],
         [ 6.6234e-02,  7.6720e+00,  1.2244e-01,  ..., -2.0598e+00,
          -1.2533e+00, -6.3262e-01],
         [ 6.1802e-02,  8.5902e+00,  1.3416e-01,  ..., -1.7370e+00,
          -1.1282e+00, -5.5133e-01],
         [ 7.2749e-02,  1.2228e+01, -3.2958e-01,  ..., -1.8519e+00,
          -2.0198e+00, -2.1666e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-8.6431, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(15.4474, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)

Everytime after generating next logits 38.0% (4192 out of 11019)
Marlandland: Government government will be
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0574,  5.8313,  0.3216,  ..., -2.3348,  0.0132, -2.3407],
         [ 0.0922,  6.0012,  0.1639,  ..., -0.2360, -0.4191, -0.0337],
         [ 0.1000,  5.7418, -0.3209,  ..., -2.0274, -1.8873, -0.3723],
         ...,
         [ 0.0522,  6.1281, -0.6651,  ..., -2.0012, -3.0861, -2.9245],
         [ 0.0248,  5.5027, -0.3146,  ..., -2.3124, -2.4522, -0.1857],
         [ 0.0581,  9.7696, -0.1363,  ..., -2.4831, -1.4776, -0.8029]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.6675, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(18.7257, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Climate minister
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0902,  5.3203,  0.4089,  ..., -1.2780,  1.1131, -1.2558],
         [ 0.0512,  7.5388, -0.0533,  ..., -1.1398, -0.8127, -0.6906],
         [ 0.0923, 11.3247, -0.2410,  ..., -1.2570, -2.3262, -1.3116]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4113, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3028, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
Peers spoken to about how to have been a spill in
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0908,  4.1071,  0.5183,  ..., -2.2985,  0.6429, -1.5263],
         [ 0.1319,  2.2438, -0.2830,  ..., -3.0189, -2.5298, -0.7239],
         [ 0.1144,  4.8085, -0.2505,  ..., -2.7152, -3.4401, -2.4214],
         ...,
         [ 0.0453, 10.5241, -0.4584,  ..., -0.2738,  0.6289,  0.2861],
         [ 0.0539, 10.1216, -0.8077,  ...,  0.0351, -1.7853,  0.0632],
         [ 0.0541, 11.0751, -0.7507,  ..., -0.6479, -1.3959, -0.1859]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0561, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6808, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 1428,  1307,  2652,  2882,  2033,   134, 84838,   726, 17403,  4596,
          16036,   148,  1939,   114,   177, 14464,  3889,   124,   109, 14154,
           7175,   113,  3064,   762,   210,   110,   108,   301,  2662,   416,
            110,   107,   168,   117,  8549,   109,   177,  3889,   138,   923,
            109,  8186,   111,  3155,   109,   762,   269,   154,   113,   126,
            137,  6218,   190,   109,  1917,   155,   126,   256,   129,   372,
            228,   390,   269, 16036,   235,   682,   109,   807,  2353,   117,
           1147,   110,   107,   139, 11335,   113,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,   200,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
13 people installed installed
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1075,  8.2868,  0.4907,  ..., -3.6419,  0.7794,  0.3328],
         [ 0.0561,  7.6431, -0.2454,  ..., -2.7526, -0.1291, -0.2137],
         [ 0.0609,  8.8401, -0.3678,  ..., -2.7813, -0.1094, -0.7809],
         [ 0.0722,  8.9127, -0.3820,  ..., -2.6852,  0.3575, -0.3752],
         [ 0.0732, 10.1308, -0.3815,  ..., -2.3419,  0.6079, -0.3687]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8683, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1432, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)
13 people installed installed
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1013,  8.2030,  0.5132,  ..., -3.9087,  0.8817,  0.3231],
         [ 0.0582,  7.5255, -0.2201,  ..., -2.7810, -0.1023, -0.2545],
         [ 0.0627,  8.6609, -0.3711,  ..., -3.0349, -0.1914, -0.7655],
         [ 0.0735,  8.8967, -0.3735,  ..., -2.8128,  0.2801, -0.3504],
         [ 0.0737, 10.1263, -0.3670,  ..., -2.4314,  0.5456, -0.3595]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2874, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.4083, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
13 people installed installed
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0982,  8.0378,  0.5538,  ..., -4.0716,  0.9410,  0.2644],
         [ 0.0580,  7.3434, -0.1899,  ..., -2.8202, -0.0645, -0.2595],
         [ 0.0595,  8.3073, -0.3553,  ..., -3.1611, -0.3681, -0.8247],
         [ 0.0731,  8.7184, -0.3518,  ..., -2.7962,  0.1417, -0.3120],
         [ 0.0731,  9.9281, -0.3397,  ..., -2.4233,  0.3739, -0.3344]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0358, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.3616, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)
13 people installed installed
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0953,  7.7461,  0.5740,  ..., -4.2430,  0.9317,  0.0817],
         [ 0.0561,  6.8365, -0.1681,  ..., -2.9358, -0.0620, -0.2893],
         [ 0.0521,  7.4894, -0.3204,  ..., -3.3071, -0.5386, -0.9215],
         [ 0.0697,  7.8632, -0.3282,  ..., -2.9384, -0.0120, -0.3729],
         [ 0.0698,  8.9183, -0.3120,  ..., -2.6065,  0.1752, -0.4181]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3426, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.2240, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)
13 people installed installed on the sea latest sealing 
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0915,  7.2671,  0.6845,  ..., -4.4386,  1.2562, -0.3367],
         [ 0.0482,  6.3732, -0.1285,  ..., -3.0159, -0.0134, -0.5312],
         [ 0.0430,  6.9536, -0.2452,  ..., -3.2280, -0.5280, -1.0046],
         ...,
         [ 0.1041,  9.1503, -0.0786,  ..., -2.1441,  1.3476, -0.0422],
         [ 0.0810,  8.6688, -0.5092,  ..., -3.7113, -0.0284, -1.7569],
         [ 0.0770, 12.5197,  0.0979,  ..., -1.2845,  0.8098,  1.2123]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.4376, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.6165, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[16036,   762, 14567,   114,   711,   113,   110,   105,  2111,  1057,
            395,  1034,   139, 21549, 16036,   762, 14567,   115,   109,  7175,
            113,  3064,   148, 50233,   109,  4170,   160,  3079,   644,  2175,
            110,   108,   155,   109,  1319,  1977,   113, 11461,   649,   109,
          14567,   140,   109,   711,   113,  1025, 46366,   110,   107,  1084,
          44907, 41534,   140,  1977,   113, 11461,  1034,   116,   655,   260,
            135,  5109,   112,  3390,   111,   148,   243,   223,   644,   524,
            632,   112,   823,   114,   110,   105, 30493,   824,   113,   109,
           2379,   110,   107, 16837,   125,   116,  1086,   734,   112,   145,
           1321,  1110,   299,   114,   300,   121,  1704,  6030,   112, 11881,
          13922,   110,   152,   325,   117,   461,   762,   297,   113,   109,
            951,   110,   108,   132,   109,   575,   110,   152,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
American company
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1412,  7.8097,  0.6203,  ..., -2.2268, -0.4932, -1.8408],
         [ 0.1224,  7.6149,  0.1631,  ..., -0.3765, -1.0510, -1.5612],
         [ 0.1035, 10.9431, -0.3886,  ..., -1.2493, -1.3144, -1.9214]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(9.8527, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.5329, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
Shell
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1219,  3.3713,  0.7527,  ..., -2.4395,  0.4052, -3.4668],
         [-0.0123, 11.5973, -0.3714,  ..., -2.5634, -0.4372, -2.0216]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.7452, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(31.5861, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Shell
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1032,  2.6575,  0.7421,  ..., -3.0251,  0.2702, -3.6050],
         [-0.0258, 12.4380, -0.5061,  ..., -2.9915, -0.2427, -2.6316]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8435, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(14.9618, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Shell
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0953,  2.7756,  0.7376,  ..., -3.1980,  0.0542, -3.6209],
         [-0.0342, 12.5273, -0.5512,  ..., -2.9292, -0.4081, -2.4531]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5550, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3586, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
Shell
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0834,  3.0299,  0.6829,  ..., -3.2503, -0.1395, -3.5388],
         [-0.0429, 12.5459, -0.5646,  ..., -2.9495, -0.4853, -2.3265]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1750, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2600, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1346,  6661,   118,   762, 14567,   945,   139,  2800,  1728,   112,
           2555,   110,   105, 41638, 16837,  1003,   121,   768,  1739,   120,
            133,   174,   263,   115,   109,  7175,   113,  3064,   139,  1346,
           6661,  2800,   110,   108,   229,   606,   118,  6957,   109,   808,
          70959,   503,   110,   108,   148,  2365,   114,  3662, 13602,   604,
            762,  1003,   121,   768,  1459,   110,   107,   139,  2800,   110,
            108,   162,  1653,   120,   203,  1962,  2560,   117,   110,   105,
            112,   650,   160,  8695, 33237,   118,   109,  1280,   113,  7633,
          16837,  1487,   203,   807,  4086,   134,   114,  1833,  1792,   115,
           1741,  3710,   110,   107,   182,   117,   203,  6932,   110,   105,
            698,  9501,  1702, 16837,   110,   107,  1810,  1518,   137,  2337,
            118,   109,  1702,   430,   960,  2651,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0273,  8.1769,  0.9702,  ..., -1.2017, -0.1972, -0.9840],
         [ 0.0240, 11.9721,  0.4307,  ..., -2.6134,  0.2948, -0.8956]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.3691, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(37.5184, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
press press press press press press is the
iter = 1 reward = 0
final_logits =  tensor([[[ 4.5121e-02,  7.6804e+00,  6.1303e-01,  ..., -2.9036e+00,
          -4.6496e-01, -1.0792e+00],
         [ 1.8233e-02,  5.8453e+00, -1.5706e-01,  ..., -4.2137e+00,
          -2.0532e+00, -1.1743e+00],
         [ 3.6194e-03,  5.2500e+00, -2.7109e-01,  ..., -4.1801e+00,
          -2.0173e+00, -1.4438e+00],
         ...,
         [ 1.2021e-02,  5.4872e+00, -3.5929e-01,  ..., -3.5582e+00,
          -1.4146e+00, -1.9469e+00],
         [ 2.9480e-02,  9.7796e+00, -2.5461e-01,  ..., -2.5477e+00,
           2.2652e-02, -1.1937e+00],
         [ 5.5205e-02,  1.0145e+01,  8.4018e-02,  ..., -3.1852e+00,
           3.9615e-01, -7.3638e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-12.8948, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(29.8950, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
The X has been announced this clumsy oil challenge at
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0490,  3.4582,  0.6351,  ..., -2.1781, -0.0342, -1.6347],
         [ 0.0322,  6.7724,  0.0680,  ..., -3.4309, -0.9690, -2.7132],
         [ 0.0213,  4.4789, -0.2157,  ..., -0.8641, -2.7192, -1.9547],
         ...,
         [ 0.0288,  7.0772, -0.1194,  ..., -1.1708, -1.0959, -0.5812],
         [ 0.0727, 10.4404, -0.6922,  ..., -2.0149, -0.3038, -1.5723],
         [ 0.0474, 11.3705, -0.2654,  ..., -0.8701,  0.2353, -0.9522]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.7123, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(9.1393, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
X has established its major major spaceflight in its
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0576,  6.0811,  0.6299,  ..., -0.8308, -0.4252, -2.3014],
         [ 0.0381,  4.2328,  0.0271,  ..., -1.2251, -1.1131, -2.0030],
         [ 0.0793,  6.2814, -0.1295,  ..., -0.5340, -0.2032, -0.3951],
         ...,
         [ 0.0649, 10.1606, -0.6551,  ..., -2.4492, -1.2958, -1.2283],
         [ 0.0829,  9.9838, -0.0836,  ..., -1.3413,  0.4903, -1.1245],
         [ 0.0405, 11.0186, -0.1986,  ..., -2.2113,  0.6411, -1.0805]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.6841, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.3320, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
X has has has the X has known the X has a
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0818,  6.9213,  0.4696,  ..., -0.2647, -0.9792, -1.7282],
         [ 0.0576,  3.6762, -0.0293,  ..., -1.5971, -1.2440, -1.7278],
         [ 0.1262,  5.7917, -0.1492,  ..., -1.2621, -0.0771, -0.7547],
         ...,
         [ 0.0918,  6.9067, -0.5115,  ..., -2.8053, -1.0643, -1.7845],
         [ 0.1575,  9.8098, -0.1937,  ..., -1.2473,  0.7785, -0.5240],
         [ 0.1419, 11.8289,  0.1338,  ..., -1.5190,  1.5083, -0.9844]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5687, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7302, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 3211,  1307,  2652,  2882,  2033,   134,   280, 85536, 17403,  4596,
            398, 16036,  1034,   116, 11599,  2664,   109,   519,   113,   114,
           6033,   124,  9134,  9600,   110,   108,   109, 12220,   113, 14645,
           9727,   135,   109,   762, 14567,   115,   109,  7175,   113,  3064,
            148,  9380,   164,   115,   114,  2043, 22369,   115, 10792,   110,
            107,   353,  1761,  7690,   355,  1854,   199,   109, 18191,   113,
          14645,   246,   129,  8626,   122,   110,   107,  9903, 90966,  1574,
            135,   351,   859,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
Idaho courtroom reports report count from the lawsuits 
iter = 0 reward = 2
final_logits =  tensor([[[ 0.0843,  5.4789,  1.0112,  ...,  1.7149,  0.3333, -0.7545],
         [ 0.0232,  5.7489,  0.1101,  ..., -1.0268,  1.2865, -0.2265],
         [ 0.0226,  4.9489,  0.0769,  ..., -0.4146, -1.0825,  0.6526],
         ...,
         [ 0.0315,  7.3305,  0.3676,  ...,  0.2603,  2.8358,  0.7929],
         [ 0.1538,  6.3671, -0.3000,  ..., -1.2764,  0.6239, -0.4235],
         [ 0.0761, 10.9122,  0.2776,  ...,  0.8114,  0.8864,  1.8434]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4216, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.7173, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Idaho courtroom count from the lawsuits arising  arising
iter = 1 reward = 0
final_logits =  tensor([[[ 9.0188e-02,  5.5202e+00,  1.0195e+00,  ...,  1.6686e+00,
           3.9399e-01, -6.8744e-01],
         [ 3.6307e-02,  5.5752e+00,  1.4420e-01,  ..., -7.4121e-01,
           1.2706e+00, -2.8920e-02],
         [ 3.0752e-02,  4.8615e+00,  8.7726e-02,  ..., -3.6727e-01,
          -1.3631e+00,  6.0371e-01],
         ...,
         [ 6.9120e-02,  7.3844e+00,  2.7954e-03,  ..., -6.0926e-01,
           1.3926e+00,  2.8334e+00],
         [ 6.6638e-02,  1.0720e+01,  4.2788e-01,  ...,  9.6622e-01,
           1.4336e+00,  2.0728e+00],
         [ 3.4696e-02,  1.0719e+01,  8.3395e-03,  ..., -1.0700e+00,
           6.7119e-01,  2.6302e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4256, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.4902, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Idaho courtroom count from the lawsuits arising 
iter = 2 reward = 0
final_logits =  tensor([[[ 8.9568e-02,  5.6763e+00,  1.0263e+00,  ...,  1.4844e+00,
           6.1995e-01, -5.7122e-01],
         [ 3.9814e-02,  5.5969e+00,  1.2528e-01,  ..., -7.8128e-01,
           1.2709e+00,  1.8511e-01],
         [ 4.2133e-02,  4.8349e+00,  5.7404e-02,  ..., -5.8386e-01,
          -1.4817e+00,  4.0114e-01],
         ...,
         [ 1.4215e-01,  6.6201e+00, -1.4259e-01,  ..., -2.0420e+00,
           1.1200e+00, -9.2986e-01],
         [ 7.1858e-02,  7.3567e+00, -6.5047e-03,  ..., -1.0192e+00,
           1.4608e+00,  2.9378e+00],
         [ 7.2512e-02,  1.0553e+01,  4.8163e-01,  ...,  7.1116e-01,
           1.2553e+00,  2.2028e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.8686, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.5447, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Idaho courtroom count from the lawsuits arising in Idaho 
iter = 3 reward = 0
final_logits =  tensor([[[ 9.3758e-02,  5.7480e+00,  1.0438e+00,  ...,  1.4088e+00,
           9.3586e-01, -3.6568e-01],
         [ 4.0036e-02,  5.6248e+00,  7.5668e-02,  ..., -9.4328e-01,
           1.3592e+00,  4.0905e-01],
         [ 6.2882e-02,  4.7921e+00,  1.1396e-02,  ..., -1.1727e+00,
          -1.3101e+00,  3.6763e-01],
         ...,
         [ 1.0251e-01,  7.5661e+00,  2.2354e-01,  ...,  3.1765e-01,
           5.9842e-01,  1.3914e+00],
         [ 8.4411e-02,  8.0076e+00, -3.5649e-01,  ..., -5.9487e-01,
           4.6619e-01,  2.1102e-01],
         [ 6.3372e-02,  1.2326e+01,  2.8667e-01,  ..., -5.3585e-01,
           1.7050e-01,  2.1146e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3766, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.0724, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
The tide is the tide in the tide of
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1028,  5.8573,  1.0302,  ...,  1.8994,  0.9091, -0.1003],
         [ 0.1109,  5.7741,  0.7796,  ..., -0.3854,  0.5356, -0.6373],
         [ 0.1229,  8.0902, -0.0266,  ..., -0.9516, -1.9722, -0.2105],
         ...,
         [ 0.1099,  8.9239,  0.5455,  ...,  0.8078, -0.4875, -0.3189],
         [ 0.1592,  8.1266, -0.0780,  ..., -0.5324, -2.1235,  0.3154],
         [ 0.1146, 12.1031,  0.2052,  ...,  0.7999, -0.8237,  0.0931]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5782, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.5533, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 2571,  1508,  2652,  2882,  2033,   134,   305, 49218, 17403,  4596,
            222,  6358,   109, 40522, 34524,  4820,   164,   299,  4027,  1034,
            116, 62223,   454,  3682,  3793,   156,   113,   109,   278,  1034,
            116,  3741,   762, 12802,   110,   107,  1478,   115,   109,  5569,
            110,   108,  3070,   111,   176,  3217, 17659,   109,  1322,   192,
            394,  5097,   110,   107,   343, 62223,   148,   174, 71731,   115,
            109,  1965, 43983,   231,   110,   108,   112,   253,   142,  4156,
            120,   126,   117,   744,   130,   175,   109,  2648,   394,  2032,
            110,   107,   168,   117,  8549, 62223,  1034,   116,   584,   256,
            319,  2520,   118,   274,   115,   109,  7175,   113,  3064,   170,
            127, 48322,   120,   157,   138,   521,  5097,   135,   109,  2926,
          16036,   762, 14567,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Galician industries were broke in August last August .
iter = 0 reward = 0
final_logits =  tensor([[[ 7.6858e-02,  5.5258e+00,  6.2347e-01,  ..., -5.3475e+00,
          -1.2703e+00, -4.1700e+00],
         [-6.1590e-03,  3.4172e+00,  1.2506e-01,  ..., -3.1247e+00,
          -2.2534e+00, -2.7424e+00],
         [ 1.2175e-02,  3.9128e+00, -1.3167e-01,  ..., -4.5129e+00,
          -1.6354e+00, -2.5841e+00],
         ...,
         [ 8.9146e-02,  4.4279e+00, -3.6270e-01,  ..., -2.0716e+00,
          -1.0711e+00, -2.0778e+00],
         [ 8.7839e-02,  6.8487e+00,  1.5889e-01,  ..., -3.6640e+00,
          -1.5812e+00, -2.2296e+00],
         [ 6.7115e-02,  1.2355e+01, -6.3993e-02,  ..., -2.9313e+00,
          -6.4882e-01, -3.0891e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.4602, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.1411, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galician industries were broke in August last August .
iter = 1 reward = 0
final_logits =  tensor([[[ 9.5341e-02,  5.8796e+00,  6.7527e-01,  ..., -5.1594e+00,
          -1.3555e+00, -3.8318e+00],
         [-4.4143e-03,  3.8815e+00,  1.3610e-01,  ..., -3.0325e+00,
          -2.2444e+00, -2.5626e+00],
         [ 1.5944e-02,  4.2530e+00, -1.1370e-01,  ..., -4.4645e+00,
          -1.5335e+00, -2.2732e+00],
         ...,
         [ 9.3292e-02,  4.7544e+00, -3.4482e-01,  ..., -1.9113e+00,
          -1.1657e+00, -1.8793e+00],
         [ 9.0428e-02,  7.2369e+00,  2.0510e-01,  ..., -3.5698e+00,
          -1.4770e+00, -1.9145e+00],
         [ 7.4549e-02,  1.2594e+01,  1.9403e-02,  ..., -2.9045e+00,
          -6.9657e-01, -2.7468e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.0250, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.4199, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galician industries broke in August    tourism       
iter = 2 reward = 0
final_logits =  tensor([[[ 1.2407e-01,  6.1680e+00,  7.9297e-01,  ..., -4.5014e+00,
          -1.0238e+00, -2.7491e+00],
         [ 3.4176e-03,  4.5926e+00,  2.1575e-01,  ..., -3.3780e+00,
          -2.1266e+00, -2.0604e+00],
         [ 2.2605e-02,  4.5631e+00, -2.9310e-02,  ..., -4.2332e+00,
          -1.2870e+00, -1.5938e+00],
         ...,
         [ 9.0802e-02,  8.6751e+00,  1.6264e-01,  ..., -3.6274e+00,
          -1.3866e+00, -1.7589e+00],
         [ 8.8704e-02,  8.7171e+00,  2.3435e-01,  ..., -3.8702e+00,
          -1.3512e+00, -1.9060e+00],
         [ 8.7270e-02,  8.7723e+00,  3.0316e-01,  ..., -4.0401e+00,
          -1.3228e+00, -2.0317e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.3039, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.4044, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)

Everytime after generating next logits 38.4% (4234 out of 11019)
Galician industries broke in August   
iter = 3 reward = 0
final_logits =  tensor([[[ 1.2362e-01,  6.2734e+00,  8.3662e-01,  ..., -4.2910e+00,
          -6.1172e-01, -2.5795e+00],
         [ 1.5677e-03,  5.0144e+00,  2.1596e-01,  ..., -3.4542e+00,
          -2.0558e+00, -2.0295e+00],
         [ 2.0756e-02,  4.9230e+00,  1.7589e-02,  ..., -4.0281e+00,
          -1.0531e+00, -1.5736e+00],
         ...,
         [ 9.2322e-02,  7.3556e+00,  4.9174e-01,  ..., -3.8602e+00,
          -7.3630e-01, -6.4498e-01],
         [ 9.0321e-02,  8.0070e+00,  5.2136e-01,  ..., -3.9813e+00,
          -6.9744e-01, -1.1452e+00],
         [ 8.8903e-02,  8.6076e+00,  5.7388e-01,  ..., -3.9608e+00,
          -6.8892e-01, -1.3881e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.9659, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5482, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Galician industries broke in August when Galician tourism broke .
iter = 4 reward = 0
final_logits =  tensor([[[ 7.3093e-02,  5.6718e+00,  6.0717e-01,  ..., -5.2465e+00,
          -1.3490e+00, -4.2969e+00],
         [-8.2679e-03,  3.5309e+00,  1.4601e-01,  ..., -3.2823e+00,
          -2.2093e+00, -2.5981e+00],
         [ 7.8468e-03,  4.0905e+00, -1.1129e-01,  ..., -4.3428e+00,
          -1.4146e+00, -2.1834e+00],
         ...,
         [ 9.9753e-02,  4.9594e+00, -4.3434e-01,  ..., -2.9011e+00,
           1.0287e-01, -1.7042e+00],
         [ 8.2053e-02,  8.9659e+00, -2.0810e-02,  ..., -2.8023e+00,
          -5.7004e-01, -1.2461e+00],
         [ 5.6488e-02,  1.2702e+01, -1.8614e-01,  ..., -2.2584e+00,
          -8.1086e-01, -1.8957e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.5778, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.3360, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  787, 17984,   116, 16036,   204,  7175,   113,  3064,   762,  5135,
           1195,  1408,  2652,  2882,  2033,   134, 79386,   914, 17403,  4596,
            139,   706,  1013,   117,   112, 17984, 16036,   111,  1965,   176,
            524,   204,   114,  1124,   762, 14567,   115,   109,  7175,   113,
           3064,   110,   107,   139,   657,   243,   126,   192,  1137,   109,
           3358,  1069,  9873,   118,   109, 13353,   113,  2729,  1363,   124,
           1496,   164,   109,  3741,  2249,  5135,   115,   787,   689,   110,
            107, 36347,  1024,  2342,   115,   109, 11335,   124,   109, 81065,
          18308,  9600, 13773,   115,   960,   110,   107,   139,  6442,  1034,
            116, 55065, 66707,  1574,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
BBC Eleven4 Eleven4
iter = 0 reward = 1
final_logits =  tensor([[[ 0.0222,  3.6181,  0.6102,  ..., -5.8331,  2.6152, -1.2564],
         [ 0.0498,  8.8108,  0.3335,  ..., -5.2915, -1.4126, -1.6391],
         [ 0.0110,  5.1945,  0.3195,  ..., -0.8689, -0.4106,  0.1371],
         [ 0.0597,  7.7529, -0.3954,  ..., -4.6056, -0.9982, -1.5825],
         [ 0.0244,  5.5866,  0.3092,  ..., -0.9219, -0.1800,  0.1454],
         [ 0.0603,  9.1294, -0.4427,  ..., -4.5778, -1.0666, -1.5080]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3955, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8937, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
BBC Eleven4 Eleven4
iter = 1 reward = 1
final_logits =  tensor([[[ 0.0252,  3.6746,  0.5848,  ..., -5.5096,  2.3658, -1.3049],
         [ 0.0507,  8.5588,  0.3224,  ..., -5.3203, -1.4727, -1.7706],
         [ 0.0089,  5.1750,  0.3104,  ..., -0.8813, -0.3726,  0.1924],
         [ 0.0571,  7.5299, -0.3715,  ..., -4.6248, -0.9001, -1.6421],
         [ 0.0223,  5.5363,  0.3001,  ..., -0.9177, -0.1294,  0.1682],
         [ 0.0605,  8.6721, -0.4192,  ..., -4.6290, -0.9678, -1.6299]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0670, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6081, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
BBC Eleven4 Eleven4  MacKenzie
iter = 2 reward = 1
final_logits =  tensor([[[ 2.2240e-02,  3.5254e+00,  5.0344e-01,  ..., -5.7962e+00,
           2.8117e+00, -1.1341e+00],
         [ 4.7451e-02,  7.2603e+00,  2.7344e-01,  ..., -5.6584e+00,
          -1.2883e+00, -2.2964e+00],
         [ 1.0164e-02,  5.0708e+00,  2.6443e-01,  ..., -9.3212e-01,
          -2.7266e-01, -2.3803e-02],
         ...,
         [ 5.6672e-02,  7.3094e+00, -4.0165e-01,  ..., -4.9383e+00,
          -9.6673e-01, -2.3293e+00],
         [ 5.8663e-02,  8.9100e+00,  2.0278e-01,  ..., -9.0580e-01,
          -3.1043e-01,  1.9033e-01],
         [ 3.9813e-02,  1.1414e+01, -6.2588e-01,  ..., -3.3548e+00,
          -1.2435e+00, -1.7112e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3672, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.0396, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
BBC Eleven4 Eleven4 
iter = 3 reward = 1
final_logits =  tensor([[[ 0.0162,  3.6611,  0.5585,  ..., -5.7186,  3.2924, -0.7933],
         [ 0.0424,  7.1215,  0.2632,  ..., -5.8634, -1.3572, -2.3236],
         [ 0.0120,  4.9721,  0.2683,  ..., -0.8382, -0.2005, -0.1166],
         ...,
         [ 0.0224,  5.1859,  0.2236,  ..., -1.0035,  0.1343, -0.1521],
         [ 0.0485,  7.0835, -0.3993,  ..., -5.3923, -1.0224, -2.5613],
         [ 0.0563,  8.9404,  0.2068,  ..., -1.4899, -0.2636,  0.5419]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.3386, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8932, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
BBC Eleven4 Eleven4 
iter = 4 reward = 1
final_logits =  tensor([[[ 0.0148,  3.7286,  0.5637,  ..., -5.5232,  3.2854, -0.7827],
         [ 0.0406,  7.1301,  0.2608,  ..., -5.9127, -1.4676, -2.3226],
         [ 0.0110,  4.8855,  0.2676,  ..., -0.8389, -0.2052, -0.1342],
         ...,
         [ 0.0203,  5.0179,  0.2256,  ..., -1.0033,  0.1097, -0.1648],
         [ 0.0471,  6.8974, -0.4118,  ..., -5.4896, -1.0964, -2.6963],
         [ 0.0565,  8.5687,  0.2003,  ..., -1.7266, -0.2186,  0.5029]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.6335, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6084, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 7915, 26939,  4355,  1194,   244, 16036,   762, 14567,  5823,  8437,
            117,   364,   109, 19954,   113,   109,  7175,   113,  3064,   235,
            149,   314,   210,   110,   107,   139,   908,   317,  6299,   111,
           1174,   117,  8988,   153, 19347,   578,   110,   107,   343,   136,
            232,   205,   113,   109, 27736,   127,  2609,   110,   107,   139,
          27736,   127,   146,  1622,   115,   762,   110,   108,   130,   109,
           6442,  1034,   116,  2040,  9518,  1574,   135,  7915,   110,   108,
            155,  3040,   299,   141,  2926, 21615, 22611,   116,   120,   195,
           2443,   112,  2512,   109, 15737,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Adams oysters contain from the economic reports from the economic reports .
iter = 0 reward = 3
final_logits =  tensor([[[ 5.5926e-02,  4.0746e+00,  8.7985e-01,  ..., -2.4807e+00,
          -1.4766e-01, -2.1356e+00],
         [ 1.0693e-02,  4.1076e+00,  1.2898e-01,  ..., -1.3402e+00,
          -1.5786e+00, -1.2012e+00],
         [ 8.9546e-02,  3.8469e+00, -2.2891e-01,  ..., -3.3201e+00,
          -2.2028e+00,  1.0115e-02],
         ...,
         [ 7.0247e-02,  4.7997e+00, -7.8565e-01,  ..., -3.4107e+00,
          -1.5217e+00, -1.9064e+00],
         [ 9.0734e-02,  7.7929e+00,  3.8103e-01,  ..., -2.4177e+00,
          -1.2290e+00, -8.7799e-01],
         [ 9.4458e-02,  1.2729e+01,  2.3061e-02,  ..., -5.6465e-01,
          -1.5918e+00, -1.1738e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.3450, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(11.2703, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
Adams oysters contain from economic reports from the economic reports .
iter = 1 reward = 3
final_logits =  tensor([[[ 5.0801e-02,  4.1515e+00,  8.7147e-01,  ..., -2.5175e+00,
          -1.4326e-01, -1.9989e+00],
         [ 7.2887e-03,  4.1538e+00,  1.2424e-01,  ..., -1.4721e+00,
          -1.6256e+00, -1.1130e+00],
         [ 8.9378e-02,  3.8612e+00, -2.1194e-01,  ..., -3.2250e+00,
          -2.2544e+00, -2.3899e-02],
         ...,
         [ 8.9246e-02,  4.6047e+00, -7.8230e-01,  ..., -3.3128e+00,
          -1.8639e+00, -1.4112e+00],
         [ 9.1233e-02,  7.3848e+00,  3.6561e-01,  ..., -2.8081e+00,
          -1.6027e+00, -2.2322e-01],
         [ 8.9675e-02,  1.2330e+01,  5.4357e-02,  ..., -7.4229e-01,
          -1.6588e+00, -1.2252e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.5889, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.2513, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
Adams oysters contain from economic reports from the economic reports .
iter = 2 reward = 3
final_logits =  tensor([[[ 4.7316e-02,  4.2160e+00,  8.6903e-01,  ..., -2.5360e+00,
          -1.3422e-01, -1.9345e+00],
         [ 2.3080e-03,  4.1927e+00,  1.2300e-01,  ..., -1.5482e+00,
          -1.6411e+00, -1.0346e+00],
         [ 9.0614e-02,  3.9025e+00, -1.9322e-01,  ..., -3.0463e+00,
          -2.3131e+00,  1.2016e-02],
         ...,
         [ 9.9608e-02,  4.8560e+00, -7.2301e-01,  ..., -2.9084e+00,
          -2.1909e+00, -9.3801e-01],
         [ 9.1515e-02,  7.7009e+00,  3.2075e-01,  ..., -2.6230e+00,
          -1.6935e+00, -2.4305e-02],
         [ 8.3602e-02,  1.2725e+01,  5.1420e-02,  ..., -7.1571e-01,
          -1.7139e+00, -1.1949e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7115, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.2441, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
Adams oysters contain from economic reports from the economic reports .
iter = 3 reward = 3
final_logits =  tensor([[[ 4.4920e-02,  4.2639e+00,  8.6571e-01,  ..., -2.5320e+00,
          -1.3483e-01, -1.9431e+00],
         [-1.6120e-03,  4.2294e+00,  1.1771e-01,  ..., -1.5906e+00,
          -1.6414e+00, -9.8333e-01],
         [ 8.8366e-02,  3.9761e+00, -1.8187e-01,  ..., -2.9012e+00,
          -2.3629e+00,  1.3398e-02],
         ...,
         [ 9.9387e-02,  4.9971e+00, -6.6624e-01,  ..., -2.6121e+00,
          -2.2527e+00, -6.3379e-01],
         [ 8.8773e-02,  7.9420e+00,  2.9936e-01,  ..., -2.4172e+00,
          -1.6280e+00, -4.7301e-03],
         [ 7.9264e-02,  1.3130e+01,  4.4172e-02,  ..., -6.9956e-01,
          -1.7128e+00, -1.1751e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0632, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.7128, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
Adams oysters contain from the economic reports from the economic reports .
iter = 4 reward = 3
final_logits =  tensor([[[ 4.1721e-02,  4.2860e+00,  8.6189e-01,  ..., -2.5446e+00,
          -1.3384e-01, -1.9872e+00],
         [-4.6262e-03,  4.2888e+00,  1.1062e-01,  ..., -1.6023e+00,
          -1.6412e+00, -9.2845e-01],
         [ 8.4615e-02,  4.0920e+00, -1.7446e-01,  ..., -2.7416e+00,
          -2.3806e+00,  2.2539e-02],
         ...,
         [ 9.9824e-02,  5.1779e+00, -6.4006e-01,  ..., -2.2060e+00,
          -2.2985e+00, -3.6906e-01],
         [ 7.8024e-02,  8.6358e+00,  2.0966e-01,  ..., -1.6407e+00,
          -1.5672e+00, -1.8831e-01],
         [ 7.6068e-02,  1.3251e+01,  2.7084e-02,  ..., -4.2692e-01,
          -1.5871e+00, -9.7091e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5383, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5888, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  3
3
topic:  ('bpoil_bbc',)
env initialized...

Before training:  38.2% (4210 out of 11019)
{'input_ids': tensor([[[  110,   105,  3893, 15737,  1034,  8255,   464, 16036,   134,   109,
           1816,  2447,   139,  1816,  2447,   649,   126,   117,  4562,   112,
          16036,   118,   203,   337,   983,   762,   121,  2134,  5626,   148,
            174, 12832,   279,   156,   113,   109,  1816,  2447,  1034,   116,
          18072,   141, 10162, 18232,   126,   112,   370,   203, 10971,   818,
            122, 16036,   110,   107,   139,  4635, 41588,   110,   108, 50595,
          81452, 60490,   457,   131,   304,   110,   108,   117,   114,  4055,
          17225,   113,   114,   883,   693,   111, 28286,   111,   117,   160,
           6155,   231,   459,   110,   107,   202,   456,   568,  7200,  9221,
           3893,  2777,   165,   109,  8255,   110,   107,   202,   984,  8255,
           4635, 20678,  4329,   115,  1185,   110,   107,   139,  1816,  2447,
            243,   109,  5626,  1065,   140, 39059,   110,   108,   162,   196,
            146,  3954,   109,  4976,  2098, 11976,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
The Haka giant has been a
iter = 0 reward = 0
final_logits =  tensor([[[ 0.3821,  4.4872,  1.4196,  ..., -2.6642, -0.0131, -1.4149],
         [ 0.3434,  7.4824,  0.9682,  ..., -2.8977,  0.4066, -0.6998],
         [ 0.2814,  5.3044,  0.1196,  ..., -1.5503, -0.5835, -1.1691],
         ...,
         [ 0.2693,  8.2270,  0.3277,  ..., -1.3633, -0.4460, -1.0118],
         [ 0.3134,  7.5421,  0.3154,  ..., -1.9095, -0.3951, -1.5578],
         [ 0.2890, 11.3795,  0.4398,  ..., -0.5824,  1.1019, -1.6390]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(13.7558, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(74.2850, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Sponsorship has been poured molasses poured molasses poured
iter = 1 reward = 0
final_logits =  tensor([[[ 2.5891e-01,  7.0693e+00,  1.0309e+00,  ..., -1.6655e+00,
           7.9263e-01, -2.3163e+00],
         [ 1.5201e-01,  7.8499e+00,  9.3780e-03,  ..., -1.8238e+00,
          -2.8908e-02, -2.4591e+00],
         [ 1.5806e-01,  7.9180e+00,  1.9122e-01,  ..., -1.1084e+00,
          -1.2581e-01, -1.9257e+00],
         ...,
         [ 1.1401e-01,  1.0688e+01,  2.4760e-01,  ..., -1.2836e+00,
           1.5209e-01, -8.1169e-01],
         [ 9.1321e-02,  9.4823e+00, -1.2373e-03,  ..., -1.6901e+00,
          -1.3830e+00, -2.2040e+00],
         [ 1.0465e-01,  1.1417e+01,  2.2469e-01,  ..., -1.4753e+00,
          -6.6062e-02, -8.6554e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.5356, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.7437, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
The British British government is the
iter = 2 reward = 2
final_logits =  tensor([[[ 2.2458e-01,  6.6844e+00,  1.0274e+00,  ..., -1.3958e+00,
          -3.8383e-03, -1.5407e+00],
         [ 2.0003e-01,  6.3090e+00,  8.0743e-01,  ..., -3.3577e+00,
           5.2901e-01, -1.2929e+00],
         [ 1.5121e-01,  7.7011e+00,  5.9773e-01,  ..., -1.6261e-01,
           6.1044e-02, -8.9848e-01],
         ...,
         [ 1.2827e-01,  8.7135e+00, -2.4818e-01,  ..., -6.8787e-01,
           7.0835e-02, -1.5190e+00],
         [ 1.7826e-01,  8.3492e+00,  2.7993e-02,  ..., -2.2102e+00,
          -1.9586e-01, -4.7639e-01],
         [ 2.2009e-01,  8.4028e+00,  1.6767e-01,  ..., -2.3759e+00,
           8.1633e-01, -1.6664e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(11.3825, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(17.5643, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
The British government has a
iter = 3 reward = 1
final_logits =  tensor([[[ 2.2737e-01,  7.3179e+00,  1.0663e+00,  ..., -1.4869e+00,
           7.3083e-01, -1.4182e+00],
         [ 2.0406e-01,  7.8188e+00,  6.8351e-01,  ..., -2.8811e+00,
           3.5361e-01, -1.8983e+00],
         [ 1.7473e-01,  8.6653e+00,  4.7208e-01,  ..., -3.9051e-01,
           2.3265e-01, -1.5484e+00],
         [ 1.7015e-01,  1.0460e+01, -5.7843e-02,  ..., -4.8381e-01,
           3.7576e-01, -1.8753e+00],
         [ 1.6758e-01,  8.3846e+00,  1.5840e-01,  ..., -1.5251e+00,
           8.1969e-03, -9.7227e-01],
         [ 1.8037e-01,  1.1121e+01,  4.1842e-01,  ..., -1.5229e+00,
           1.2742e+00, -1.9718e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5589, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.7088, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
The British
iter = 4 reward = 1
final_logits =  tensor([[[ 0.2315,  7.3814,  1.1357,  ..., -1.4824,  0.3877, -1.5746],
         [ 0.2055,  8.6977,  0.7306,  ..., -2.7379,  0.1980, -2.0072],
         [ 0.1648,  9.8021,  0.4962,  ...,  0.1069,  0.0330, -1.6160]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3373, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6193, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 4123,   113,   219,  6234,   195,  6908,   115,   109, 75158,  1153,
           3893,  1419, 16036,   148,  6305,  3906,   142, 10580,   805,   113,
            203,  7175,   113,  3064,   762, 14567,  1407,  1104,   124,   203,
            387,   110,   107,   139,  1082,   110,   108,  1155,   204,   109,
           1339,   110,   108,   939,  1841,   115,   683,   113,   114,  1679,
            113,   461,  6234, 10361,  1055,   113,   203,  3954,   210,   124,
            109,  1917,  1030,   110,   107, 16036,  9619,  3582,  7217,   243,
            120,   339,  6234,   195,  6908,   115,   109,   856,  1153,   111,
          10390,   680,   196,   174,   263,   112,   535,  1055,   110,   107,
            139, 10580,   805,   140,  3530,   122,   109,   856,   244,   114,
            787,  9024,  8666,   126,   110,   107,  1263,  7217,   243,   109,
           4787,   170,   635,   109,  1153,   140, 10361,   169,   766,   122,
          10390,   680,   111,   186,   140,   220,  5313,  6596,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)

Everytime after generating next logits 37.9% (4174 out of 11019)
Dean Dean Dean posted an altered image on Photoshop skills on Photoshop
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0608,  4.9129,  0.4605,  ..., -4.8138,  0.9363, -1.6278],
         [ 0.0555,  5.2715, -0.1552,  ..., -5.3257, -2.3300, -1.2255],
         [ 0.0571,  5.4608, -0.2141,  ..., -5.0770, -2.6420, -1.4978],
         ...,
         [ 0.0829, 10.2463, -0.5503,  ..., -3.8113, -2.3802, -2.0090],
         [ 0.1059, 10.5237, -0.3386,  ..., -3.8104, -0.8354, -1.9395],
         [ 0.0721,  9.8439, -0.4133,  ..., -4.9552, -2.9699, -1.6041]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.7143, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(46.8756, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)
Dean workers posted a
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0453,  4.5204,  0.4602,  ..., -5.6159,  0.7447, -1.3067],
         [ 0.0473,  4.2685, -0.0443,  ..., -5.0853, -2.0770, -0.3845],
         [ 0.1063,  4.2361, -0.4262,  ..., -6.3804, -2.2162, -1.5129],
         [ 0.1033,  5.2019, -0.3237,  ..., -4.4248, -0.7163, -1.6565],
         [ 0.0622, 11.6281, -0.2317,  ..., -3.9157, -0.2182, -1.8922]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-9.0743, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(83.9272, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Dean Dean altered image posted on the screens of his image on the BP website .
iter = 2 reward = 1
final_logits =  tensor([[[ 0.0546,  4.3147,  0.4609,  ..., -5.9101,  0.9110, -1.3013],
         [ 0.0877,  2.1608, -0.0490,  ..., -4.5205, -2.6647, -0.8745],
         [ 0.0841,  2.0067, -0.0966,  ..., -4.3804, -2.7937, -1.2685],
         ...,
         [ 0.0522,  4.9367, -0.9148,  ..., -4.4538, -2.0312, -0.5563],
         [ 0.0710,  9.3037, -0.0836,  ..., -2.7685, -1.7102, -0.0843],
         [ 0.0340, 11.9230, -0.6304,  ..., -4.5215, -1.1981, -1.4741]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-12.0634, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(55.9862, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)

Everytime after generating next logits 38.5% (4242 out of 11019)
Dean Dean Dean posted a message on the online online with a message on the BP website .
iter = 3 reward = 1
final_logits =  tensor([[[ 8.4210e-02,  5.0462e+00,  5.5471e-01,  ..., -5.7553e+00,
           1.0248e+00, -9.4588e-01],
         [ 1.2621e-01,  2.6493e+00,  1.2959e-01,  ..., -4.4973e+00,
          -2.4769e+00, -2.9453e-01],
         [ 1.2302e-01,  2.4676e+00,  5.2900e-02,  ..., -4.2611e+00,
          -2.6858e+00, -7.8068e-01],
         ...,
         [ 7.2164e-02,  7.6305e+00, -6.7886e-01,  ..., -4.9033e+00,
          -2.6689e+00, -7.5784e-01],
         [ 1.3075e-01,  1.0244e+01, -1.2118e-02,  ..., -2.6643e+00,
          -1.7549e+00, -9.1302e-04],
         [ 7.0393e-02,  1.2540e+01, -3.2237e-01,  ..., -3.8293e+00,
          -9.4105e-01, -9.1577e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-7.2581, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(15.5353, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)

Everytime after generating next logits 38.5% (4244 out of 11019)
BP software photographer spotted in Gulf spill floor photo on BP website 
iter = 4 reward = 5
final_logits =  tensor([[[ 0.1133,  5.2337,  0.6090,  ..., -5.9837,  1.1883, -0.8421],
         [ 0.0177,  2.8336, -0.2114,  ..., -6.6284, -1.2992, -1.9811],
         [ 0.0170,  3.1052, -0.1418,  ..., -6.3668, -2.3410, -0.3593],
         ...,
         [ 0.0154,  6.3650, -0.3345,  ..., -6.0706, -0.8397, -0.0716],
         [ 0.0365,  6.3083, -0.7446,  ..., -4.5017, -1.7991, -0.1502],
         [ 0.0595, 12.7046, -0.1008,  ..., -2.5585, -1.5023,  0.6363]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2129, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.6946, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  5
5
{'input_ids': tensor([[[599, 960, 110,  ..., 109, 804,   1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.3% (4216 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)
BP BP has been sent to
iter = 0 reward = 2
final_logits =  tensor([[[ 0.0507,  4.1955,  0.3812,  ..., -3.3496,  1.6867,  0.4519],
         [-0.0467,  5.7141, -0.3917,  ..., -4.1721, -0.6895, -1.3718],
         [-0.0368,  6.7734, -0.4762,  ..., -3.6611, -0.8291, -1.2693],
         ...,
         [ 0.0362,  9.3229, -0.1031,  ..., -3.3657, -0.4294, -0.2917],
         [ 0.0702,  8.8397, -0.1333,  ..., -3.2054,  1.9715, -0.5796],
         [ 0.0534,  9.5708, -0.2701,  ..., -2.6375,  0.7495,  0.5088]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-4.9076, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.3091, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4166 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.0% (4294 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)

Everytime after generating next logits 39.5% (4358 out of 11019)
BP BP has been stopped by the government officials to
iter = 1 reward = 3
final_logits =  tensor([[[ 6.1924e-02,  4.6923e+00,  3.7350e-01,  ..., -2.9743e+00,
           9.6538e-01,  4.4360e-01],
         [-6.2968e-02,  5.2840e+00, -3.6606e-01,  ..., -4.1873e+00,
          -8.5552e-01, -1.2613e+00],
         [-5.3409e-02,  5.9149e+00, -4.4178e-01,  ..., -3.7845e+00,
          -8.6366e-01, -1.3217e+00],
         ...,
         [ 9.3770e-02,  9.7700e+00, -5.7657e-01,  ..., -3.0281e+00,
          -5.9162e-01, -1.2869e+00],
         [ 1.3907e-01,  8.9238e+00, -5.9806e-01,  ..., -2.0962e+00,
          -1.7523e+00, -9.8435e-01],
         [ 1.0751e-02,  1.1591e+01, -2.8370e-01,  ..., -1.8150e+00,
          -4.1463e-01,  4.2796e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.1914, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2628, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4260 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)
BP BP has been forced to stop the cap in Gulf Thadacher,
iter = 2 reward = 5
final_logits =  tensor([[[ 6.8578e-02,  4.7186e+00,  4.6150e-01,  ..., -3.1321e+00,
           7.0397e-01,  6.4457e-01],
         [-6.7504e-02,  4.3682e+00, -3.1757e-01,  ..., -4.5421e+00,
          -1.1761e+00, -1.3608e+00],
         [-5.5737e-02,  4.7188e+00, -3.6887e-01,  ..., -4.1344e+00,
          -1.1214e+00, -1.4597e+00],
         ...,
         [ 2.7038e-02,  7.7484e+00, -3.2130e-01,  ..., -2.7929e-01,
          -2.6357e+00,  1.5377e+00],
         [-8.3071e-04,  7.9598e+00, -7.7208e-01,  ..., -2.2328e+00,
          -2.8121e+00,  8.7916e-01],
         [ 1.4535e-03,  1.0921e+01, -5.1070e-01,  ..., -2.1822e+00,
          -4.6336e-01,  2.1249e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(8.9471, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.0422, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4250 out of 11019)

Everytime after generating next logits 39.2% (4314 out of 11019)

Everytime after generating next logits 39.2% (4314 out of 11019)

Everytime after generating next logits 39.2% (4314 out of 11019)

Everytime after generating next logits 39.7% (4378 out of 11019)
Video shows the
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0742,  3.3367,  0.6022,  ..., -3.5097, -0.5430, -0.6835],
         [ 0.0573,  8.1066, -0.1594,  ..., -3.9853, -1.8953, -2.4123],
         [ 0.0955,  8.9147, -0.5029,  ..., -2.9978, -1.0715, -3.3394],
         [ 0.0678,  8.7567, -0.2775,  ..., -3.9646, -0.7616, -2.1497]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.6601, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.8856, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)

Everytime after generating next logits 39.5% (4352 out of 11019)
BP has rejected its plan to cap in Gulf Thadacher, and the cap was not connected to cap .
iter = 4 reward = 5
final_logits =  tensor([[[ 5.0324e-02,  5.2225e+00,  3.9116e-01,  ..., -3.1378e+00,
           8.6702e-01,  7.4860e-01],
         [-7.2985e-02,  3.2603e+00, -2.5934e-01,  ..., -4.7489e+00,
          -8.0081e-01, -1.3561e+00],
         [ 1.3875e-02,  3.1377e+00, -5.4144e-02,  ..., -3.3012e+00,
           2.1481e-01, -7.1320e-01],
         ...,
         [-2.0937e-02,  6.1608e+00, -6.5620e-01,  ..., -4.2055e+00,
          -6.8805e-01,  6.5037e-01],
         [ 3.6873e-02,  1.0265e+01,  8.8778e-03,  ..., -2.9335e+00,
          -1.5325e-01,  1.5358e+00],
         [ 1.4062e-02,  1.2243e+01, -3.2739e-01,  ..., -2.8264e+00,
           3.6636e-01,  8.1271e-02]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(7.6037, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(37.5687, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  5
5
{'input_ids': tensor([[[6174,  692,  110,  ...,  526,  115,    1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.6% (4256 out of 11019)

Everytime after generating next logits 39.2% (4320 out of 11019)

Everytime after generating next logits 39.2% (4320 out of 11019)

Everytime after generating next logits 39.2% (4320 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)

Everytime after generating next logits 39.8% (4384 out of 11019)
There is a risk of a spillm that
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1197,  3.9052,  0.3846,  ..., -6.6611, -0.1784, -0.5478],
         [ 0.0860,  4.8986, -0.4582,  ..., -3.1683, -1.0126, -1.0519],
         [ 0.1226,  1.8196, -0.3071,  ..., -4.1103, -0.4340, -0.7502],
         ...,
         [ 0.0638,  6.2012, -0.2601,  ..., -1.8429, -0.8170,  0.0517],
         [ 0.0552,  8.1462, -0.7720,  ..., -2.1711, -1.4808, -0.9951],
         [ 0.0322, 12.1135, -0.4497,  ..., -1.8640,  0.3057, -0.5290]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(8.8106, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(26.2133, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
There are the worst possible spill ever ever for
iter = 1 reward = 2
final_logits =  tensor([[[ 0.1121,  4.1550,  0.5142,  ..., -6.2889, -0.4050, -0.0250],
         [ 0.0780,  8.6485, -0.4401,  ..., -3.1430, -1.0872, -1.6117],
         [ 0.0702,  9.4586, -0.3349,  ..., -3.5599, -1.3074, -1.3816],
         ...,
         [ 0.0779,  7.2016, -0.5866,  ..., -5.4002, -0.8795, -2.0613],
         [ 0.0831,  7.7125, -0.6488,  ..., -5.3379, -0.8643, -1.9850],
         [ 0.0875, 11.4901, -0.4737,  ..., -2.7420, -0.2345, -1.1088]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(8.5164, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(16.0331, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)
There
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1093,  4.6089,  0.4760,  ..., -5.8423, -0.4239,  0.2337],
         [ 0.0645, 12.0976, -0.4587,  ..., -1.6059, -0.6751, -1.6637]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8640, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.0503, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
There
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0930,  4.6947,  0.4826,  ..., -5.5224, -0.4348,  0.6108],
         [ 0.0478, 12.2233, -0.4603,  ..., -1.6598, -0.7549, -1.6821]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1734, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.1018, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
There is the biggest risk in the world: The
iter = 4 reward = 2
final_logits =  tensor([[[ 0.0753,  4.7623,  0.4825,  ..., -5.4380, -0.5217,  0.9452],
         [ 0.0393,  6.2131, -0.4467,  ..., -3.0992, -1.2811, -1.2667],
         [ 0.0859,  4.2329, -0.2291,  ..., -3.5398, -0.6581, -1.5149],
         ...,
         [ 0.0479,  6.0099, -0.8550,  ..., -4.0818, -0.4230, -1.3780],
         [ 0.0594,  8.2571, -0.1371,  ..., -4.5578,  1.0832, -0.7406],
         [ 0.0328,  9.5706, -0.1375,  ..., -5.0510,  0.5296, -1.3014]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.6406, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.1277, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  139,  5543,  9254,   320,  3702,   142,   865,   728,   113,   109,
          16036,   762, 14567,   110,   107,  8916,   114,  1713,   113,  5012,
            122,   662,   503, 32908,   110,   108,   330,   278,  2668,   116,
            122,  4605, 35522,   110,   108,   109,   177,  3378,   113, 16036,
            111,  6061, 32886,   110,   108,   169, 15978,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)
The Money is a new feature of the Money and a new host
iter = 0 reward = 2
final_logits =  tensor([[[ 0.2168,  4.7182,  0.4857,  ..., -1.7928,  0.4042, -0.8347],
         [ 0.1752,  6.2914,  0.0530,  ..., -4.3049,  1.7912, -2.3246],
         [ 0.1514,  5.2911, -0.5275,  ..., -3.6337, -1.5637, -2.7802],
         ...,
         [ 0.1698, 10.7907,  0.0705,  ..., -2.3510,  0.4452, -1.3498],
         [ 0.2102,  9.4038,  0.0131,  ..., -1.4021,  0.2164, -0.2464],
         [ 0.1858, 11.8224, -0.5167,  ..., -2.8481, -1.4306, -0.7982]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.6182, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(22.6710, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
The Money is a new host and a new host
iter = 1 reward = 2
final_logits =  tensor([[[ 0.1938,  4.5660,  0.5421,  ..., -1.8746,  0.6264, -1.0288],
         [ 0.1586,  5.9099,  0.0179,  ..., -4.3834,  2.0265, -2.4700],
         [ 0.1409,  5.1030, -0.5250,  ..., -3.8659, -1.4430, -2.7312],
         ...,
         [ 0.1941,  9.5030,  0.0931,  ..., -1.4254,  0.6078, -0.1817],
         [ 0.1963,  7.8184,  0.0356,  ..., -0.6639,  0.7952,  0.3215],
         [ 0.2106, 10.6117, -0.5053,  ..., -2.9541, -0.1180, -0.8355]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.2690, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(12.3214, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)
The Money is a new host and a new host
iter = 2 reward = 2
final_logits =  tensor([[[ 0.1623,  4.3942,  0.6343,  ..., -1.4515,  0.6399, -1.0220],
         [ 0.1286,  6.8101,  0.0509,  ..., -3.6181,  1.9808, -2.3080],
         [ 0.1099,  6.2702, -0.4691,  ..., -3.4681, -1.0521, -2.2788],
         ...,
         [ 0.1545, 11.1481,  0.0673,  ..., -0.9655,  0.6317,  0.3000],
         [ 0.1766,  9.2925,  0.0625,  ..., -0.2913,  0.8010,  1.1117],
         [ 0.1727, 12.0507, -0.5537,  ..., -1.6579, -0.8473, -0.2078]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4498, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.0807, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)
The Money is a new host and a new host
iter = 3 reward = 2
final_logits =  tensor([[[ 0.1340,  4.3761,  0.7654,  ..., -0.3283,  0.9479, -0.6989],
         [ 0.1108,  6.2858,  0.1694,  ..., -3.2099,  2.1027, -1.9449],
         [ 0.0919,  5.2589, -0.4749,  ..., -2.9399, -0.9863, -2.4250],
         ...,
         [ 0.1421,  9.8941,  0.0950,  ..., -1.3219,  0.8174,  0.5872],
         [ 0.1625,  8.3802,  0.0442,  ..., -0.3451,  1.1444,  1.1133],
         [ 0.1681, 12.1447, -0.5898,  ..., -1.7253, -0.9739, -0.6991]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0139, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6188, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Features features features features features 
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1146,  4.3768,  0.7775,  ..., -0.3507,  0.9601, -0.7821],
         [ 0.1612,  6.1523, -0.2754,  ..., -2.3433, -2.6106, -2.4773],
         [ 0.1943,  7.0175, -0.4165,  ..., -3.7304, -2.7820, -2.0572],
         ...,
         [ 0.1905,  8.0665, -0.4846,  ..., -4.1136, -2.5350, -1.8805],
         [ 0.1883,  8.8132, -0.5121,  ..., -4.2159, -2.4167, -1.8546],
         [ 0.1034,  9.6810,  0.3201,  ..., -4.8019, -1.3739, -1.4045]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.4787, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.7854, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1084, 18756,   110,  ...,  5135,   378,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)
US Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast
iter = 0 reward = 73
final_logits =  tensor([[[-0.0403,  5.3078,  0.3958,  ..., -5.6323, -0.2516, -2.4673],
         [-0.0904,  5.1511, -0.1240,  ..., -1.4368,  1.9922, -2.1875],
         [-0.1175,  5.2471,  0.0484,  ..., -5.1244,  0.4876, -1.0555],
         ...,
         [-0.1340,  8.8517, -0.4682,  ..., -6.0851,  1.8665, -1.7789],
         [-0.1354,  9.2439, -0.4645,  ..., -5.9551,  1.8630, -1.7258],
         [-0.1371,  9.7435, -0.4569,  ..., -5.7771,  1.8275, -1.6569]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(41.4157, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1056.1703, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.1% (4416 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 40.7% (4480 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)

Everytime after generating next logits 41.2% (4544 out of 11019)
US Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast
iter = 1 reward = 158
final_logits =  tensor([[[-0.0678,  5.2242,  0.4614,  ..., -5.3155, -0.8827, -2.0034],
         [-0.1313,  4.8758, -0.1718,  ..., -1.4643,  1.6067, -2.4760],
         [-0.1779,  3.9894, -0.0642,  ..., -4.3813, -0.3402, -1.5597],
         ...,
         [-0.1208,  9.5837, -0.4478,  ..., -4.1951,  0.2102, -2.2999],
         [-0.1215,  9.9646, -0.4464,  ..., -4.1182,  0.2425, -2.2815],
         [-0.1220, 10.2887, -0.4460,  ..., -4.0514,  0.2575, -2.2646]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(75.1573, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6047.5142, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 41.6% (4586 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.2% (4650 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 42.8% (4714 out of 11019)

Everytime after generating next logits 44.0% (4846 out of 11019)

Everytime after generating next logits 45.2% (4978 out of 11019)

Everytime after generating next logits 45.2% (4978 out of 11019)

Everytime after generating next logits 45.2% (4978 out of 11019)

Everytime after generating next logits 45.2% (4978 out of 11019)

Everytime after generating next logits 45.2% (4978 out of 11019)

Everytime after generating next logits 46.4% (5114 out of 11019)

Everytime after generating next logits 47.6% (5250 out of 11019)

Everytime after generating next logits 47.6% (5250 out of 11019)

Everytime after generating next logits 47.6% (5250 out of 11019)

Everytime after generating next logits 47.6% (5250 out of 11019)

Everytime after generating next logits 48.9% (5390 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 51.5% (5674 out of 11019)

Everytime after generating next logits 52.8% (5818 out of 11019)

Everytime after generating next logits 52.8% (5818 out of 11019)

Everytime after generating next logits 52.8% (5818 out of 11019)

Everytime after generating next logits 52.8% (5818 out of 11019)

Everytime after generating next logits 52.8% (5818 out of 11019)

Everytime after generating next logits 54.1% (5966 out of 11019)

Everytime after generating next logits 55.5% (6114 out of 11019)

Everytime after generating next logits 55.5% (6114 out of 11019)

Everytime after generating next logits 55.5% (6114 out of 11019)

Everytime after generating next logits 55.5% (6114 out of 11019)

Everytime after generating next logits 56.9% (6266 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 59.7% (6574 out of 11019)

Everytime after generating next logits 61.1% (6730 out of 11019)

Everytime after generating next logits 61.1% (6730 out of 11019)

Everytime after generating next logits 61.1% (6730 out of 11019)

Everytime after generating next logits 61.1% (6730 out of 11019)

Everytime after generating next logits 62.5% (6890 out of 11019)

Everytime after generating next logits 64.0% (7050 out of 11019)

Everytime after generating next logits 64.0% (7050 out of 11019)

Everytime after generating next logits 64.0% (7050 out of 11019)

Everytime after generating next logits 64.0% (7050 out of 11019)

Everytime after generating next logits 64.0% (7050 out of 11019)

Everytime after generating next logits 65.5% (7214 out of 11019)

Everytime after generating next logits 67.0% (7378 out of 11019)

Everytime after generating next logits 67.0% (7378 out of 11019)

Everytime after generating next logits 67.0% (7378 out of 11019)

Everytime after generating next logits 67.0% (7378 out of 11019)

Everytime after generating next logits 68.5% (7546 out of 11019)

Everytime after generating next logits 70.0% (7714 out of 11019)

Everytime after generating next logits 70.0% (7714 out of 11019)

Everytime after generating next logits 70.0% (7714 out of 11019)

Everytime after generating next logits 70.0% (7714 out of 11019)

Everytime after generating next logits 70.0% (7714 out of 11019)

Everytime after generating next logits 71.6% (7886 out of 11019)

Everytime after generating next logits 73.1% (8058 out of 11019)

Everytime after generating next logits 73.1% (8058 out of 11019)

Everytime after generating next logits 73.1% (8058 out of 11019)

Everytime after generating next logits 73.1% (8058 out of 11019)

Everytime after generating next logits 74.7% (8234 out of 11019)

Everytime after generating next logits 76.3% (8410 out of 11019)

Everytime after generating next logits 76.3% (8410 out of 11019)

Everytime after generating next logits 76.3% (8410 out of 11019)

Everytime after generating next logits 76.3% (8410 out of 11019)

Everytime after generating next logits 76.3% (8410 out of 11019)

Everytime after generating next logits 78.0% (8590 out of 11019)

Everytime after generating next logits 79.6% (8770 out of 11019)

Everytime after generating next logits 79.6% (8770 out of 11019)

Everytime after generating next logits 79.6% (8770 out of 11019)
Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast Coast
iter = 2 reward = 243
final_logits =  tensor([[[-0.2131,  4.8881,  0.1565,  ..., -5.6131, -0.1122, -1.7312],
         [-0.3616,  3.3857, -0.3903,  ..., -5.7777, -0.0351, -1.8844],
         [-0.3624,  3.4235, -0.4474,  ..., -5.7158, -0.2047, -2.0525],
         ...,
         [-0.2935, 11.4026, -0.3806,  ..., -3.6787,  0.6366, -1.2232],
         [-0.2879, 11.4588, -0.3619,  ..., -3.5906,  0.6276, -1.1166],
         [-0.2837, 11.5042, -0.3493,  ..., -3.5331,  0.6142, -1.0435]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(37.9468, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(13229.0225, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)

Everytime after generating next logits 43.6% (4806 out of 11019)
BP BP BP BP says it could be used to prevent spillm . BP says it will not be able to use of funnel to prevent spillm .
iter = 3 reward = 10
final_logits =  tensor([[[-0.2828,  3.2636, -0.2380,  ..., -6.1672,  0.8665, -2.5958],
         [-0.3410,  2.0100, -1.0770,  ..., -6.6818, -0.6424, -3.9160],
         [-0.3292,  2.1162, -1.0842,  ..., -6.7335, -0.6345, -3.9984],
         ...,
         [-0.3109,  3.7764, -1.2568,  ..., -1.8783, -1.1681, -0.8528],
         [-0.0388,  3.3314, -0.0339,  ..., -0.9818,  0.1577, -0.0309],
         [-0.2681, 12.2899, -0.6894,  ..., -5.1564,  1.0915, -2.3949]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-50.4122, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1317.3766, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 39.0% (4292 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)

Everytime after generating next logits 40.1% (4420 out of 11019)
BP BP BP has failed to get the it to stop any spill . BP says it will use a stemsteel to to to to stop any spill .
iter = 4 reward = 8
final_logits =  tensor([[[-0.3488,  3.0486, -0.4013,  ..., -4.6763,  1.7501, -2.2174],
         [-0.3723,  1.1357, -1.0816,  ..., -5.4369, -0.4182, -4.3783],
         [-0.3572,  1.1146, -1.0598,  ..., -5.2284, -1.0000, -4.2593],
         ...,
         [-0.2049,  4.0829, -0.7303,  ..., -1.8879, -1.7344, -0.3356],
         [-0.1495,  5.3671, -0.0260,  ..., -1.4757, -0.2688,  0.6992],
         [-0.3250, 11.5231, -0.7575,  ..., -4.0468,  0.9181, -1.6874]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-82.9436, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2055.1030, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  8
8
{'input_ids': tensor([[[16036,   243,   186,  ...,   111,  2684,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 39.3% (4332 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)

Everytime after generating next logits 39.9% (4396 out of 11019)
The US has cut the company's share price by 1.4% . The company is under the US government's own .
iter = 0 reward = 1
final_logits =  tensor([[[-0.2084,  5.0706, -0.0277,  ..., -3.6025,  2.4789, -2.5368],
         [-0.1996,  3.1688, -0.0217,  ..., -4.5949,  2.9272, -2.9905],
         [-0.2583,  4.2496, -0.4693,  ..., -2.4670,  0.7184, -4.6977],
         ...,
         [-0.1672,  4.0841, -0.3674,  ..., -4.0954,  1.7205, -2.1531],
         [-0.0998,  5.9544,  0.0253,  ..., -3.1221,  1.1040, -1.7539],
         [-0.2187, 11.6298, -0.3944,  ..., -2.7440,  2.2897, -2.9597]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-63.9017, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1697.8600, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.8% (4272 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.4% (4336 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)

Everytime after generating next logits 39.9% (4400 out of 11019)
The US president has also held the company shares are up up up up up .
iter = 1 reward = 2
final_logits =  tensor([[[-0.2455,  6.0752,  0.0530,  ..., -4.0712,  2.7838, -1.7283],
         [-0.2317,  4.5557, -0.1873,  ..., -4.8551,  2.7306, -2.7648],
         [-0.2401,  5.5577, -0.3358,  ..., -1.5222,  1.2648, -3.9305],
         ...,
         [-0.1113,  8.0360, -0.5037,  ..., -4.1951,  0.2472, -1.7647],
         [-0.1468,  9.7224, -0.0192,  ..., -3.5860,  2.2646, -0.5444],
         [-0.2250, 11.8989, -0.5727,  ..., -3.1141,  1.9357, -1.8830]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-53.1645, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1201.7850, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4260 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)
Nord shares . US president has also accused him of the oil spill .
iter = 2 reward = 3
final_logits =  tensor([[[-1.9841e-01,  4.9982e+00, -3.9410e-02,  ..., -4.5983e+00,
           3.0546e+00, -1.3532e+00],
         [-1.5078e-01,  1.9342e+00, -9.9789e-04,  ..., -5.3427e+00,
           5.0804e-01, -2.7240e+00],
         [-6.5624e-02,  3.3128e+00, -6.3973e-01,  ..., -4.0979e+00,
           1.8485e+00, -2.3390e+00],
         ...,
         [-2.0942e-01,  3.7049e+00, -5.8263e-01,  ..., -1.3931e+00,
          -1.8483e-01, -1.5095e+00],
         [-1.3212e-01,  6.2212e+00, -2.9999e-01,  ..., -3.1206e+00,
           1.3803e+00, -1.9941e-01],
         [-2.3909e-01,  1.1079e+01, -6.8106e-01,  ..., -2.7296e+00,
           2.3284e+00, -1.6967e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-67.9524, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1284.8796, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
President Obama's comments have led to the rise to the company .
iter = 3 reward = 2
final_logits =  tensor([[[-0.1692,  5.4030,  0.1420,  ..., -4.2146,  3.2464, -1.1334],
         [-0.0356,  5.3816, -0.4473,  ..., -4.1178,  0.0317, -2.8715],
         [-0.0570,  3.9931, -0.7465,  ..., -4.0707, -0.4643, -3.5735],
         ...,
         [-0.1614,  6.0955, -0.9748,  ..., -4.8569,  0.7760, -1.8973],
         [-0.1204,  7.4967, -0.1674,  ..., -4.2731,  1.1631, -0.2210],
         [-0.1981, 11.7077, -0.2460,  ..., -3.0813,  2.8206, -2.0668]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-42.6465, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(824.2314, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4248 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)
President Obama's comments on the company .
iter = 4 reward = 2
final_logits =  tensor([[[-0.1514,  5.6841,  0.1247,  ..., -4.1260,  3.6285, -1.0808],
         [-0.0280,  5.7381, -0.4412,  ..., -4.0881,  0.1607, -2.8243],
         [-0.0396,  4.2281, -0.7151,  ..., -3.8809, -0.2770, -3.2731],
         ...,
         [-0.1488,  5.7631, -1.0372,  ..., -3.6361,  1.1407, -2.4420],
         [-0.1081,  7.4365, -0.0897,  ..., -3.9173,  1.5374, -0.0366],
         [-0.1824, 12.3670, -0.2455,  ..., -2.8676,  2.7163, -2.2519]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-29.0943, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(389.4550, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[16036, 35640,   116,  ...,  3598, 32220,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.5% (4240 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)

Everytime after generating next logits 39.6% (4368 out of 11019)
pipe broken by the leak . BP has promised to keep it down over over 11 days .
iter = 0 reward = 6
final_logits =  tensor([[[-0.4989,  4.2874, -0.1438,  ..., -3.6967,  1.1409, -1.9918],
         [-0.3679,  1.5420, -0.5676,  ...,  0.1748, -1.4561, -1.4304],
         [-0.2877,  2.8658, -0.6753,  ..., -0.6027, -1.7256, -2.3933],
         ...,
         [-0.2201,  6.2547, -0.7675,  ..., -1.4483, -0.3846, -0.4341],
         [-0.2397,  9.8657, -0.5472,  ..., -1.8779, -0.2962,  0.8374],
         [-0.3040, 11.6124, -0.6674,  ..., -1.8970,  0.1990, -0.5928]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-32.0964, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(349.1559, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4252 out of 11019)

Everytime after generating next logits 39.2% (4316 out of 11019)

Everytime after generating next logits 39.2% (4316 out of 11019)

Everytime after generating next logits 39.2% (4316 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)

Everytime after generating next logits 39.7% (4380 out of 11019)
BP pledge to to reduce the amount of the spill spill 
iter = 1 reward = 3
final_logits =  tensor([[[-0.6361,  5.4708, -0.0618,  ..., -2.8819,  2.5301, -1.2965],
         [-0.3140,  5.3986, -0.9258,  ..., -2.9621, -0.1535, -2.4966],
         [-0.1672,  6.0361, -0.7925,  ..., -2.8154,  2.1900, -1.4741],
         ...,
         [-0.4266,  7.6264, -0.6817,  ..., -2.2055, -0.3163, -0.3041],
         [-0.4153,  7.3027, -0.5847,  ..., -2.0471, -0.0302, -0.1492],
         [-0.3867, 10.7130, -0.4042,  ..., -3.2757,  0.8305,  0.6762]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-29.9172, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(209.6299, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.5% (4244 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)

Everytime after generating next logits 39.7% (4372 out of 11019)
Oil spill spill spill spill spill spill spill spill spill spill spill spill spill spill  
iter = 2 reward = 15
final_logits =  tensor([[[-0.5547,  4.9290,  0.0977,  ..., -3.1947,  1.5735, -1.1469],
         [-0.6105,  3.8397, -0.3121,  ..., -2.0493, -0.0989,  0.4138],
         [-0.3332,  3.2723, -0.5867,  ..., -1.2915,  0.2824, -1.0454],
         ...,
         [-0.3778,  5.9258, -0.7905,  ..., -2.7708, -0.7197, -1.0504],
         [-0.3445,  9.3366, -0.1530,  ..., -2.5100, -0.0631, -0.1402],
         [-0.3603,  9.9813, -0.2157,  ..., -2.5893, -0.0683, -0.1555]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-5.1611, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(29.2335, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4248 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.1% (4312 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)

Everytime after generating next logits 39.7% (4376 out of 11019)
Dispers Dispers Dispers Dispers Dispers Dispers Dispersed to
iter = 3 reward = 0
final_logits =  tensor([[[-0.4787,  3.5152,  0.2170,  ..., -4.3944,  0.8069, -0.3925],
         [-0.2634,  5.3338, -0.0544,  ..., -2.9280, -0.3221,  1.5527],
         [-0.2822,  6.0638, -0.1136,  ..., -3.1585, -0.3493,  1.5117],
         ...,
         [-0.2920,  7.8769, -0.2668,  ..., -3.6666, -0.8016,  0.7734],
         [-0.3394,  9.0042, -0.7464,  ..., -3.6652,  0.0801,  0.5675],
         [-0.3251, 10.3495, -0.5200,  ..., -3.0625,  0.1277,  1.3171]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-3.2248, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(8.1446, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.6% (4258 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.2% (4322 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)

Everytime after generating next logits 39.8% (4386 out of 11019)
BP has offered to to ensure the spill .
iter = 4 reward = 2
final_logits =  tensor([[[-0.3731,  3.2520,  0.2653,  ..., -3.5247,  0.8025, -0.6254],
         [-0.1500,  4.6706, -0.8555,  ..., -2.4699,  0.2320, -2.1548],
         [-0.0153,  5.6539, -0.5993,  ..., -2.3593,  1.2675, -0.0732],
         ...,
         [-0.1676,  7.2859, -1.0807,  ...,  0.4942, -0.4966, -0.4344],
         [-0.1454, 10.1011, -0.3118,  ..., -1.7101,  0.7212,  1.2955],
         [-0.2321, 12.6598, -0.5728,  ..., -2.0861,  0.4420, -0.3200]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(11.6799, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(33.3740, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  787,  1276, 12998,  3531,   148,  4486, 18205, 53857,  7028,   112,
          15079,   109,  3662,   599, 10970,   233, 20447,   788,   121,  1768,
          43304,   110, 10970,   233, 16567,   788,   121,  2617,   120, 16036,
            148,   323,   164,   112, 13889,  4807,   113,   109,  7175,   113,
           3064,   762, 14567,   110,   107,  1263, 53857,  7028,   148,   306,
            115,   253,  2887,   110,   151,   178,  3120,   109,  4807,  1034,
           1844,  2617,   323,   164,   115,   109,  4619,   113,   109,  1073,
           1338,  6687,  3613,   115,   351,   859,   111,  1741,   110,   107,
            285,   148,   243,   178,   117,   146, 10237,   122,   109,   657,
            132, 16036,   111,   138, 15079,   109,  2617,  7539,   110,   107,
           2632,   138,   719,  3916,   135,   109,  2617,   110,   152,   139,
            762, 14567,   148,  2145, 12071,   466,   109,   787,  7175,  3500,
            110,   108,  7271,  3070,   111,  5569,   111, 65047,   181,  4758,
            111, 44650, 18205, 53857,  7028, 35571,  3916,   118,  4807,   113,
            109,  1073,  1338,   110,   108,  6687,  3613,  7922,  8749, 18205,
          53857,  7028, 18097, 16915,   918,   111,   243,  2784,   192,   129,
            154,  5263,   197,   274,   120,   192,   129,  3366,   141,   114,
           1462,   110,   107,   343,   178,   243,   274,  2486,  3916,   355,
            361,   164,   153,   268,   112, 17984, 16036,   110,   107,   139,
           2617,   117,   112, 34262,  7175,   113,  3064,  1836,   111,  1098,
            118,  1166,  9125,   111,  5471,   111,   118,   510,  3207,   111,
           1003,   121,   768,   110,   108,   790,   176,  2242,   110,   107,
          16036,   148,   506,  1389,  3662,   110, 37622,   208,   115,  2242,
            381,   109,   960, 14567,   110,   107,   139,   762, 14567,   110,
            108,   162,  1219,   599,   960,   122,   109, 11335,   113,   109,
          16036,   121, 38539,   252, 81065, 18308,  9600, 13773,   110,   108,
           2145,  8010, 12071,   466,   109,   787,  7175,  3500, 18205, 53857,
           7028, 35571,  3916,   118,  4807,   113,   109,  1073,  1338,   110,
            108,  6687,  3613,   139,  8749,   113,   114,  3662,   599, 10970,
            233, 20447,   788,   121,  1768, 31197,   110, 10970,   233, 16567,
            788,   121,  2617,   112, 13889,  4807,   113,   109, 16036,   762,
          14567,   148,   243,   186,   117,   110,   105,   220,  2767, 16837,
            120, 15931,  2242,   127,   142,   797,   110,   107, 18205, 53857,
           7028, 18097,   112,   129, 24915,   204,   170,   915,  2784,   112,
           1480,   109,  4959,   113,   109,  2617,   110,   107,  3440,  3662,
          12622,   110, 10970,   148,   506,   174,  1389,   165,   115,  2280,
           2784,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)
Claim to over over over over over payments for BP .
iter = 0 reward = 1
final_logits =  tensor([[[ 7.2601e-02,  3.6224e+00,  5.0760e-01,  ..., -1.8401e+00,
           3.1634e+00,  7.0059e-01],
         [-6.4052e-02,  3.7956e+00, -4.8074e-01,  ..., -9.3897e-01,
           5.9140e-01, -1.2794e+00],
         [-8.6873e-03,  3.7952e+00, -4.8669e-01,  ..., -1.4090e+00,
           8.0356e-01, -7.2807e-01],
         ...,
         [-5.0251e-02,  3.5516e+00, -9.1373e-01,  ..., -1.9372e+00,
           3.6151e+00, -9.9226e-01],
         [ 2.3763e-02,  8.5171e+00,  5.9429e-02,  ..., -1.4655e+00,
           2.7924e+00, -1.0057e-01],
         [-2.5716e-02,  1.2310e+01, -2.1608e-01,  ..., -1.7967e+00,
           2.1118e+00, -6.4298e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(7.6271, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(18.9842, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)

Everytime after generating next logits 38.7% (4260 out of 11019)
Claim over over over over over payments for BP .
iter = 1 reward = 1
final_logits =  tensor([[[ 9.2767e-02,  3.7983e+00,  5.7836e-01,  ..., -1.8402e+00,
           4.6944e+00,  1.0098e+00],
         [-3.7088e-02,  3.6128e+00, -4.8036e-01,  ..., -1.4005e+00,
           9.6277e-01, -1.7717e+00],
         [ 9.8988e-03,  2.9348e+00, -2.8709e-02,  ..., -1.5456e+00,
           2.5325e+00, -8.5764e-01],
         ...,
         [-6.6792e-02,  3.9868e+00, -8.7923e-01,  ..., -2.4432e+00,
           3.9835e+00, -1.4787e+00],
         [ 1.1031e-02,  9.3203e+00, -1.9511e-02,  ..., -2.2187e+00,
           3.0976e+00, -3.1501e-01],
         [-1.7963e-02,  1.2629e+01, -1.5058e-01,  ..., -2.0788e+00,
           2.9279e+00, -1.1289e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(7.3764, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.2529, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
Claim over over over over over over over BP .
iter = 2 reward = 1
final_logits =  tensor([[[ 1.1483e-01,  3.6408e+00,  6.0424e-01,  ..., -2.1630e+00,
           4.9895e+00,  8.9757e-01],
         [-2.3193e-02,  3.7093e+00, -5.0250e-01,  ..., -1.1805e+00,
           8.5260e-01, -1.7718e+00],
         [ 2.4560e-02,  2.9106e+00, -1.1639e-01,  ..., -1.5400e+00,
           2.2411e+00, -1.0408e+00],
         ...,
         [-6.4136e-02,  3.8422e+00, -8.9562e-01,  ..., -8.0003e-01,
           2.6891e+00, -1.4936e+00],
         [ 4.0362e-02,  8.7134e+00, -1.9415e-02,  ..., -2.2089e+00,
           2.5613e+00, -8.3551e-01],
         [-4.7355e-03,  1.2776e+01, -1.5954e-01,  ..., -2.3397e+00,
           2.8428e+00, -1.0457e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.6899, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(25.7965, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
Claim over over over over over over over over over BP .
iter = 3 reward = 1
final_logits =  tensor([[[ 1.3255e-01,  3.5271e+00,  5.3958e-01,  ..., -2.5748e+00,
           4.9838e+00,  1.6644e-01],
         [-8.0122e-03,  4.5343e+00, -5.5044e-01,  ..., -7.0700e-01,
           9.2711e-01, -1.9612e+00],
         [-4.0312e-03,  4.1367e+00, -2.1428e-01,  ..., -7.2615e-01,
           1.6548e+00, -1.0820e+00],
         ...,
         [-3.1291e-02,  4.5968e+00, -9.3956e-01,  ..., -7.1808e-01,
           2.5010e+00, -1.6427e+00],
         [ 4.3237e-02,  9.3458e+00, -5.0589e-02,  ..., -2.2351e+00,
           2.1568e+00, -8.8091e-01],
         [ 2.1604e-02,  1.2862e+01, -1.4468e-01,  ..., -2.0620e+00,
           1.8551e+00, -9.9241e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(5.2612, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.8791, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)
Obama pledge pledge to victims who who have been awarded for BP 
iter = 4 reward = 3
final_logits =  tensor([[[ 0.1213,  3.6763,  0.5476,  ..., -2.4467,  4.4149, -0.2122],
         [ 0.0460,  2.9419, -0.1406,  ..., -0.9756, -0.2279, -2.3752],
         [ 0.2627,  3.4313, -0.2105,  ..., -1.9920,  2.6317, -1.2663],
         ...,
         [ 0.1191,  7.2375, -0.1277,  ..., -4.4164,  5.6801, -0.2242],
         [ 0.0334,  6.1881, -0.8003,  ..., -3.1333,  4.4766, -1.3803],
         [ 0.0381, 11.9232, -0.0411,  ..., -1.6247,  2.0253, -0.3084]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(14.8306, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(53.8965, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  3
3
{'input_ids': tensor([[[  787,   762, 14567,   110,   151, 15265,  7788,   110,   105,   124,
            109,  2143,  1034,  1027,  3070,  6375,   127,   239,   270,   263,
            112,   225, 16036,   562,   109, 15737,  2584, 51128,   116, 10928,
           1034,   116,  3070,  2414,   148,  7646,   339,   698, 26680,   233,
          37399,   110,   108, 35493,   111, 23363,   110,   107,   110,   105,
            600,   480,   140, 12144,   110,   108,   155,   265,  7646,   110,
            108, 16837,   178,   649,   110,   108,  1132,   109,  2414,   114,
           4081, 15115,   110,   107,   343,  1263, 51128,   116, 10928,  7719,
            180,   138,  4428,   169,  1162,  3070,   260,   559,   111,   118,
            149,   117,   146,   114,   710,  5135,   110,   108,   155,   114,
            729,   121,  4109,   156,   110,   107,   202,   729,  1034,   116,
            419,   112,   133,   114,   715,   110,   108,   181,   660,   113,
            523,   134,   109,   370,   113,   109,  8483, 16837,  4645, 16848,
           2584, 51128,   116, 10928,  7915, 25996,   110,   105,  2184,  6021,
            134,   214,   173,   145,   416,   136,   762, 14567,   256,   129,
           3150,   197, 23363,   110,   108,   155,   145,   114,   457,  3178,
            131,   144, 34742,   110,   108, 16837,   178,   649,   110,   107,
            398,   178, 41593,   164,   114,  1124,  2944,   113,  9606,  6545,
            115,   109,  2414,  1034,   116,  7270,   110,   108,  2584,   649,
            178,   117,  5238,   120,   109, 14567,   138,   129,   289, 13502,
            118,   223,   200,   115,   136,  3820,   121, 23623,  3070,   427,
            113, 38584,  1946, 11958,   144,   216,   110,   108,  7915, 29546,
           3070,   148,   174,  7162,   115,  7915,   262,   113,   109, 14567,
          10250,  1034,   116,  1750,   110,   108,  1946, 74523,   110,   108,
           5765,   122,   342,   111,  2779,   112,  7904,   110,   107,   110,
            105, 15265,   117,   169,   271,   110,   108,   347,   126,   178,
            358,  3178,   131,   144,   235,   742,   997,   110,   108, 16837,
            265,   649,   110,   107,   110,   105,   285,  1034,   116, 13735,
            110,   107,   285,  1034,   116,  7432,   134,   488,   110,   107,
            285,  1034,   116,   146,   109,   310, 29546,   420, 15538, 90155,
            110,   151,   110,   105,   168,   978,   172,   114, 10447,  1120,
            279,   264, 16837, 16036,   148, 20350,  5478,   113, 63981,  7881,
            333,   109,  7175,   113,  3064,   762, 14567,   110,   108,   155,
            186,   127,   274,   170,   127,  1192,   126,  2773,  7427,   118,
            109,   201,   126,   117,   557,   110,   108,  6260,   109,  6442,
           1034,   116,  6869,  3544,   115,  7915,   110,   107, 46095,   126,
            110,   108,   155, 16036,   117,   146,   114,  6749,  1172,   264,
            115,   109,  6805,  1120,   113,  7026, 63116, 58439,   110,   107,
            222,   109, 10601,  1034,   116,   629,   110,   108, 14515,   429,
            115,   114,  1120,  4511,   120,   117,   239,   163,   238,   112,
          16036,  1034,   116,   648,   115,   136,   297,   113,  7915,   110,
            108,   623,   391,  1725,  2051,   279,   115,  4555,   523,  1490,
          21955,  8802,   110,   107,   110,   105,   184,  1034,   216,   146,
            314,   785,   118,  1609,   126,   110,   108,   155,   264, 16036,
           1034,   116,   557,   234,   110,   108, 16837,   156,   649,   110,
            107,   353,  1034,   116,   956,  2158,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)

Everytime after generating next logits 38.3% (4218 out of 11019)
BP says she has a
iter = 0 reward = 2
final_logits =  tensor([[[-0.1270,  4.0856,  0.1248,  ..., -6.0114,  0.4914, -1.0850],
         [-0.0687,  7.6246, -0.7097,  ..., -3.1641, -1.8715, -2.8066],
         [-0.0822,  9.9539, -0.7391,  ..., -3.0634, -0.9985, -2.2062],
         [-0.0519,  8.5229, -0.5672,  ..., -1.7215, -1.1936, -1.0566],
         [ 0.1441,  8.5025, -0.5827,  ..., -4.1472, -1.2138, -1.4928],
         [-0.0451, 11.5840, -0.3956,  ..., -3.4419, -0.3228, -2.1765]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(6.6463, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(36.1214, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)

Everytime after generating next logits 38.0% (4182 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[-0.0704,  3.9298,  0.2267,  ..., -5.2802, -0.0847, -1.2772],
         [-0.1565, 12.3596, -0.6901,  ..., -1.1051, -1.6733, -1.7590]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.0691, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(24.4002, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[-0.0788,  4.1433,  0.1985,  ..., -5.1154, -0.1424, -1.4007],
         [-0.1660, 12.3860, -0.6821,  ..., -0.9582, -1.3752, -1.5442]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.2967, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(21.9991, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[-0.0911,  4.4558,  0.1737,  ..., -4.8177,  0.0280, -1.4075],
         [-0.1820, 12.4135, -0.6946,  ..., -0.9670, -1.2224, -1.5703]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.4525, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(20.5529, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[-0.0550,  4.8956,  0.1492,  ..., -4.4725,  0.1339, -1.6803],
         [-0.1805, 12.5199, -0.7353,  ..., -1.0037, -0.9913, -1.7151]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0986, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(18.2858, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  608,  1338,  2652,  2882,  2033,   134,   305, 91516, 17403,  4596,
            202,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   115,   109,  7175,   113,  3064,   110,   108, 16036,
            649,   110,   107,   983,  3244,  2777,   165,   141, 16036,   649,
            126,   140,  1470,   115,   297,   118,   109,  5135,   110,   108,
            155,   163,  1262,   181,  6511,   124,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,   608,
           1338,  2652,  2882,  2033,   134, 71437, 17403,  4596, 16036,   148,
           1788,   114,  1933,   545,   162,   939,   109,   301,  1034,   116,
            700,   113,   702,   964,   164,   112,   109,  7175,   113,  3064,
            762, 14567,   110,   107,  2973,   112,   109,   301,   110,   108,
            114,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   110,   107,   983,  3244,  2777,   165,   141, 16036,
            243,   120,   126,   140,  1470,   115,   297,   118,   109,  5135,
            110,   108,   155,   126,   163, 17188,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4140 out of 11019)

Everytime after generating next logits 37.6% (4142 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[-0.0269,  3.9659,  0.4266,  ..., -4.3459,  2.2875, -0.3327],
         [-0.0870, 12.6685, -0.3497,  ..., -1.9432,  0.0724, -1.4058]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.3667, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.6016, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[-9.4203e-03,  5.2214e+00,  3.3179e-01,  ..., -4.4344e+00,
           1.9824e+00, -7.0672e-01],
         [-9.8569e-02,  1.3251e+01, -3.3105e-01,  ..., -1.1144e+00,
           3.7353e-01, -8.6121e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.2405, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.4143, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[ 4.2343e-03,  6.1285e+00,  1.0626e-01,  ..., -4.1161e+00,
           1.1959e+00, -1.4764e+00],
         [-1.0786e-01,  1.3104e+01, -2.9635e-01,  ..., -1.1723e+00,
           1.6265e-01, -6.2031e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.5014, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(5.2256, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[-0.0514,  7.0581, -0.0588,  ..., -4.0998,  0.3818, -1.4132],
         [-0.1223, 13.3656, -0.3170,  ..., -1.2629,  0.1736, -0.6159]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3610, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.5627, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[-1.0395e-02,  6.7227e+00, -8.3270e-02,  ..., -4.7438e+00,
           5.0801e-01, -1.2997e+00],
         [-1.1995e-01,  1.3325e+01, -3.4771e-01,  ..., -1.5173e+00,
           2.9794e-01, -6.3118e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2030, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.6044, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  530,  1268,  2651,  2882,  2033,   134, 80621, 17403,  4596, 25688,
            115, 16036,  1963,   902,   124,  1789,  2409,   114,   787,  7501,
           5268, 79701,   109,   762,   301,  1034,   116,  4206,   111, 12856,
            130,   210,   130, 16036,   118,   109,  7175,   113,  3064,   762,
          14567,   110,   107,   139, 11335,   134,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,  1024,   111,  1358,   112,   109,  1368,
            521,  9134,   762,  8186,   110,   107,  4987,   109,  4469,   110,
            108, 16036,  2853,  3947,   607,  2527,   110, 43995,   118,   109,
            211,   166,   381,   913,   289,   232,   110,   107,  6442,   260,
          21089, 80736, 82734,  4278,  3886,   112,  5930, 37313,   110,   108,
            142,   762,  8962,   122, 85411,   116,  1714,   208, 59297, 20185,
            110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)
SharesSharesSharesSharesSharesSharesSharesShares
iter = 0 reward = 0
final_logits =  tensor([[[-1.3609e-01,  5.9483e+00,  1.1997e-01,  ..., -4.5228e+00,
           2.4141e+00, -1.5314e+00],
         [ 3.2941e-02,  1.0960e+01,  1.1792e-01,  ..., -1.1211e+00,
           2.8040e-01,  9.9244e-01],
         [ 2.3121e-02,  1.1508e+01,  9.7721e-02,  ..., -1.1637e+00,
           2.4132e-01,  8.0141e-01],
         ...,
         [-1.0509e-02,  1.1448e+01, -1.3677e-01,  ..., -1.0476e+00,
          -1.8944e-01,  3.4940e-01],
         [-2.8123e-02,  1.1454e+01, -1.9899e-01,  ..., -9.1124e-01,
          -3.9249e-01,  3.1784e-01],
         [-4.6116e-02,  1.1507e+01, -2.5616e-01,  ..., -7.9075e-01,
          -6.0275e-01,  3.0686e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8828, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(6.4533, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
SharesSharesShares
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1462,  5.0910,  0.1244,  ..., -3.5380,  2.2804, -1.1932],
         [ 0.0757, 11.8398, -0.1408,  ..., -0.3970, -0.5574,  1.0004],
         [ 0.0572, 11.8825, -0.1634,  ..., -0.1984, -0.5654,  1.1162],
         [ 0.0424, 11.9364, -0.1873,  ..., -0.0932, -0.6473,  1.1694]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.4415, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.8140, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)

Everytime after generating next logits 38.1% (4194 out of 11019)
SharesSharesSharesShares
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1467,  4.9290,  0.1499,  ..., -3.6317,  2.1414, -1.4944],
         [ 0.0820, 11.8617, -0.1379,  ..., -0.6556, -0.9955,  1.4066],
         [ 0.0672, 11.9397, -0.1473,  ..., -0.4510, -1.0364,  1.6051],
         [ 0.0544, 11.9701, -0.1571,  ..., -0.2602, -1.0903,  1.7274],
         [ 0.0434, 11.9753, -0.1749,  ..., -0.2017, -1.1581,  1.8221]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.6643, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(4.0593, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
SharesSharesSharesSharesShares
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1474,  4.9915,  0.1702,  ..., -3.6633,  2.1386, -1.5879],
         [ 0.0838, 11.8006, -0.1250,  ..., -0.7180, -1.1278,  1.1379],
         [ 0.0727, 11.8421, -0.1314,  ..., -0.5415, -1.1223,  1.3359],
         [ 0.0625, 11.8801, -0.1411,  ..., -0.4052, -1.1729,  1.4789],
         [ 0.0552, 11.8701, -0.1515,  ..., -0.3324, -1.2269,  1.6436],
         [ 0.0477, 11.8867, -0.1708,  ..., -0.3128, -1.2322,  1.7895]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1964, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.5073, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
SharesSharesSharesSharesSharesSharesShares
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1384,  5.0124,  0.1644,  ..., -3.7261,  1.9740, -1.6158],
         [ 0.0929, 11.8114, -0.0988,  ..., -0.6640, -1.2672,  0.9514],
         [ 0.0879, 11.7777, -0.1040,  ..., -0.5461, -1.2811,  1.1369],
         ...,
         [ 0.0709, 11.7928, -0.1372,  ..., -0.3414, -1.3347,  1.6531],
         [ 0.0615, 11.8188, -0.1696,  ..., -0.3657, -1.3036,  1.8427],
         [ 0.0584, 11.8767, -0.1949,  ..., -0.4261, -1.2472,  1.8953]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.9009, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(3.0404, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3788,   110,   108,   258,   111,  1183,   109,  4193,   120,  5887,
            119,  3788, 22017,  3249,  2309,   114,  4340,   132,  2162,   110,
            108,   132,   989,  6502,   115,   150,   545,  1771,  6180,   114,
           4340,   493,   126,   586,   112,   258,   165,   241,   111,   173,
            157,   133,  6502,   110,   107, 14845,   127,  1661,   115,   156,
            295,   110,   108,  2063,   119,  1235,   111,   400,   489,   110,
            107, 21556,   116,  4170, 16036,   762, 14567,  1736,   651,  1265,
           1185,  2652,   110,   108,  3013,   111,  9792,  5297,  5299,  2346,
           3601,  2567,  7499,   114,  1736,   266,  1678,   115,   109, 11319,
            124,   109, 16036,   762, 14567,   110,   107,  2346,  3601,  2567,
            898,  6949,   120,   142,  8635,   933,   113,  1647,   196,   506,
            174,  9889,   110,   108,   155,   701, 51098,   192,   129,   656,
            130,  6031,  1219,   115,  4190,  6500,  3381,   113, 43278,   110,
            107,   139,   657,   148, 18097,   112,   110,   105,   543,   109,
           2919,   113,   219,  6209,   702, 16837,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Commons Commons Commons Commons Commons Commons today 
iter = 0 reward = 0
final_logits =  tensor([[[ 2.2398e-01,  4.9682e+00,  4.2268e-01,  ..., -8.4838e-01,
          -9.0605e-01, -2.2785e+00],
         [ 1.8336e-01,  3.9757e+00, -3.6917e-02,  ..., -4.1280e-01,
          -1.6095e+00, -1.2500e+00],
         [ 1.7340e-01,  3.5133e+00, -1.5400e-01,  ..., -7.2264e-01,
          -1.4151e+00, -1.1078e+00],
         ...,
         [ 2.4191e-02,  2.9875e+00, -3.9540e-01,  ..., -1.8230e+00,
          -9.0164e-01, -7.7646e-01],
         [ 1.7623e-01,  6.2713e+00, -3.3219e-01,  ..., -2.2814e+00,
          -4.8979e-01, -6.0085e-01],
         [-9.9774e-03,  1.2097e+01, -1.2635e-01,  ..., -4.4276e-01,
          -4.0695e-01,  3.4595e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.0876, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.7913, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Commons Commons Commons
iter = 1 reward = 0
final_logits =  tensor([[[ 0.2086,  5.6229,  0.4056,  ..., -0.8934, -0.9201, -2.4920],
         [ 0.0497,  9.0250, -0.1968,  ..., -0.1387, -1.9800, -1.9002],
         [ 0.0473,  8.6058, -0.2724,  ..., -0.3466, -1.9947, -1.7456],
         [ 0.0209,  9.1279, -0.4308,  ..., -0.7079, -2.0950, -1.8629]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(4.0107, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2417, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
Commons
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1641,  5.4714,  0.3194,  ..., -1.1160, -0.9548, -2.2873],
         [-0.0257, 11.7036, -0.4438,  ..., -0.4056, -1.7674, -2.3139]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.0392, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.4232, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
Peer
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1869,  5.5001,  0.3672,  ..., -0.9435, -0.9076, -2.2919],
         [ 0.1284, 11.3037, -0.3889,  ..., -0.4963, -2.1369, -1.6436]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8107, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8850, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
Peer
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1959,  5.5676,  0.3886,  ..., -0.9155, -0.9825, -2.2738],
         [ 0.1345, 11.4323, -0.3701,  ..., -0.4495, -2.2464, -1.6633]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.3408, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.6091, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1428,  1307,  2652,  2882,  2033,   134, 84838,   726, 17403,  4596,
          16036,   148,  1939,   114,   177, 14464,  3889,   124,   109, 14154,
           7175,   113,  3064,   762,   210,   110,   108,   301,  2662,   416,
            110,   107,   168,   117,  8549,   109,   177,  3889,   138,   923,
            109,  8186,   111,  3155,   109,   762,   269,   154,   113,   126,
            137,  6218,   190,   109,  1917,   155,   126,   256,   129,   372,
            228,   390,   269, 16036,   235,   682,   109,   807,  2353,   117,
           1147,   110,   107,   139, 11335,   113,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,   200,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
13 killed in the the 13 killed and the 13 people killed .
iter = 0 reward = 0
final_logits =  tensor([[[-0.2088,  7.5730,  0.1291,  ..., -2.2991,  1.1870,  0.3415],
         [-0.2019,  6.5524, -0.3362,  ..., -0.7113,  0.0641, -0.5013],
         [-0.1669,  5.4836, -0.4742,  ..., -0.9968,  0.2153, -1.2182],
         ...,
         [-0.1671,  7.3113, -0.5835,  ..., -1.5516,  0.0649, -1.0013],
         [-0.2282, 10.1295, -0.0546,  ..., -2.0730,  0.9056,  1.8655],
         [-0.2070, 12.1460, -0.1226,  ..., -1.8626,  0.5300,  0.6467]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8653, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2253, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
13 killed in the the 13 killed and the 13 killed .
iter = 1 reward = 0
final_logits =  tensor([[[-0.2228,  7.5760,  0.1155,  ..., -2.3288,  1.2106,  0.3303],
         [-0.2106,  6.5598, -0.3356,  ..., -0.7551,  0.0429, -0.5633],
         [-0.1789,  5.4944, -0.4899,  ..., -1.0595,  0.1966, -1.2472],
         ...,
         [-0.2236,  7.2290, -0.5197,  ..., -1.9535, -0.3470, -0.9861],
         [-0.2427,  9.9204,  0.0605,  ..., -1.8369,  0.6786,  1.7502],
         [-0.2270, 12.4100, -0.1540,  ..., -1.8686,  0.4915,  0.5883]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6755, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1393, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
13 killed in the the July explosion .
iter = 2 reward = 0
final_logits =  tensor([[[-0.2322,  7.5616,  0.1064,  ..., -2.3573,  1.2540,  0.2995],
         [-0.2184,  6.5434, -0.3331,  ..., -0.8061,  0.0327, -0.6303],
         [-0.1899,  5.4806, -0.5026,  ..., -1.1443,  0.1629, -1.2941],
         ...,
         [-0.1698,  7.4715, -0.7807,  ..., -2.0603,  0.2180, -0.3085],
         [-0.1492,  9.5486,  0.0909,  ..., -1.3531,  0.4478,  1.6023],
         [-0.2617, 13.0292, -0.2475,  ..., -1.1682,  0.4520,  0.4009]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5451, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0875, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
13 killed in the the July explosion .
iter = 3 reward = 0
final_logits =  tensor([[[-2.3401e-01,  7.5040e+00,  1.0324e-01,  ..., -2.3876e+00,
           1.3044e+00,  2.4683e-01],
         [-2.2281e-01,  6.5040e+00, -3.2967e-01,  ..., -8.3240e-01,
           3.7790e-03, -7.0242e-01],
         [-1.9637e-01,  5.4314e+00, -5.1060e-01,  ..., -1.2240e+00,
           9.9034e-02, -1.3363e+00],
         ...,
         [-1.6541e-01,  7.4127e+00, -7.8944e-01,  ..., -2.0269e+00,
           2.0552e-01, -3.4889e-01],
         [-1.5180e-01,  9.5199e+00,  8.9150e-02,  ..., -1.3735e+00,
           4.2641e-01,  1.5691e+00],
         [-2.6518e-01,  1.3037e+01, -2.5266e-01,  ..., -1.1887e+00,
           4.4752e-01,  3.5069e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3855, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0452, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
13 killed killed in the July explosion  
iter = 4 reward = 0
final_logits =  tensor([[[-2.3028e-01,  7.4052e+00,  1.0638e-01,  ..., -2.4235e+00,
           1.3696e+00,  1.6732e-01],
         [-2.2500e-01,  6.4257e+00, -3.2918e-01,  ..., -8.5345e-01,
          -3.3037e-02, -7.9241e-01],
         [-1.9924e-01,  5.3458e+00, -5.1332e-01,  ..., -1.2952e+00,
           4.5142e-03, -1.3813e+00],
         ...,
         [-2.0517e-01,  7.2656e+00, -7.7510e-01,  ..., -2.2143e+00,
           4.1115e-01, -5.1363e-01],
         [-1.6735e-01,  9.4118e+00,  7.9844e-02,  ..., -1.3590e+00,
           6.7732e-01,  1.2904e+00],
         [-2.1323e-01,  9.9728e+00,  1.7946e-02,  ..., -1.8321e+00,
           4.4219e-01,  1.2261e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2605, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   762, 14567,   114,   711,   113,   110,   105,  2111,  1057,
            395,  1034,   139, 21549, 16036,   762, 14567,   115,   109,  7175,
            113,  3064,   148, 50233,   109,  4170,   160,  3079,   644,  2175,
            110,   108,   155,   109,  1319,  1977,   113, 11461,   649,   109,
          14567,   140,   109,   711,   113,  1025, 46366,   110,   107,  1084,
          44907, 41534,   140,  1977,   113, 11461,  1034,   116,   655,   260,
            135,  5109,   112,  3390,   111,   148,   243,   223,   644,   524,
            632,   112,   823,   114,   110,   105, 30493,   824,   113,   109,
           2379,   110,   107, 16837,   125,   116,  1086,   734,   112,   145,
           1321,  1110,   299,   114,   300,   121,  1704,  6030,   112, 11881,
          13922,   110,   152,   325,   117,   461,   762,   297,   113,   109,
            951,   110,   108,   132,   109,   575,   110,   152,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
2008 2005 2005 fossil fuels strategies 
iter = 0 reward = 0
final_logits =  tensor([[[ 6.7465e-03,  4.2179e+00,  5.4758e-01,  ..., -2.6131e+00,
          -8.7728e-01, -5.9352e-01],
         [-6.3462e-02,  7.4053e+00,  3.7800e-01,  ..., -9.4174e-01,
           3.6113e-01, -1.6189e+00],
         [-1.1542e-01,  9.5646e+00,  2.4476e-01,  ..., -5.0733e-01,
           7.1161e-01, -1.6213e+00],
         ...,
         [-8.0024e-03,  7.6381e+00, -1.6878e-01,  ..., -2.3353e+00,
          -5.2893e-01, -8.2723e-01],
         [ 5.7860e-02,  7.2003e+00, -2.3305e-01,  ..., -2.2040e+00,
          -1.3323e+00, -1.3382e+00],
         [-1.3599e-01,  1.2229e+01, -5.1290e-02,  ..., -1.5783e+00,
          -6.7862e-01, -4.6631e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1758, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
2008 2005 2005 fossil fuels strategies 
iter = 1 reward = 0
final_logits =  tensor([[[ 3.0865e-03,  4.2053e+00,  5.5274e-01,  ..., -2.4724e+00,
          -9.0080e-01, -5.7459e-01],
         [-6.2497e-02,  7.3776e+00,  3.8835e-01,  ..., -9.1746e-01,
           3.8257e-01, -1.6406e+00],
         [-1.1578e-01,  9.4776e+00,  2.5371e-01,  ..., -4.6468e-01,
           7.4287e-01, -1.6171e+00],
         ...,
         [-9.1306e-03,  7.6182e+00, -1.5655e-01,  ..., -2.3134e+00,
          -5.1902e-01, -8.2313e-01],
         [ 5.6306e-02,  7.2047e+00, -2.2537e-01,  ..., -2.2181e+00,
          -1.3303e+00, -1.3401e+00],
         [-1.3823e-01,  1.2183e+01, -3.3130e-02,  ..., -1.6022e+00,
          -6.8506e-01, -4.7703e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0642, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
2008 2005 2005 fossil fuels strategies,
iter = 2 reward = 0
final_logits =  tensor([[[ 1.0512e-03,  4.2016e+00,  5.5844e-01,  ..., -2.3284e+00,
          -9.4181e-01, -5.5688e-01],
         [-6.0733e-02,  7.3361e+00,  4.0419e-01,  ..., -9.0447e-01,
           3.8782e-01, -1.6482e+00],
         [-1.1588e-01,  9.3750e+00,  2.6642e-01,  ..., -4.2412e-01,
           7.5968e-01, -1.5775e+00],
         ...,
         [-1.1113e-02,  7.6229e+00, -1.4671e-01,  ..., -2.3182e+00,
          -5.1096e-01, -8.1898e-01],
         [ 5.4561e-02,  7.2227e+00, -2.1749e-01,  ..., -2.2559e+00,
          -1.3422e+00, -1.3369e+00],
         [-4.1203e-02,  1.0736e+01, -2.5543e-01,  ..., -1.7303e+00,
          -6.0582e-01, -6.9372e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0834, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
2008 2005 2005 fossil fuels strategies,
iter = 3 reward = 0
final_logits =  tensor([[[ 1.9822e-02,  4.0798e+00,  5.8159e-01,  ..., -2.3505e+00,
          -8.7318e-01, -5.7518e-01],
         [-5.5035e-02,  7.3169e+00,  4.0461e-01,  ..., -8.8797e-01,
           3.8308e-01, -1.6930e+00],
         [-1.1288e-01,  9.4446e+00,  2.5136e-01,  ..., -4.1218e-01,
           7.8412e-01, -1.5694e+00],
         ...,
         [-4.4120e-03,  7.9173e+00, -1.6031e-01,  ..., -2.4302e+00,
          -3.9380e-01, -9.5642e-01],
         [ 6.3098e-02,  7.3110e+00, -2.0877e-01,  ..., -2.3404e+00,
          -1.3360e+00, -1.3549e+00],
         [-3.8035e-02,  1.0972e+01, -2.7155e-01,  ..., -1.7828e+00,
          -5.3317e-01, -7.8378e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1746, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 5.8711e-02,  3.7641e+00,  5.7215e-01,  ..., -3.0238e+00,
          -5.4610e-01, -8.9627e-01],
         [-9.8769e-02,  1.1221e+01, -2.7283e-01,  ..., -2.0681e+00,
           7.6613e-04, -2.2788e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2470, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1346,  6661,   118,   762, 14567,   945,   139,  2800,  1728,   112,
           2555,   110,   105, 41638, 16837,  1003,   121,   768,  1739,   120,
            133,   174,   263,   115,   109,  7175,   113,  3064,   139,  1346,
           6661,  2800,   110,   108,   229,   606,   118,  6957,   109,   808,
          70959,   503,   110,   108,   148,  2365,   114,  3662, 13602,   604,
            762,  1003,   121,   768,  1459,   110,   107,   139,  2800,   110,
            108,   162,  1653,   120,   203,  1962,  2560,   117,   110,   105,
            112,   650,   160,  8695, 33237,   118,   109,  1280,   113,  7633,
          16837,  1487,   203,   807,  4086,   134,   114,  1833,  1792,   115,
           1741,  3710,   110,   107,   182,   117,   203,  6932,   110,   105,
            698,  9501,  1702, 16837,   110,   107,  1810,  1518,   137,  2337,
            118,   109,  1702,   430,   960,  2651,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1]]])}

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
X X X is the the the X million used to launch 
iter = 0 reward = 2
final_logits =  tensor([[[-0.0923,  8.4426,  0.0896,  ..., -3.4344, -0.4019, -1.7933],
         [-0.1970,  5.0479, -0.3671,  ..., -3.1342, -1.0985, -0.9084],
         [-0.1998,  4.8853, -0.4212,  ..., -3.3288, -1.1172, -1.1512],
         ...,
         [-0.0620,  7.9057, -0.5192,  ..., -3.9915, -0.3828, -1.9397],
         [ 0.0134,  7.9055, -0.5476,  ..., -4.0077, -0.4597, -1.7096],
         [-0.1274, 10.6121, -0.1682,  ..., -2.6200, -0.6744, -0.0572]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1099, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2372, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
X Foundation
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1956,  6.5572,  0.4015,  ..., -3.3273, -0.1480, -1.7121],
         [-0.0246,  4.3640,  0.0599,  ..., -3.3007, -0.2901, -0.8363],
         [-0.1772, 12.2224, -0.5449,  ..., -2.2918, -0.9850, -0.9784]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3734, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[ 0.2680,  5.6898,  0.3384,  ..., -3.5525, -0.0345, -1.1881],
         [-0.0802, 13.2595, -0.3146,  ..., -1.4826, -0.3177, -1.4954]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2923, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0630, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
the
iter = 3 reward = 0
final_logits =  tensor([[[ 0.3162,  5.4335,  0.3570,  ..., -3.5395, -0.2680, -1.0375],
         [ 0.0673, 12.2192, -0.0327,  ..., -2.2037, -0.1630, -1.0266]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4616, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0926, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
the
iter = 4 reward = 0
final_logits =  tensor([[[ 0.2763,  4.9624,  0.4360,  ..., -3.7776, -0.4423, -0.7102],
         [ 0.0592, 12.0538,  0.0387,  ..., -2.2939, -0.2500, -1.1575]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5518, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1024, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3211,  1307,  2652,  2882,  2033,   134,   280, 85536, 17403,  4596,
            398, 16036,  1034,   116, 11599,  2664,   109,   519,   113,   114,
           6033,   124,  9134,  9600,   110,   108,   109, 12220,   113, 14645,
           9727,   135,   109,   762, 14567,   115,   109,  7175,   113,  3064,
            148,  9380,   164,   115,   114,  2043, 22369,   115, 10792,   110,
            107,   353,  1761,  7690,   355,  1854,   199,   109, 18191,   113,
          14645,   246,   129,  8626,   122,   110,   107,  9903, 90966,  1574,
            135,   351,   859,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Lawsuits
iter = 0 reward = 0
final_logits =  tensor([[[-0.1036,  4.7667,  0.3650,  ...,  0.6411,  1.2051,  0.0574],
         [-0.2109, 10.9701, -0.4367,  ...,  0.1102, -0.3470, -0.8317],
         [ 0.0135,  8.8636, -0.3284,  ...,  0.5035, -0.3573, -1.5600]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3870, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0809, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
Lawsuits to
iter = 1 reward = 0
final_logits =  tensor([[[-0.0951,  4.3790,  0.4029,  ...,  0.5509,  1.1618, -0.2007],
         [-0.1973,  9.8066, -0.3825,  ...,  0.0127, -0.2532, -0.8527],
         [ 0.0472,  7.9300, -0.2787,  ...,  0.3830, -0.2129, -1.7103],
         [ 0.0380,  9.2360, -0.3173,  ..., -0.6097, -0.2534, -1.5262]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6044, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1030, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Lawsuits dealt in in New Mexico .
iter = 2 reward = 1
final_logits =  tensor([[[-0.1036,  4.1036,  0.4188,  ...,  0.2953,  1.2052, -0.4594],
         [-0.1867,  9.0214, -0.3511,  ..., -0.1478, -0.3286, -0.9534],
         [ 0.0676,  7.1382, -0.2764,  ...,  0.0845, -0.3543, -1.8554],
         ...,
         [-0.2477,  5.4835, -1.0054,  ..., -2.0555, -0.7420, -1.9283],
         [-0.1232,  9.4903, -0.3430,  ..., -0.5515, -0.2486, -0.3933],
         [-0.1800, 12.8303, -0.6482,  ..., -0.4683, -0.0152, -1.3115]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.0160, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2839, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
The tide
iter = 3 reward = 0
final_logits =  tensor([[[-0.1101,  3.9591,  0.3941,  ...,  0.0835,  1.1746, -0.6032],
         [-0.1134,  9.0368, -0.0388,  ...,  0.2664, -0.0548, -1.8793],
         [-0.1611, 12.0376, -0.7951,  ..., -0.5565, -1.8113, -1.5577]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4263, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1104, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
The tide
iter = 4 reward = 0
final_logits =  tensor([[[-1.0916e-01,  3.9098e+00,  3.8807e-01,  ...,  1.5084e-02,
           1.1740e+00, -6.1534e-01],
         [-1.1003e-01,  8.7551e+00, -2.4964e-02,  ...,  2.6495e-01,
           6.9256e-03, -1.9264e+00],
         [-1.5325e-01,  1.1797e+01, -7.8538e-01,  ..., -5.7438e-01,
          -1.8037e+00, -1.5452e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4576, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1182, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 2571,  1508,  2652,  2882,  2033,   134,   305, 49218, 17403,  4596,
            222,  6358,   109, 40522, 34524,  4820,   164,   299,  4027,  1034,
            116, 62223,   454,  3682,  3793,   156,   113,   109,   278,  1034,
            116,  3741,   762, 12802,   110,   107,  1478,   115,   109,  5569,
            110,   108,  3070,   111,   176,  3217, 17659,   109,  1322,   192,
            394,  5097,   110,   107,   343, 62223,   148,   174, 71731,   115,
            109,  1965, 43983,   231,   110,   108,   112,   253,   142,  4156,
            120,   126,   117,   744,   130,   175,   109,  2648,   394,  2032,
            110,   107,   168,   117,  8549, 62223,  1034,   116,   584,   256,
            319,  2520,   118,   274,   115,   109,  7175,   113,  3064,   170,
            127, 48322,   120,   157,   138,   521,  5097,   135,   109,  2926,
          16036,   762, 14567,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1]]])}

Before Sampling 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
Galicia region in 2010 tourism 
iter = 0 reward = 1
final_logits =  tensor([[[-0.2155,  3.5262,  0.6619,  ..., -4.8130,  0.7799, -1.8363],
         [-0.3638,  5.0159, -0.6036,  ..., -6.0493, -2.5464, -3.4154],
         [-0.2435,  6.4848, -0.7391,  ..., -5.6253, -1.0831, -4.0945],
         ...,
         [-0.3220,  5.6448, -0.3842,  ..., -5.1878,  0.4509, -3.1096],
         [-0.1486,  3.5347, -0.6465,  ..., -5.3887,  0.0824, -2.8013],
         [-0.1943,  9.8365, -0.0516,  ..., -3.6795, -0.1321, -2.7631]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1588, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3630, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
Galicia region to recover from the disaster in 2010 .
iter = 1 reward = 2
final_logits =  tensor([[[-0.2097,  2.6909,  0.5529,  ..., -4.7209,  0.6048, -2.3386],
         [-0.3698,  4.6719, -0.6994,  ..., -5.7023, -2.4488, -3.8347],
         [-0.2263,  6.2531, -0.7913,  ..., -4.9580, -1.0820, -4.1577],
         ...,
         [-0.1769,  5.8986, -0.6725,  ..., -4.0482, -0.7708, -2.9822],
         [-0.1285,  9.3288, -0.1679,  ..., -2.6390, -0.2765, -1.8169],
         [-0.2695, 12.5044, -0.4619,  ..., -1.9904, -0.7052, -1.4289]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2948, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5554, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
Galicia region to recover from the disaster in 2010 .
iter = 2 reward = 2
final_logits =  tensor([[[-0.2201,  2.6850,  0.5425,  ..., -4.7910,  0.6595, -2.2463],
         [-0.3749,  4.7414, -0.7062,  ..., -5.7328, -2.4589, -3.8627],
         [-0.2320,  6.3858, -0.8051,  ..., -5.0038, -1.1097, -4.1888],
         ...,
         [-0.1823,  6.0037, -0.6740,  ..., -4.1075, -0.8011, -2.9987],
         [-0.1352,  9.6513, -0.1861,  ..., -2.6194, -0.3093, -1.7842],
         [-0.2715, 12.5863, -0.4719,  ..., -1.9787, -0.7551, -1.3985]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2543, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.5239, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
Galicia region to recover from the disaster in 2010 .
iter = 3 reward = 2
final_logits =  tensor([[[-0.2242,  2.6864,  0.5346,  ..., -4.7981,  0.6883, -2.2204],
         [-0.3777,  4.7222, -0.7100,  ..., -5.7320, -2.4328, -3.8633],
         [-0.2355,  6.3742, -0.8118,  ..., -5.0089, -1.0955, -4.1758],
         ...,
         [-0.1833,  5.9779, -0.6788,  ..., -4.0887, -0.7846, -3.0029],
         [-0.1344,  9.5820, -0.1832,  ..., -2.6344, -0.2990, -1.7990],
         [-0.2722, 12.5554, -0.4736,  ..., -1.9721, -0.7539, -1.3924]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2048, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.4992, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galicia region to recover from the disaster in 2010 .
iter = 4 reward = 2
final_logits =  tensor([[[-0.2327,  2.7181,  0.5175,  ..., -4.7776,  0.7409, -2.2183],
         [-0.3807,  4.6968, -0.7117,  ..., -5.6998, -2.3784, -3.8481],
         [-0.2401,  6.3222, -0.8164,  ..., -4.9838, -1.0604, -4.1338],
         ...,
         [-0.1849,  5.9087, -0.6885,  ..., -4.0463, -0.7431, -2.9952],
         [-0.1324,  9.3707, -0.1766,  ..., -2.6518, -0.2593, -1.8269],
         [-0.2741, 12.4764, -0.4700,  ..., -1.9817, -0.7227, -1.4058]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1480, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.4763, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  787, 17984,   116, 16036,   204,  7175,   113,  3064,   762,  5135,
           1195,  1408,  2652,  2882,  2033,   134, 79386,   914, 17403,  4596,
            139,   706,  1013,   117,   112, 17984, 16036,   111,  1965,   176,
            524,   204,   114,  1124,   762, 14567,   115,   109,  7175,   113,
           3064,   110,   107,   139,   657,   243,   126,   192,  1137,   109,
           3358,  1069,  9873,   118,   109, 13353,   113,  2729,  1363,   124,
           1496,   164,   109,  3741,  2249,  5135,   115,   787,   689,   110,
            107, 36347,  1024,  2342,   115,   109, 11335,   124,   109, 81065,
          18308,  9600, 13773,   115,   960,   110,   107,   139,  6442,  1034,
            116, 55065, 66707,  1574,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1]]])}

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
BBC
iter = 0 reward = 1
final_logits =  tensor([[[-0.2515,  4.5119,  0.2887,  ..., -5.3447,  2.7799, -1.3551],
         [-0.1948, 12.0466, -0.1673,  ..., -4.4201, -0.8247, -3.0348]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6143, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3132, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
BBC
iter = 1 reward = 1
final_logits =  tensor([[[-0.2595,  4.5779,  0.2675,  ..., -5.3858,  2.7764, -1.4493],
         [-0.2128, 12.1952, -0.2494,  ..., -3.6872, -0.7838, -2.7206]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4863, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2954, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
BBC
iter = 2 reward = 1
final_logits =  tensor([[[-0.2621,  4.5285,  0.2503,  ..., -5.3293,  2.9186, -1.4642],
         [-0.2187, 12.2083, -0.2452,  ..., -3.7457, -0.8742, -2.7721]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4019, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2799, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
BBC
iter = 3 reward = 1
final_logits =  tensor([[[-0.2644,  4.5248,  0.2366,  ..., -5.2580,  2.9827, -1.4801],
         [-0.2259, 12.2188, -0.2436,  ..., -3.7818, -0.9537, -2.7793]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3491, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2625, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
BBC
iter = 4 reward = 1
final_logits =  tensor([[[-0.2687,  4.5080,  0.2322,  ..., -5.2004,  3.0263, -1.4917],
         [-0.2332, 12.2273, -0.2373,  ..., -3.8198, -1.0347, -2.7643]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3018, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2461, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 7915, 26939,  4355,  1194,   244, 16036,   762, 14567,  5823,  8437,
            117,   364,   109, 19954,   113,   109,  7175,   113,  3064,   235,
            149,   314,   210,   110,   107,   139,   908,   317,  6299,   111,
           1174,   117,  8988,   153, 19347,   578,   110,   107,   343,   136,
            232,   205,   113,   109, 27736,   127,  2609,   110,   107,   139,
          27736,   127,   146,  1622,   115,   762,   110,   108,   130,   109,
           6442,  1034,   116,  2040,  9518,  1574,   135,  7915,   110,   108,
            155,  3040,   299,   141,  2926, 21615, 22611,   116,   120,   195,
           2443,   112,  2512,   109, 15737,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
economic
iter = 0 reward = 0
final_logits =  tensor([[[-5.4869e-01,  6.7361e+00,  8.1490e-02,  ..., -4.4938e+00,
           2.1558e-02, -2.3077e-01],
         [-3.8289e-01,  1.2767e+01, -4.8850e-01,  ..., -2.7751e+00,
          -6.2206e-01,  8.1244e-03]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6479, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1459, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[-0.5585,  6.3378,  0.1159,  ..., -4.6491,  0.0201, -0.0543],
         [-0.4947, 12.0803, -0.3580,  ..., -3.0639, -0.4242, -0.9593]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5202, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
economic economic reports
iter = 2 reward = 1
final_logits =  tensor([[[-0.5369,  5.5733,  0.0764,  ..., -4.2544, -0.0976,  0.1088],
         [-0.2768,  8.1125, -0.3165,  ..., -3.6592, -0.5059, -0.0861],
         [-0.2980,  8.7558, -0.3791,  ..., -3.9184, -0.5585, -0.1506],
         [-0.2166,  9.2172, -0.8012,  ..., -4.1470, -0.7568, -0.4158]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0258, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3805, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[-0.5523,  5.9799,  0.1235,  ..., -4.7878,  0.0228, -0.1749],
         [-0.5148, 10.9146, -0.3259,  ..., -3.4096, -0.5327, -0.9430]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6422, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0916, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)

Everytime after generating next logits 37.7% (4154 out of 11019)
economic
iter = 4 reward = 0
final_logits =  tensor([[[-0.5317,  6.1597,  0.0874,  ..., -4.3879,  0.0788, -0.1704],
         [-0.3619, 11.8863, -0.3971,  ..., -3.4955, -0.4791, -0.1625]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8212, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1756, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
topic:  ('bpoil_bbc',)
env initialized...

Before training:  37.7% (4150 out of 11019)
{'input_ids': tensor([[[  110,   105,  3893, 15737,  1034,  8255,   464, 16036,   134,   109,
           1816,  2447,   139,  1816,  2447,   649,   126,   117,  4562,   112,
          16036,   118,   203,   337,   983,   762,   121,  2134,  5626,   148,
            174, 12832,   279,   156,   113,   109,  1816,  2447,  1034,   116,
          18072,   141, 10162, 18232,   126,   112,   370,   203, 10971,   818,
            122, 16036,   110,   107,   139,  4635, 41588,   110,   108, 50595,
          81452, 60490,   457,   131,   304,   110,   108,   117,   114,  4055,
          17225,   113,   114,   883,   693,   111, 28286,   111,   117,   160,
           6155,   231,   459,   110,   107,   202,   456,   568,  7200,  9221,
           3893,  2777,   165,   109,  8255,   110,   107,   202,   984,  8255,
           4635, 20678,  4329,   115,  1185,   110,   107,   139,  1816,  2447,
            243,   109,  5626,  1065,   140, 39059,   110,   108,   162,   196,
            146,  3954,   109,  4976,  2098, 11976,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
A Hoa Hoa
iter = 0 reward = 0
final_logits =  tensor([[[ 4.6758e-02,  3.7367e+00,  9.1492e-01,  ..., -4.2828e+00,
           1.3976e+00,  8.0241e-01],
         [-2.6187e-02,  4.9946e+00,  8.0997e-01,  ..., -3.7115e+00,
           6.4670e-01, -6.1404e-01],
         [-1.5671e-01,  1.1148e+01,  3.6437e-01,  ..., -1.8430e+00,
           2.1648e-01, -1.0772e-02],
         [-1.9622e-01,  1.2085e+01,  3.2671e-01,  ..., -1.6877e+00,
           5.0365e-02, -3.2440e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.9474, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2409, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)

Everytime after generating next logits 38.0% (4190 out of 11019)
A Hoa Hoa Hoa Hoa Hoa Hoa Hoa Hoa Hoa Hoa
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0352,  3.1658,  0.9421,  ..., -4.3262,  1.4057,  0.9094],
         [-0.0258,  2.8405,  0.8324,  ..., -3.9478,  0.5619, -0.7179],
         [-0.0553,  6.3758,  0.5654,  ..., -2.0265,  0.4257, -0.3623],
         ...,
         [-0.1722,  9.9746,  0.5672,  ..., -1.6773,  0.5873, -0.6529],
         [-0.1811, 10.4144,  0.5212,  ..., -1.6625,  0.5000, -0.7223],
         [-0.1862, 10.9261,  0.4720,  ..., -1.7529,  0.3312, -0.6680]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.5431, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1230, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
A Hoa Hoa Hoa Hoa June statue targeted by British Museum .
iter = 2 reward = 2
final_logits =  tensor([[[ 3.0591e-02,  2.7439e+00,  9.6296e-01,  ..., -4.2886e+00,
           1.4533e+00,  1.0216e+00],
         [-4.1703e-02,  2.3205e+00,  7.9432e-01,  ..., -4.0231e+00,
           5.9032e-01, -5.5735e-01],
         [-3.4354e-02,  4.9743e+00,  6.4465e-01,  ..., -2.2181e+00,
           4.6859e-01, -4.1054e-01],
         ...,
         [ 6.2956e-03,  3.1577e+00, -4.2589e-01,  ..., -5.1335e+00,
           1.3184e+00, -4.4169e-01],
         [-8.9020e-02,  8.6923e+00,  1.5528e-01,  ..., -3.1414e+00,
           9.1916e-01,  3.7514e-01],
         [-2.3292e-01,  1.1985e+01,  1.3392e-01,  ..., -3.7755e+00,
           1.1248e+00,  6.1993e-02]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2243, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5430, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
A Hoa Hoa Hoa June statue targeted by British Museum .
iter = 3 reward = 2
final_logits =  tensor([[[ 3.0137e-02,  2.6895e+00,  9.6201e-01,  ..., -4.2096e+00,
           1.5045e+00,  1.0696e+00],
         [-4.4384e-02,  2.2617e+00,  7.9578e-01,  ..., -3.9658e+00,
           6.5322e-01, -4.4661e-01],
         [-2.9045e-02,  4.9506e+00,  6.9122e-01,  ..., -2.2610e+00,
           6.0790e-01, -4.1469e-01],
         ...,
         [ 1.7115e-03,  2.8812e+00, -4.3353e-01,  ..., -5.3826e+00,
           1.1335e+00, -2.5169e-01],
         [-6.6318e-02,  7.4339e+00,  2.7718e-01,  ..., -3.5942e+00,
           1.0772e+00,  8.1505e-01],
         [-2.2625e-01,  1.1823e+01,  1.4729e-01,  ..., -3.5999e+00,
           8.6213e-01,  3.2222e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1242, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5388, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)
A Hoa Hoa Hoa June statue targeted by British Museum .
iter = 4 reward = 2
final_logits =  tensor([[[ 2.9121e-02,  2.8534e+00,  9.5627e-01,  ..., -4.0908e+00,
           1.4846e+00,  1.0036e+00],
         [-3.9405e-02,  2.4526e+00,  8.1796e-01,  ..., -3.8298e+00,
           6.7543e-01, -4.0333e-01],
         [-3.1087e-02,  5.4236e+00,  7.2099e-01,  ..., -2.2474e+00,
           7.5721e-01, -3.4565e-01],
         ...,
         [-2.0144e-03,  3.3235e+00, -4.3785e-01,  ..., -5.4129e+00,
           1.0632e+00, -1.7802e-01],
         [-1.0221e-01,  9.2776e+00,  2.1559e-01,  ..., -3.1860e+00,
           8.5732e-01,  7.2102e-01],
         [-2.2514e-01,  1.2139e+01,  1.2203e-01,  ..., -3.4988e+00,
           7.9914e-01,  2.8377e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1534, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5430, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[ 4123,   113,   219,  6234,   195,  6908,   115,   109, 75158,  1153,
           3893,  1419, 16036,   148,  6305,  3906,   142, 10580,   805,   113,
            203,  7175,   113,  3064,   762, 14567,  1407,  1104,   124,   203,
            387,   110,   107,   139,  1082,   110,   108,  1155,   204,   109,
           1339,   110,   108,   939,  1841,   115,   683,   113,   114,  1679,
            113,   461,  6234, 10361,  1055,   113,   203,  3954,   210,   124,
            109,  1917,  1030,   110,   107, 16036,  9619,  3582,  7217,   243,
            120,   339,  6234,   195,  6908,   115,   109,   856,  1153,   111,
          10390,   680,   196,   174,   263,   112,   535,  1055,   110,   107,
            139, 10580,   805,   140,  3530,   122,   109,   856,   244,   114,
            787,  9024,  8666,   126,   110,   107,  1263,  7217,   243,   109,
           4787,   170,   635,   109,  1153,   140, 10361,   169,   766,   122,
          10390,   680,   111,   186,   140,   220,  5313,  6596,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)
Photoshop Photoshop screens screens which
iter = 0 reward = 0
final_logits =  tensor([[[ 0.1236,  3.9457,  0.5061,  ..., -6.0062,  1.5023, -0.8412],
         [ 0.1353,  5.6003, -0.2005,  ..., -5.6687, -1.5758, -1.7439],
         [ 0.1144,  5.9858, -0.3187,  ..., -5.8451, -1.6922, -1.6901],
         [ 0.0978,  8.6725, -0.7457,  ..., -5.8050, -1.6090, -2.2922],
         [ 0.0490,  9.7863, -0.8071,  ..., -5.4818, -1.7100, -2.5199],
         [ 0.0259, 11.6330, -0.5549,  ..., -4.5761, -1.1958, -1.6313]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-2.1572, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8700, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Photoshop Photoshop workers who altered the image .
iter = 1 reward = 0
final_logits =  tensor([[[ 0.1216,  3.8941,  0.5019,  ..., -6.1500,  1.3861, -0.8539],
         [ 0.1401,  5.5100, -0.1961,  ..., -5.6320, -1.6525, -1.7280],
         [ 0.1186,  5.8714, -0.3135,  ..., -5.8189, -1.7529, -1.6717],
         ...,
         [ 0.1375,  5.9353, -0.8200,  ..., -3.5846, -1.2686, -1.4526],
         [ 0.0493, 10.5357, -0.1506,  ..., -3.0503, -0.6015, -0.7916],
         [-0.0202, 13.0648, -0.4007,  ..., -4.3396,  0.4272, -1.7833]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.3621, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7056, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)

Everytime after generating next logits 38.2% (4210 out of 11019)
Images of
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1192,  3.8540,  0.4924,  ..., -6.2884,  1.2894, -0.7807],
         [-0.0582,  9.5492, -0.6348,  ..., -3.5715, -1.8386, -2.2232],
         [-0.0171, 12.1414, -0.5978,  ..., -4.2820, -0.0670, -1.1852]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.6691, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7555, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1204,  3.7961,  0.4788,  ..., -6.4954,  1.2681, -0.6943],
         [-0.0233, 12.0251, -0.1860,  ..., -4.7085,  0.5191, -1.8240]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.3665, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5951, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1177,  3.8379,  0.4780,  ..., -6.4903,  1.2491, -0.6328],
         [-0.0275, 12.1098, -0.1836,  ..., -4.6584,  0.5063, -1.8026]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.3486, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5574, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[599, 960, 110,  ..., 109, 804,   1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 39.0% (4296 out of 11019)

Everytime after generating next logits 39.0% (4296 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[-0.4447,  4.3991, -0.2237,  ..., -4.0500,  1.7647, -0.2400],
         [-0.2758, 11.3505, -0.9377,  ..., -1.8207, -1.3158, -0.9004]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2670, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[-0.4454,  4.4403, -0.2278,  ..., -4.0692,  1.7811, -0.2799],
         [-0.2701, 11.4321, -0.9359,  ..., -1.7563, -1.2331, -0.8984]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2929, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[-0.4512,  4.8432, -0.2488,  ..., -4.0637,  1.7562, -0.4833],
         [-0.2383, 11.9723, -0.8760,  ..., -1.3604, -0.9079, -0.7770]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3100, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1218, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[-0.4495,  4.6883, -0.2489,  ..., -4.0952,  1.6602, -0.9090],
         [-0.2392, 12.0009, -0.9074,  ..., -1.3918, -0.9007, -0.7878]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2227, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1221, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[-0.4484,  4.6817, -0.2565,  ..., -4.2725,  1.5903, -1.0741],
         [-0.2357, 12.0243, -0.9074,  ..., -1.4817, -0.9374, -0.7828]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1975, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1268, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[6174,  692,  110,  ...,  526,  115,    1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Environment
iter = 0 reward = 0
final_logits =  tensor([[[-0.2706,  4.4775,  0.1480,  ..., -4.8344,  0.0164,  0.2363],
         [-0.3446, 11.9002, -0.7597,  ..., -1.2848, -0.9325, -1.1622]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8435, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1589, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
Environment
iter = 1 reward = 0
final_logits =  tensor([[[-0.2701,  4.5056,  0.1464,  ..., -4.8144,  0.0231,  0.2527],
         [-0.3451, 11.8866, -0.7617,  ..., -1.2734, -0.9239, -1.1483]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8523, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1544, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[-0.2684,  4.5555,  0.1450,  ..., -4.7566,  0.0405,  0.2929],
         [-0.2719, 13.2378, -0.4814,  ..., -1.8447, -0.0922, -1.0089]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7250, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1266, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[-0.2666,  4.5848,  0.1447,  ..., -4.7145,  0.0650,  0.3169],
         [-0.2718, 13.2478, -0.4776,  ..., -1.8378, -0.0922, -0.9699]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7084, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1217, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[-0.2649,  4.5887,  0.1420,  ..., -4.6901,  0.0809,  0.3093],
         [-0.2709, 13.2532, -0.4757,  ..., -1.8283, -0.1059, -0.9485]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7028, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1169, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  139,  5543,  9254,   320,  3702,   142,   865,   728,   113,   109,
          16036,   762, 14567,   110,   107,  8916,   114,  1713,   113,  5012,
            122,   662,   503, 32908,   110,   108,   330,   278,  2668,   116,
            122,  4605, 35522,   110,   108,   109,   177,  3378,   113, 16036,
            111,  6061, 32886,   110,   108,   169, 15978,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4138 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0432,  4.2269,  0.3573,  ..., -2.5571,  0.9341, -2.2108],
         [-0.0742,  8.7641, -0.3337,  ..., -3.0894,  0.7404, -1.5008]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6769, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1373, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0492,  4.1938,  0.3802,  ..., -2.6430,  0.9804, -2.2513],
         [-0.0652,  8.5698, -0.3377,  ..., -3.2799,  0.7932, -1.4821]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7048, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1314, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0575,  4.2002,  0.4184,  ..., -2.9430,  1.0087, -2.2781],
         [-0.0376,  8.6354, -0.3276,  ..., -3.5446,  0.8737, -1.4950]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7248, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1218, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0749,  3.8926,  0.4222,  ..., -3.2420,  1.1929, -2.3711],
         [-0.0131,  8.4860, -0.3264,  ..., -3.8021,  0.9189, -1.3776]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8708, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1207, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.7% (4152 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)

Everytime after generating next logits 37.9% (4172 out of 11019)
Money Money features Bob Tony and Bob Tony 
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0753,  4.5188,  0.4924,  ..., -2.8576,  0.7994, -2.6800],
         [ 0.0583,  5.7907, -0.2687,  ..., -4.0409, -1.8332, -3.3999],
         [ 0.0528,  6.1095, -0.2930,  ..., -3.8049, -2.0439, -3.4346],
         ...,
         [ 0.0423,  7.2598, -0.3853,  ..., -3.8905, -2.6802, -2.4616],
         [ 0.1001,  5.6469, -0.7521,  ..., -4.2530, -4.2878, -4.0451],
         [ 0.0618, 10.4242, -0.0319,  ..., -3.6689, -2.2543, -1.8078]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6436, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1462, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1084, 18756,   110,  ...,  5135,   378,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 38.0% (4182 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.1% (4310 out of 11019)

Everytime after generating next logits 39.7% (4374 out of 11019)
BP has a
iter = 0 reward = 1
final_logits =  tensor([[[-0.4569,  2.3654, -0.1718,  ..., -3.9479,  2.6915, -1.4724],
         [-0.2948,  7.0515, -0.9862,  ..., -3.6200, -0.4233, -1.3982],
         [-0.0862,  8.3129, -0.5757,  ..., -2.1359,  0.0715,  0.5524],
         [-0.2678, 10.3781, -0.3301,  ..., -2.1486,  0.4944,  1.4949]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1657, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2217, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)

Everytime after generating next logits 38.9% (4288 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[-0.4482,  2.9443, -0.2054,  ..., -4.0800,  2.6216, -1.5850],
         [-0.3416,  9.7950, -1.0256,  ..., -3.3918, -0.6100, -1.4402]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.8508, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2549, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[-0.4407,  3.1091, -0.2118,  ..., -4.1685,  2.5713, -1.6544],
         [-0.3434, 11.1908, -1.0200,  ..., -3.2007, -0.7226, -1.3385]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5159, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2667, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[-0.4343,  3.1978, -0.2130,  ..., -4.2237,  2.5332, -1.6713],
         [-0.3436, 11.5152, -1.0164,  ..., -3.1552, -0.7526, -1.3356]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4553, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2698, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[-0.4329,  3.1866, -0.2166,  ..., -4.2695,  2.5086, -1.6768],
         [-0.3417, 11.4828, -1.0154,  ..., -3.1582, -0.7483, -1.3514]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4458, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2653, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[16036,   243,   186,  ...,   111,  2684,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[ 0.1036,  5.1042,  0.2718,  ..., -2.7796,  4.5670, -2.3801],
         [-0.1086, 11.5467, -0.7334,  ..., -2.8575, -0.1024, -1.5920]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3996, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1541, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[ 0.1110,  5.0868,  0.2683,  ..., -2.8098,  4.5570, -2.3876],
         [-0.1025, 11.6029, -0.7186,  ..., -2.7134, -0.1370, -1.4881]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3702, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1488, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[ 0.1148,  5.1260,  0.2623,  ..., -2.7853,  4.5123, -2.4495],
         [-0.0946, 11.6181, -0.7136,  ..., -2.6225, -0.1776, -1.3861]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3193, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1353, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[ 0.1214,  5.1730,  0.2658,  ..., -2.7607,  4.4916, -2.5070],
         [-0.0884, 11.6073, -0.7030,  ..., -2.5285, -0.2074, -1.2393]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2796, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1186, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[ 0.1321,  5.1672,  0.2889,  ..., -2.7162,  4.5234, -2.5448],
         [-0.0857, 11.5880, -0.6823,  ..., -2.4425, -0.2178, -1.1662]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2415, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1054, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[16036, 35640,   116,  ...,  3598, 32220,     1]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[-0.4836,  5.0955,  0.2763,  ..., -4.0843,  1.4876, -0.9888],
         [-0.2950, 12.4870, -0.7701,  ..., -1.8617, -0.3172, -0.6607]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5093, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2704, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
BP plans to ensure ensure it it is
iter = 1 reward = 1
final_logits =  tensor([[[-3.4724e-01,  2.3119e+00,  4.2535e-01,  ..., -4.0552e+00,
           7.2339e-01, -5.3732e-01],
         [-1.7366e-01,  6.7601e+00, -7.9883e-01,  ..., -2.3993e+00,
          -2.4320e-01, -1.5476e+00],
         [ 7.9370e-03,  8.7984e+00, -4.9766e-01,  ..., -1.5457e+00,
           1.6847e+00, -4.3234e-01],
         ...,
         [-1.8809e-01,  7.6464e+00, -6.2032e-01,  ..., -9.7348e-01,
          -6.7601e-01,  4.8521e-01],
         [-1.7898e-01,  7.0038e+00, -6.2631e-01,  ..., -1.0778e+00,
          -5.4752e-01,  3.8749e-01],
         [-6.1805e-02,  8.6820e+00, -3.4835e-01,  ..., -1.2087e+00,
           1.5349e+00,  3.4362e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.6413, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.4% (4236 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)

Everytime after generating next logits 39.0% (4300 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[-0.3414,  3.8147,  0.3775,  ..., -4.0399,  0.6396, -0.7534],
         [-0.2551, 12.0651, -0.8984,  ..., -2.1281, -0.6235, -0.9541]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2683, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1305, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)

Everytime after generating next logits 39.5% (4350 out of 11019)
BP plans to ensure
iter = 3 reward = 1
final_logits =  tensor([[[-4.3799e-01,  3.8691e+00,  2.2251e-01,  ..., -3.1402e+00,
           1.5740e+00, -5.3195e-01],
         [-2.2209e-01,  7.8676e+00, -8.8970e-01,  ..., -2.7569e+00,
          -4.4627e-01, -2.5405e+00],
         [-2.2609e-03,  9.2583e+00, -4.4477e-01,  ..., -1.5297e+00,
           2.1859e+00, -7.9294e-01],
         [-1.6245e-01,  8.6510e+00, -2.4788e-01,  ..., -1.7039e+00,
           1.4976e+00,  1.3763e+00],
         [-1.5456e-01,  1.0567e+01, -4.7270e-01,  ..., -1.5105e+00,
           1.4756e+00,  7.3556e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.5314, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.8% (4162 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 39.5% (4354 out of 11019)
BP plans to
iter = 4 reward = 1
final_logits =  tensor([[[-0.4012,  3.4704,  0.1928,  ..., -3.4035,  1.5735, -1.0048],
         [-0.2396,  9.3171, -0.9744,  ..., -2.6149, -0.6438, -2.7842],
         [-0.0572, 11.3676, -0.5563,  ..., -1.4011,  1.4584, -0.7782],
         [-0.1806, 11.3507, -0.3557,  ..., -1.4833,  0.7418,  1.0881]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4497, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  787,  1276, 12998,  3531,   148,  4486, 18205, 53857,  7028,   112,
          15079,   109,  3662,   599, 10970,   233, 20447,   788,   121,  1768,
          43304,   110, 10970,   233, 16567,   788,   121,  2617,   120, 16036,
            148,   323,   164,   112, 13889,  4807,   113,   109,  7175,   113,
           3064,   762, 14567,   110,   107,  1263, 53857,  7028,   148,   306,
            115,   253,  2887,   110,   151,   178,  3120,   109,  4807,  1034,
           1844,  2617,   323,   164,   115,   109,  4619,   113,   109,  1073,
           1338,  6687,  3613,   115,   351,   859,   111,  1741,   110,   107,
            285,   148,   243,   178,   117,   146, 10237,   122,   109,   657,
            132, 16036,   111,   138, 15079,   109,  2617,  7539,   110,   107,
           2632,   138,   719,  3916,   135,   109,  2617,   110,   152,   139,
            762, 14567,   148,  2145, 12071,   466,   109,   787,  7175,  3500,
            110,   108,  7271,  3070,   111,  5569,   111, 65047,   181,  4758,
            111, 44650, 18205, 53857,  7028, 35571,  3916,   118,  4807,   113,
            109,  1073,  1338,   110,   108,  6687,  3613,  7922,  8749, 18205,
          53857,  7028, 18097, 16915,   918,   111,   243,  2784,   192,   129,
            154,  5263,   197,   274,   120,   192,   129,  3366,   141,   114,
           1462,   110,   107,   343,   178,   243,   274,  2486,  3916,   355,
            361,   164,   153,   268,   112, 17984, 16036,   110,   107,   139,
           2617,   117,   112, 34262,  7175,   113,  3064,  1836,   111,  1098,
            118,  1166,  9125,   111,  5471,   111,   118,   510,  3207,   111,
           1003,   121,   768,   110,   108,   790,   176,  2242,   110,   107,
          16036,   148,   506,  1389,  3662,   110, 37622,   208,   115,  2242,
            381,   109,   960, 14567,   110,   107,   139,   762, 14567,   110,
            108,   162,  1219,   599,   960,   122,   109, 11335,   113,   109,
          16036,   121, 38539,   252, 81065, 18308,  9600, 13773,   110,   108,
           2145,  8010, 12071,   466,   109,   787,  7175,  3500, 18205, 53857,
           7028, 35571,  3916,   118,  4807,   113,   109,  1073,  1338,   110,
            108,  6687,  3613,   139,  8749,   113,   114,  3662,   599, 10970,
            233, 20447,   788,   121,  1768, 31197,   110, 10970,   233, 16567,
            788,   121,  2617,   112, 13889,  4807,   113,   109, 16036,   762,
          14567,   148,   243,   186,   117,   110,   105,   220,  2767, 16837,
            120, 15931,  2242,   127,   142,   797,   110,   107, 18205, 53857,
           7028, 18097,   112,   129, 24915,   204,   170,   915,  2784,   112,
           1480,   109,  4959,   113,   109,  2617,   110,   107,  3440,  3662,
          12622,   110, 10970,   148,   506,   174,  1389,   165,   115,  2280,
           2784,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.8% (4160 out of 11019)

Everytime after generating next logits 37.8% (4160 out of 11019)

Everytime after generating next logits 37.8% (4160 out of 11019)

Everytime after generating next logits 37.8% (4160 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)

Everytime after generating next logits 37.9% (4180 out of 11019)
BP has been awarded to the Gulf spill .
iter = 0 reward = 3
final_logits =  tensor([[[ 0.0429,  3.3477,  0.4282,  ..., -1.5051,  4.8014, -1.2971],
         [-0.1034,  3.3534, -0.7964,  ..., -3.7689,  0.5303, -3.2692],
         [ 0.1067,  4.7784, -0.1989,  ..., -2.6338,  0.4702,  0.3197],
         ...,
         [-0.1028,  5.0519, -0.7992,  ..., -1.8701,  0.8608, -0.1722],
         [-0.0791,  8.7951, -0.1905,  ..., -2.0962, -0.0191,  0.1956],
         [-0.1723, 13.1860, -0.4211,  ..., -1.6176,  1.4673, -1.7545]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.2428, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.2335, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
BP has been awarded to the Gulf spill .
iter = 1 reward = 3
final_logits =  tensor([[[ 0.0367,  3.7167,  0.4744,  ..., -1.5715,  5.1367, -1.2383],
         [-0.1093,  3.6812, -0.8270,  ..., -4.0986,  0.6317, -3.7925],
         [ 0.1151,  5.1637, -0.1875,  ..., -2.7026,  0.4717, -0.0657],
         ...,
         [-0.1106,  5.3998, -0.8072,  ..., -1.8402,  1.0031, -0.2177],
         [-0.0814,  8.9761, -0.2060,  ..., -2.1678, -0.0878, -0.0446],
         [-0.1616, 13.2939, -0.3927,  ..., -1.5504,  1.6959, -1.6537]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.1124, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.1521, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
BP has been awarded to the Gulf spill .
iter = 2 reward = 3
final_logits =  tensor([[[ 3.6477e-02,  3.6245e+00,  4.7099e-01,  ..., -1.5411e+00,
           5.2210e+00, -1.1497e+00],
         [-9.6370e-02,  3.6660e+00, -8.2677e-01,  ..., -3.8747e+00,
           4.8844e-01, -3.9215e+00],
         [ 1.2123e-01,  4.9234e+00, -1.7925e-01,  ..., -2.8119e+00,
           6.5069e-01, -1.6182e-01],
         ...,
         [-1.0184e-01,  5.2822e+00, -8.1860e-01,  ..., -1.8572e+00,
           1.0717e+00, -2.7907e-01],
         [-8.2716e-02,  8.9285e+00, -2.1570e-01,  ..., -2.3040e+00,
           4.1279e-02, -4.3511e-05],
         [-1.6036e-01,  1.3258e+01, -3.9335e-01,  ..., -1.6310e+00,
           1.8985e+00, -1.6808e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.0244, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(2.0697, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
BP has been awarded to the Gulf spill .
iter = 3 reward = 3
final_logits =  tensor([[[ 0.0287,  3.6216,  0.4587,  ..., -1.5290,  5.1903, -1.1720],
         [-0.0792,  3.6780, -0.8021,  ..., -3.7590,  0.4078, -3.9657],
         [ 0.1271,  4.7580, -0.1802,  ..., -2.8840,  0.8049, -0.2964],
         ...,
         [-0.1032,  5.1878, -0.8142,  ..., -1.9146,  1.1240, -0.2947],
         [-0.0874,  8.9394, -0.1826,  ..., -2.3875,  0.1260,  0.1413],
         [-0.1658, 13.3261, -0.3956,  ..., -1.6176,  1.7934, -1.7449]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.9360, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.9850, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
BP has been awarded to the Gulf spill .
iter = 4 reward = 3
final_logits =  tensor([[[ 0.0268,  3.6027,  0.4676,  ..., -1.4827,  5.1844, -1.2376],
         [-0.0607,  3.8141, -0.7590,  ..., -3.4211,  0.4541, -3.8545],
         [ 0.1287,  4.7351, -0.1638,  ..., -2.7031,  1.1817, -0.3351],
         ...,
         [-0.1082,  5.1587, -0.8214,  ..., -1.9468,  1.1735, -0.2937],
         [-0.0926,  8.8836, -0.1641,  ..., -2.4327,  0.0985,  0.2083],
         [-0.1665, 13.3302, -0.3867,  ..., -1.6314,  1.8290, -1.7559]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.7800, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.8985, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  3
3
{'input_ids': tensor([[[  787,   762, 14567,   110,   151, 15265,  7788,   110,   105,   124,
            109,  2143,  1034,  1027,  3070,  6375,   127,   239,   270,   263,
            112,   225, 16036,   562,   109, 15737,  2584, 51128,   116, 10928,
           1034,   116,  3070,  2414,   148,  7646,   339,   698, 26680,   233,
          37399,   110,   108, 35493,   111, 23363,   110,   107,   110,   105,
            600,   480,   140, 12144,   110,   108,   155,   265,  7646,   110,
            108, 16837,   178,   649,   110,   108,  1132,   109,  2414,   114,
           4081, 15115,   110,   107,   343,  1263, 51128,   116, 10928,  7719,
            180,   138,  4428,   169,  1162,  3070,   260,   559,   111,   118,
            149,   117,   146,   114,   710,  5135,   110,   108,   155,   114,
            729,   121,  4109,   156,   110,   107,   202,   729,  1034,   116,
            419,   112,   133,   114,   715,   110,   108,   181,   660,   113,
            523,   134,   109,   370,   113,   109,  8483, 16837,  4645, 16848,
           2584, 51128,   116, 10928,  7915, 25996,   110,   105,  2184,  6021,
            134,   214,   173,   145,   416,   136,   762, 14567,   256,   129,
           3150,   197, 23363,   110,   108,   155,   145,   114,   457,  3178,
            131,   144, 34742,   110,   108, 16837,   178,   649,   110,   107,
            398,   178, 41593,   164,   114,  1124,  2944,   113,  9606,  6545,
            115,   109,  2414,  1034,   116,  7270,   110,   108,  2584,   649,
            178,   117,  5238,   120,   109, 14567,   138,   129,   289, 13502,
            118,   223,   200,   115,   136,  3820,   121, 23623,  3070,   427,
            113, 38584,  1946, 11958,   144,   216,   110,   108,  7915, 29546,
           3070,   148,   174,  7162,   115,  7915,   262,   113,   109, 14567,
          10250,  1034,   116,  1750,   110,   108,  1946, 74523,   110,   108,
           5765,   122,   342,   111,  2779,   112,  7904,   110,   107,   110,
            105, 15265,   117,   169,   271,   110,   108,   347,   126,   178,
            358,  3178,   131,   144,   235,   742,   997,   110,   108, 16837,
            265,   649,   110,   107,   110,   105,   285,  1034,   116, 13735,
            110,   107,   285,  1034,   116,  7432,   134,   488,   110,   107,
            285,  1034,   116,   146,   109,   310, 29546,   420, 15538, 90155,
            110,   151,   110,   105,   168,   978,   172,   114, 10447,  1120,
            279,   264, 16837, 16036,   148, 20350,  5478,   113, 63981,  7881,
            333,   109,  7175,   113,  3064,   762, 14567,   110,   108,   155,
            186,   127,   274,   170,   127,  1192,   126,  2773,  7427,   118,
            109,   201,   126,   117,   557,   110,   108,  6260,   109,  6442,
           1034,   116,  6869,  3544,   115,  7915,   110,   107, 46095,   126,
            110,   108,   155, 16036,   117,   146,   114,  6749,  1172,   264,
            115,   109,  6805,  1120,   113,  7026, 63116, 58439,   110,   107,
            222,   109, 10601,  1034,   116,   629,   110,   108, 14515,   429,
            115,   114,  1120,  4511,   120,   117,   239,   163,   238,   112,
          16036,  1034,   116,   648,   115,   136,   297,   113,  7915,   110,
            108,   623,   391,  1725,  2051,   279,   115,  4555,   523,  1490,
          21955,  8802,   110,   107,   110,   105,   184,  1034,   216,   146,
            314,   785,   118,  1609,   126,   110,   108,   155,   264, 16036,
           1034,   116,   557,   234,   110,   108, 16837,   156,   649,   110,
            107,   353,  1034,   116,   956,  2158,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)
BP
iter = 0 reward = 1
final_logits =  tensor([[[-0.1286,  3.8904,  0.1265,  ..., -4.4729, -0.3402, -1.6047],
         [-0.2856, 12.2934, -0.8796,  ..., -1.0051, -1.6121, -2.2032]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0868, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1174, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 1 reward = 1
final_logits =  tensor([[[-0.1285,  3.8701,  0.1180,  ..., -4.5098, -0.3359, -1.6281],
         [-0.2862, 12.2972, -0.8844,  ..., -1.0340, -1.6171, -2.2079]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0762, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0933, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 2 reward = 1
final_logits =  tensor([[[-0.1284,  3.8544,  0.1111,  ..., -4.5580, -0.3241, -1.6454],
         [-0.2873, 12.3084, -0.8874,  ..., -1.0697, -1.6173, -2.2180]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0661, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0728, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 3 reward = 1
final_logits =  tensor([[[-0.1283,  3.8409,  0.1052,  ..., -4.6065, -0.3155, -1.6664],
         [-0.2892, 12.3234, -0.8909,  ..., -1.1072, -1.6131, -2.2324]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0566, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0559, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)

Everytime after generating next logits 38.0% (4186 out of 11019)
BP
iter = 4 reward = 1
final_logits =  tensor([[[-0.1286,  3.8246,  0.1010,  ..., -4.6446, -0.3129, -1.6844],
         [-0.2915, 12.3394, -0.8944,  ..., -1.1433, -1.6103, -2.2464]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.0481, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[  608,  1338,  2652,  2882,  2033,   134,   305, 91516, 17403,  4596,
            202,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   115,   109,  7175,   113,  3064,   110,   108, 16036,
            649,   110,   107,   983,  3244,  2777,   165,   141, 16036,   649,
            126,   140,  1470,   115,   297,   118,   109,  5135,   110,   108,
            155,   163,  1262,   181,  6511,   124,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,   608,
           1338,  2652,  2882,  2033,   134, 71437, 17403,  4596, 16036,   148,
           1788,   114,  1933,   545,   162,   939,   109,   301,  1034,   116,
            700,   113,   702,   964,   164,   112,   109,  7175,   113,  3064,
            762, 14567,   110,   107,  2973,   112,   109,   301,   110,   108,
            114,   110,   105,  5936,   113, 10114,  4064,   114,   344,   113,
            291,  1829, 16837,   140,   112,  6511,   118,   109, 81065, 18308,
            762, 14567,   110,   107,   983,  3244,  2777,   165,   141, 16036,
            243,   120,   126,   140,  1470,   115,   297,   118,   109,  5135,
            110,   108,   155,   126,   163, 17188,   176,   524,   375,   124,
            109,   210,   110,   107, 16036,  4121, 13353,   113,  2729,   121,
           8805,   113,  1165,  2242,   118,  3916,   204,   109, 14567,   110,
            108,   109,  3741,   115,   909,   787,   689,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4138 out of 11019)

Everytime after generating next logits 37.6% (4140 out of 11019)

Everytime after generating next logits 37.6% (4142 out of 11019)
The
iter = 0 reward = 0
final_logits =  tensor([[[-0.4297,  8.5875, -0.0198,  ..., -3.4820, -0.7601, -1.1395],
         [-0.3758, 12.7340, -0.4219,  ..., -2.2856, -0.0987, -1.1743]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6555, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3699, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
The
iter = 1 reward = 0
final_logits =  tensor([[[-0.4284,  8.5844, -0.0211,  ..., -3.4915, -0.7647, -1.1476],
         [-0.3759, 12.7364, -0.4225,  ..., -2.2882, -0.1036, -1.1718]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6764, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3908, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[-0.4286,  8.5812, -0.0251,  ..., -3.5023, -0.7810, -1.1472],
         [-0.3767, 12.7338, -0.4239,  ..., -2.2818, -0.0974, -1.1731]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6961, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4040, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[-0.4342,  8.5831, -0.0319,  ..., -3.4987, -0.8135, -1.1113],
         [-0.3809, 12.7157, -0.4264,  ..., -2.2702, -0.0770, -1.1762]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7049, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4009, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[-0.4353,  8.5808, -0.0334,  ..., -3.5006, -0.8391, -1.0980],
         [-0.3824, 12.6963, -0.4287,  ..., -2.2667, -0.0778, -1.1976]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.7172, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4011, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[  530,  1268,  2651,  2882,  2033,   134, 80621, 17403,  4596, 25688,
            115, 16036,  1963,   902,   124,  1789,  2409,   114,   787,  7501,
           5268, 79701,   109,   762,   301,  1034,   116,  4206,   111, 12856,
            130,   210,   130, 16036,   118,   109,  7175,   113,  3064,   762,
          14567,   110,   107,   139, 11335,   134,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,  1024,   111,  1358,   112,   109,  1368,
            521,  9134,   762,  8186,   110,   107,  4987,   109,  4469,   110,
            108, 16036,  2853,  3947,   607,  2527,   110, 43995,   118,   109,
            211,   166,   381,   913,   289,   232,   110,   107,  6442,   260,
          21089, 80736, 82734,  4278,  3886,   112,  5930, 37313,   110,   108,
            142,   762,  8962,   122, 85411,   116,  1714,   208, 59297, 20185,
            110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 37.8% (4168 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.0% (4188 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.2% (4212 out of 11019)

Everytime after generating next logits 38.4% (4226 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.5% (4240 out of 11019)

Everytime after generating next logits 38.6% (4256 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.8% (4272 out of 11019)

Everytime after generating next logits 38.9% (4290 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.3% (4328 out of 11019)

Everytime after generating next logits 39.5% (4348 out of 11019)

Everytime after generating next logits 39.5% (4348 out of 11019)

Everytime after generating next logits 39.5% (4348 out of 11019)

Everytime after generating next logits 39.5% (4348 out of 11019)

Everytime after generating next logits 39.9% (4392 out of 11019)

Everytime after generating next logits 40.3% (4436 out of 11019)

Everytime after generating next logits 40.3% (4436 out of 11019)

Everytime after generating next logits 40.3% (4436 out of 11019)

Everytime after generating next logits 40.3% (4436 out of 11019)

Everytime after generating next logits 40.3% (4436 out of 11019)

Everytime after generating next logits 40.7% (4484 out of 11019)

Everytime after generating next logits 41.1% (4532 out of 11019)

Everytime after generating next logits 41.1% (4532 out of 11019)

Everytime after generating next logits 41.1% (4532 out of 11019)

Everytime after generating next logits 41.1% (4532 out of 11019)

Everytime after generating next logits 41.6% (4584 out of 11019)

Everytime after generating next logits 42.1% (4636 out of 11019)

Everytime after generating next logits 42.1% (4636 out of 11019)

Everytime after generating next logits 42.1% (4636 out of 11019)

Everytime after generating next logits 42.1% (4636 out of 11019)

Everytime after generating next logits 42.6% (4692 out of 11019)

Everytime after generating next logits 43.1% (4748 out of 11019)

Everytime after generating next logits 43.1% (4748 out of 11019)

Everytime after generating next logits 43.1% (4748 out of 11019)

Everytime after generating next logits 43.1% (4748 out of 11019)

Everytime after generating next logits 43.1% (4748 out of 11019)

Everytime after generating next logits 43.6% (4808 out of 11019)

Everytime after generating next logits 44.2% (4868 out of 11019)

Everytime after generating next logits 44.2% (4868 out of 11019)

Everytime after generating next logits 44.2% (4868 out of 11019)

Everytime after generating next logits 44.2% (4868 out of 11019)

Everytime after generating next logits 44.8% (4932 out of 11019)

Everytime after generating next logits 45.3% (4996 out of 11019)

Everytime after generating next logits 45.3% (4996 out of 11019)

Everytime after generating next logits 45.3% (4996 out of 11019)

Everytime after generating next logits 45.3% (4996 out of 11019)

Everytime after generating next logits 45.3% (4996 out of 11019)

Everytime after generating next logits 46.0% (5064 out of 11019)

Everytime after generating next logits 46.6% (5132 out of 11019)

Everytime after generating next logits 46.6% (5132 out of 11019)

Everytime after generating next logits 46.6% (5132 out of 11019)

Everytime after generating next logits 46.6% (5132 out of 11019)

Everytime after generating next logits 47.2% (5204 out of 11019)

Everytime after generating next logits 47.9% (5276 out of 11019)

Everytime after generating next logits 47.9% (5276 out of 11019)

Everytime after generating next logits 47.9% (5276 out of 11019)

Everytime after generating next logits 47.9% (5276 out of 11019)

Everytime after generating next logits 47.9% (5276 out of 11019)

Everytime after generating next logits 48.6% (5352 out of 11019)

Everytime after generating next logits 49.3% (5428 out of 11019)

Everytime after generating next logits 49.3% (5428 out of 11019)

Everytime after generating next logits 49.3% (5428 out of 11019)

Everytime after generating next logits 49.3% (5428 out of 11019)

Everytime after generating next logits 50.0% (5508 out of 11019)

Everytime after generating next logits 50.7% (5588 out of 11019)

Everytime after generating next logits 50.7% (5588 out of 11019)

Everytime after generating next logits 50.7% (5588 out of 11019)

Everytime after generating next logits 50.7% (5588 out of 11019)

Everytime after generating next logits 50.7% (5588 out of 11019)

Everytime after generating next logits 51.5% (5672 out of 11019)

Everytime after generating next logits 52.2% (5756 out of 11019)

Everytime after generating next logits 52.2% (5756 out of 11019)

Everytime after generating next logits 52.2% (5756 out of 11019)

Everytime after generating next logits 52.2% (5756 out of 11019)

Everytime after generating next logits 53.0% (5844 out of 11019)

Everytime after generating next logits 53.8% (5932 out of 11019)

Everytime after generating next logits 53.8% (5932 out of 11019)

Everytime after generating next logits 53.8% (5932 out of 11019)

Everytime after generating next logits 53.8% (5932 out of 11019)

Everytime after generating next logits 53.8% (5932 out of 11019)

Everytime after generating next logits 54.7% (6024 out of 11019)

Everytime after generating next logits 55.5% (6116 out of 11019)

Everytime after generating next logits 55.5% (6116 out of 11019)

Everytime after generating next logits 55.5% (6116 out of 11019)

Everytime after generating next logits 55.5% (6116 out of 11019)

Everytime after generating next logits 56.4% (6212 out of 11019)

Everytime after generating next logits 57.2% (6308 out of 11019)

Everytime after generating next logits 57.2% (6308 out of 11019)

Everytime after generating next logits 57.2% (6308 out of 11019)

Everytime after generating next logits 57.2% (6308 out of 11019)

Everytime after generating next logits 58.2% (6408 out of 11019)

Everytime after generating next logits 59.1% (6508 out of 11019)

Everytime after generating next logits 59.1% (6508 out of 11019)

Everytime after generating next logits 59.1% (6508 out of 11019)

Everytime after generating next logits 59.1% (6508 out of 11019)

Everytime after generating next logits 59.1% (6508 out of 11019)

Everytime after generating next logits 60.0% (6612 out of 11019)

Everytime after generating next logits 60.9% (6716 out of 11019)

Everytime after generating next logits 60.9% (6716 out of 11019)

Everytime after generating next logits 60.9% (6716 out of 11019)

Everytime after generating next logits 60.9% (6716 out of 11019)

Everytime after generating next logits 61.9% (6824 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 63.9% (7044 out of 11019)

Everytime after generating next logits 64.9% (7156 out of 11019)

Everytime after generating next logits 64.9% (7156 out of 11019)

Everytime after generating next logits 64.9% (7156 out of 11019)

Everytime after generating next logits 64.9% (7156 out of 11019)

Everytime after generating next logits 66.0% (7272 out of 11019)

Everytime after generating next logits 67.0% (7388 out of 11019)

Everytime after generating next logits 67.0% (7388 out of 11019)

Everytime after generating next logits 67.0% (7388 out of 11019)

Everytime after generating next logits 67.0% (7388 out of 11019)

Everytime after generating next logits 67.0% (7388 out of 11019)

Everytime after generating next logits 68.1% (7508 out of 11019)

Everytime after generating next logits 69.2% (7628 out of 11019)

Everytime after generating next logits 69.2% (7628 out of 11019)

Everytime after generating next logits 69.2% (7628 out of 11019)

Everytime after generating next logits 69.2% (7628 out of 11019)

Everytime after generating next logits 70.4% (7752 out of 11019)

Everytime after generating next logits 71.5% (7876 out of 11019)

Everytime after generating next logits 71.5% (7876 out of 11019)

Everytime after generating next logits 71.5% (7876 out of 11019)

Everytime after generating next logits 71.5% (7876 out of 11019)

Everytime after generating next logits 71.5% (7876 out of 11019)

Everytime after generating next logits 72.6% (8004 out of 11019)

Everytime after generating next logits 73.8% (8132 out of 11019)

Everytime after generating next logits 73.8% (8132 out of 11019)

Everytime after generating next logits 73.8% (8132 out of 11019)

Everytime after generating next logits 73.8% (8132 out of 11019)

Everytime after generating next logits 75.0% (8264 out of 11019)

Everytime after generating next logits 76.2% (8396 out of 11019)

Everytime after generating next logits 76.2% (8396 out of 11019)

Everytime after generating next logits 76.2% (8396 out of 11019)

Everytime after generating next logits 76.2% (8396 out of 11019)

Everytime after generating next logits 76.2% (8396 out of 11019)

Everytime after generating next logits 77.4% (8532 out of 11019)

Everytime after generating next logits 78.7% (8668 out of 11019)

Everytime after generating next logits 78.7% (8668 out of 11019)

Everytime after generating next logits 78.7% (8668 out of 11019)

Everytime after generating next logits 78.7% (8668 out of 11019)

Everytime after generating next logits 79.9% (8808 out of 11019)

Everytime after generating next logits 81.2% (8948 out of 11019)

Everytime after generating next logits 81.2% (8948 out of 11019)

Everytime after generating next logits 81.2% (8948 out of 11019)

Everytime after generating next logits 81.2% (8948 out of 11019)

Everytime after generating next logits 82.5% (9092 out of 11019)

Everytime after generating next logits 83.8% (9236 out of 11019)

Everytime after generating next logits 83.8% (9236 out of 11019)

Everytime after generating next logits 83.8% (9236 out of 11019)

Everytime after generating next logits 83.8% (9236 out of 11019)

Everytime after generating next logits 83.8% (9236 out of 11019)

Everytime after generating next logits 85.2% (9384 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 86.5% (9536 out of 11019)

Everytime after generating next logits 86.5% (9536 out of 11019)

Everytime after generating next logits 87.9% (9688 out of 11019)

Everytime after generating next logits 89.3% (9840 out of 11019)

Everytime after generating next logits 89.3% (9840 out of 11019)

Everytime after generating next logits 89.3% (9840 out of 11019)

Everytime after generating next logits 89.3% (9840 out of 11019)

Everytime after generating next logits 89.3% (9840 out of 11019)

Everytime after generating next logits 90.7% (9996 out of 11019)

Everytime after generating next logits 92.1% (10152 out of 11019)

Everytime after generating next logits 92.1% (10152 out of 11019)

Everytime after generating next logits 92.1% (10152 out of 11019)

Everytime after generating next logits 92.1% (10152 out of 11019)

Everytime after generating next logits 93.6% (10312 out of 11019)

Everytime after generating next logits 95.0% (10472 out of 11019)

Everytime after generating next logits 95.0% (10472 out of 11019)

Everytime after generating next logits 95.0% (10472 out of 11019)

Everytime after generating next logits 95.0% (10472 out of 11019)

Everytime after generating next logits 95.0% (10472 out of 11019)

Everytime after generating next logits 96.5% (10636 out of 11019)

Everytime after generating next logits 98.0% (10800 out of 11019)

Everytime after generating next logits 98.0% (10800 out of 11019)

Everytime after generating next logits 98.0% (10800 out of 11019)

Everytime after generating next logits 98.0% (10800 out of 11019)

Everytime after generating next logits 99.5% (10968 out of 11019)

Everytime after generating next logits 40.7% (4484 out of 11019)

Everytime after generating next logits 40.7% (4488 out of 11019)

Everytime after generating next logits 40.7% (4488 out of 11019)

Everytime after generating next logits 40.7% (4488 out of 11019)

Everytime after generating next logits 40.7% (4488 out of 11019)

Everytime after generating next logits 42.3% (4660 out of 11019)

Everytime after generating next logits 43.9% (4832 out of 11019)

Everytime after generating next logits 43.9% (4832 out of 11019)

Everytime after generating next logits 43.9% (4832 out of 11019)

Everytime after generating next logits 43.9% (4832 out of 11019)

Everytime after generating next logits 45.4% (5008 out of 11019)

Everytime after generating next logits 47.0% (5184 out of 11019)

Everytime after generating next logits 47.0% (5184 out of 11019)

Everytime after generating next logits 47.0% (5184 out of 11019)

Everytime after generating next logits 47.0% (5184 out of 11019)

Everytime after generating next logits 47.0% (5184 out of 11019)

Everytime after generating next logits 48.7% (5364 out of 11019)

Everytime after generating next logits 50.3% (5544 out of 11019)

Everytime after generating next logits 50.3% (5544 out of 11019)

Everytime after generating next logits 50.3% (5544 out of 11019)

Everytime after generating next logits 50.3% (5544 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 53.7% (5912 out of 11019)

Everytime after generating next logits 53.7% (5912 out of 11019)

Everytime after generating next logits 53.7% (5912 out of 11019)

Everytime after generating next logits 53.7% (5912 out of 11019)

Everytime after generating next logits 55.4% (6100 out of 11019)

Everytime after generating next logits 57.1% (6288 out of 11019)

Everytime after generating next logits 57.1% (6288 out of 11019)

Everytime after generating next logits 57.1% (6288 out of 11019)

Everytime after generating next logits 57.1% (6288 out of 11019)

Everytime after generating next logits 57.1% (6288 out of 11019)

Everytime after generating next logits 58.8% (6480 out of 11019)

Everytime after generating next logits 60.5% (6672 out of 11019)

Everytime after generating next logits 60.5% (6672 out of 11019)

Everytime after generating next logits 60.5% (6672 out of 11019)

Everytime after generating next logits 60.5% (6672 out of 11019)

Everytime after generating next logits 62.3% (6868 out of 11019)

Everytime after generating next logits 64.1% (7064 out of 11019)

Everytime after generating next logits 64.1% (7064 out of 11019)

Everytime after generating next logits 64.1% (7064 out of 11019)

Everytime after generating next logits 64.1% (7064 out of 11019)

Everytime after generating next logits 64.1% (7064 out of 11019)

Everytime after generating next logits 65.9% (7264 out of 11019)

Everytime after generating next logits 67.7% (7464 out of 11019)

Everytime after generating next logits 67.7% (7464 out of 11019)

Everytime after generating next logits 67.7% (7464 out of 11019)

Everytime after generating next logits 67.7% (7464 out of 11019)

Everytime after generating next logits 69.6% (7668 out of 11019)

Everytime after generating next logits 71.4% (7872 out of 11019)

Everytime after generating next logits 71.4% (7872 out of 11019)

Everytime after generating next logits 71.4% (7872 out of 11019)

Everytime after generating next logits 71.4% (7872 out of 11019)

Everytime after generating next logits 71.4% (7872 out of 11019)

Everytime after generating next logits 73.3% (8080 out of 11019)

Everytime after generating next logits 75.2% (8288 out of 11019)

Everytime after generating next logits 75.2% (8288 out of 11019)

Everytime after generating next logits 75.2% (8288 out of 11019)

Everytime after generating next logits 75.2% (8288 out of 11019)

Everytime after generating next logits 77.1% (8500 out of 11019)

Everytime after generating next logits 79.1% (8712 out of 11019)

Everytime after generating next logits 79.1% (8712 out of 11019)

Everytime after generating next logits 79.1% (8712 out of 11019)

Everytime after generating next logits 79.1% (8712 out of 11019)

Everytime after generating next logits 79.1% (8712 out of 11019)

Everytime after generating next logits 81.0% (8928 out of 11019)

Everytime after generating next logits 83.0% (9144 out of 11019)

Everytime after generating next logits 83.0% (9144 out of 11019)

Everytime after generating next logits 83.0% (9144 out of 11019)

Everytime after generating next logits 83.0% (9144 out of 11019)

Everytime after generating next logits 85.0% (9364 out of 11019)

Everytime after generating next logits 87.0% (9584 out of 11019)

Everytime after generating next logits 87.0% (9584 out of 11019)

Everytime after generating next logits 87.0% (9584 out of 11019)

Everytime after generating next logits 87.0% (9584 out of 11019)

Everytime after generating next logits 87.0% (9584 out of 11019)

Everytime after generating next logits 89.0% (9808 out of 11019)

Everytime after generating next logits 91.0% (10032 out of 11019)

Everytime after generating next logits 91.0% (10032 out of 11019)

Everytime after generating next logits 91.0% (10032 out of 11019)

Everytime after generating next logits 91.0% (10032 out of 11019)

Everytime after generating next logits 93.1% (10260 out of 11019)

Everytime after generating next logits 95.2% (10488 out of 11019)

Everytime after generating next logits 95.2% (10488 out of 11019)

Everytime after generating next logits 95.2% (10488 out of 11019)

Everytime after generating next logits 95.2% (10488 out of 11019)

Everytime after generating next logits 97.3% (10720 out of 11019)

Everytime after generating next logits 99.4% (10952 out of 11019)

Everytime after generating next logits 99.4% (10952 out of 11019)

Everytime after generating next logits 99.4% (10952 out of 11019)

Everytime after generating next logits 99.4% (10952 out of 11019)

Everytime after generating next logits 99.4% (10952 out of 11019)

Everytime after generating next logits 42.6% (4690 out of 11019)

Everytime after generating next logits 44.7% (4926 out of 11019)

Everytime after generating next logits 44.7% (4926 out of 11019)

Everytime after generating next logits 44.7% (4926 out of 11019)

Everytime after generating next logits 44.7% (4926 out of 11019)

Everytime after generating next logits 46.9% (5166 out of 11019)

Everytime after generating next logits 49.1% (5406 out of 11019)

Everytime after generating next logits 49.1% (5406 out of 11019)

Everytime after generating next logits 49.1% (5406 out of 11019)

Everytime after generating next logits 49.1% (5406 out of 11019)

Everytime after generating next logits 49.1% (5406 out of 11019)

Everytime after generating next logits 51.3% (5650 out of 11019)

Everytime after generating next logits 53.5% (5894 out of 11019)

Everytime after generating next logits 53.5% (5894 out of 11019)

Everytime after generating next logits 53.5% (5894 out of 11019)

Everytime after generating next logits 53.5% (5894 out of 11019)

Everytime after generating next logits 55.7% (6142 out of 11019)

Everytime after generating next logits 58.0% (6390 out of 11019)

Everytime after generating next logits 58.0% (6390 out of 11019)

Everytime after generating next logits 58.0% (6390 out of 11019)

Everytime after generating next logits 58.0% (6390 out of 11019)

Everytime after generating next logits 58.0% (6390 out of 11019)

Everytime after generating next logits 60.3% (6642 out of 11019)

Everytime after generating next logits 62.6% (6894 out of 11019)

Everytime after generating next logits 62.6% (6894 out of 11019)

Everytime after generating next logits 62.6% (6894 out of 11019)

Everytime after generating next logits 62.6% (6894 out of 11019)

Everytime after generating next logits 64.9% (7150 out of 11019)

Everytime after generating next logits 67.2% (7406 out of 11019)

Everytime after generating next logits 67.2% (7406 out of 11019)

Everytime after generating next logits 67.2% (7406 out of 11019)

Everytime after generating next logits 67.2% (7406 out of 11019)

Everytime after generating next logits 67.2% (7406 out of 11019)

Everytime after generating next logits 69.6% (7666 out of 11019)

Everytime after generating next logits 71.9% (7926 out of 11019)

Everytime after generating next logits 71.9% (7926 out of 11019)

Everytime after generating next logits 71.9% (7926 out of 11019)

Everytime after generating next logits 71.9% (7926 out of 11019)

Everytime after generating next logits 74.3% (8190 out of 11019)

Everytime after generating next logits 76.7% (8454 out of 11019)

Everytime after generating next logits 76.7% (8454 out of 11019)

Everytime after generating next logits 76.7% (8454 out of 11019)

Everytime after generating next logits 76.7% (8454 out of 11019)

Everytime after generating next logits 76.7% (8454 out of 11019)

Everytime after generating next logits 79.2% (8722 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 84.1% (9262 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 86.5% (9534 out of 11019)

Everytime after generating next logits 89.0% (9810 out of 11019)

Everytime after generating next logits 91.5% (10086 out of 11019)

Everytime after generating next logits 91.5% (10086 out of 11019)

Everytime after generating next logits 91.5% (10086 out of 11019)

Everytime after generating next logits 91.5% (10086 out of 11019)

Everytime after generating next logits 91.5% (10086 out of 11019)

Everytime after generating next logits 94.1% (10366 out of 11019)

Everytime after generating next logits 96.6% (10646 out of 11019)

Everytime after generating next logits 96.6% (10646 out of 11019)

Everytime after generating next logits 96.6% (10646 out of 11019)

Everytime after generating next logits 96.6% (10646 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 43.5% (4790 out of 11019)

Everytime after generating next logits 43.5% (4790 out of 11019)

Everytime after generating next logits 43.5% (4790 out of 11019)

Everytime after generating next logits 43.5% (4790 out of 11019)

Everytime after generating next logits 43.5% (4790 out of 11019)

Everytime after generating next logits 46.1% (5078 out of 11019)

Everytime after generating next logits 48.7% (5366 out of 11019)

Everytime after generating next logits 48.7% (5366 out of 11019)

Everytime after generating next logits 48.7% (5366 out of 11019)

Everytime after generating next logits 48.7% (5366 out of 11019)

Everytime after generating next logits 51.3% (5658 out of 11019)

Everytime after generating next logits 54.0% (5950 out of 11019)

Everytime after generating next logits 54.0% (5950 out of 11019)

Everytime after generating next logits 54.0% (5950 out of 11019)

Everytime after generating next logits 54.0% (5950 out of 11019)

Everytime after generating next logits 54.0% (5950 out of 11019)

Everytime after generating next logits 56.7% (6246 out of 11019)

Everytime after generating next logits 59.4% (6542 out of 11019)

Everytime after generating next logits 59.4% (6542 out of 11019)

Everytime after generating next logits 59.4% (6542 out of 11019)

Everytime after generating next logits 59.4% (6542 out of 11019)

Everytime after generating next logits 62.1% (6842 out of 11019)

Everytime after generating next logits 64.8% (7142 out of 11019)

Everytime after generating next logits 64.8% (7142 out of 11019)

Everytime after generating next logits 64.8% (7142 out of 11019)

Everytime after generating next logits 64.8% (7142 out of 11019)

Everytime after generating next logits 64.8% (7142 out of 11019)

Everytime after generating next logits 67.6% (7446 out of 11019)

Everytime after generating next logits 70.3% (7750 out of 11019)

Everytime after generating next logits 70.3% (7750 out of 11019)

Everytime after generating next logits 70.3% (7750 out of 11019)

Everytime after generating next logits 70.3% (7750 out of 11019)

Everytime after generating next logits 73.1% (8058 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 75.9% (8366 out of 11019)

Everytime after generating next logits 78.8% (8678 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 81.6% (8990 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 87.3% (9622 out of 11019)

Everytime after generating next logits 87.3% (9622 out of 11019)

Everytime after generating next logits 87.3% (9622 out of 11019)

Everytime after generating next logits 87.3% (9622 out of 11019)

Everytime after generating next logits 90.2% (9942 out of 11019)

Everytime after generating next logits 93.1% (10262 out of 11019)

Everytime after generating next logits 93.1% (10262 out of 11019)

Everytime after generating next logits 93.1% (10262 out of 11019)

Everytime after generating next logits 93.1% (10262 out of 11019)

Everytime after generating next logits 93.1% (10262 out of 11019)

Everytime after generating next logits 96.1% (10586 out of 11019)

Everytime after generating next logits 99.0% (10910 out of 11019)

Everytime after generating next logits 99.0% (10910 out of 11019)

Everytime after generating next logits 99.0% (10910 out of 11019)

Everytime after generating next logits 99.0% (10910 out of 11019)

Everytime after generating next logits 44.2% (4874 out of 11019)

Everytime after generating next logits 47.2% (5202 out of 11019)

Everytime after generating next logits 47.2% (5202 out of 11019)

Everytime after generating next logits 47.2% (5202 out of 11019)

Everytime after generating next logits 47.2% (5202 out of 11019)

Everytime after generating next logits 47.2% (5202 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 53.2% (5866 out of 11019)

Everytime after generating next logits 53.2% (5866 out of 11019)

Everytime after generating next logits 53.2% (5866 out of 11019)

Everytime after generating next logits 53.2% (5866 out of 11019)

Everytime after generating next logits 56.3% (6202 out of 11019)

Everytime after generating next logits 59.3% (6538 out of 11019)

Everytime after generating next logits 59.3% (6538 out of 11019)

Everytime after generating next logits 59.3% (6538 out of 11019)

Everytime after generating next logits 59.3% (6538 out of 11019)

Everytime after generating next logits 59.3% (6538 out of 11019)

Everytime after generating next logits 62.4% (6878 out of 11019)

Everytime after generating next logits 65.5% (7218 out of 11019)

Everytime after generating next logits 65.5% (7218 out of 11019)

Everytime after generating next logits 65.5% (7218 out of 11019)

Everytime after generating next logits 65.5% (7218 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 71.7% (7906 out of 11019)

Everytime after generating next logits 71.7% (7906 out of 11019)

Everytime after generating next logits 71.7% (7906 out of 11019)

Everytime after generating next logits 71.7% (7906 out of 11019)

Everytime after generating next logits 71.7% (7906 out of 11019)

Everytime after generating next logits 74.9% (8254 out of 11019)

Everytime after generating next logits 78.1% (8602 out of 11019)

Everytime after generating next logits 78.1% (8602 out of 11019)

Everytime after generating next logits 78.1% (8602 out of 11019)

Everytime after generating next logits 78.1% (8602 out of 11019)

Everytime after generating next logits 81.3% (8954 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 84.5% (9306 out of 11019)

Everytime after generating next logits 87.7% (9662 out of 11019)

Everytime after generating next logits 90.9% (10018 out of 11019)

Everytime after generating next logits 90.9% (10018 out of 11019)

Everytime after generating next logits 90.9% (10018 out of 11019)

Everytime after generating next logits 90.9% (10018 out of 11019)

Everytime after generating next logits 94.2% (10378 out of 11019)

Everytime after generating next logits 97.4% (10738 out of 11019)

Everytime after generating next logits 97.4% (10738 out of 11019)

Everytime after generating next logits 97.4% (10738 out of 11019)

Everytime after generating next logits 97.4% (10738 out of 11019)

Everytime after generating next logits 44.9% (4946 out of 11019)

Everytime after generating next logits 48.2% (5310 out of 11019)

Everytime after generating next logits 48.2% (5310 out of 11019)

Everytime after generating next logits 48.2% (5310 out of 11019)

Everytime after generating next logits 48.2% (5310 out of 11019)

Everytime after generating next logits 48.2% (5310 out of 11019)

Everytime after generating next logits 51.5% (5678 out of 11019)

Everytime after generating next logits 54.9% (6046 out of 11019)

Everytime after generating next logits 54.9% (6046 out of 11019)

Everytime after generating next logits 54.9% (6046 out of 11019)

Everytime after generating next logits 54.9% (6046 out of 11019)

Everytime after generating next logits 58.2% (6418 out of 11019)

Everytime after generating next logits 61.6% (6790 out of 11019)

Everytime after generating next logits 61.6% (6790 out of 11019)

Everytime after generating next logits 61.6% (6790 out of 11019)

Everytime after generating next logits 61.6% (6790 out of 11019)

Everytime after generating next logits 61.6% (6790 out of 11019)

Everytime after generating next logits 65.0% (7166 out of 11019)

Everytime after generating next logits 68.4% (7542 out of 11019)

Everytime after generating next logits 68.4% (7542 out of 11019)

Everytime after generating next logits 68.4% (7542 out of 11019)
SharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesShares
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0154,  3.3377,  0.1545,  ..., -3.6791,  1.7638, -1.4491],
         [ 0.1341,  2.6101,  0.1753,  ..., -2.4780, -0.8378,  0.5011],
         [ 0.1338,  2.7838,  0.1394,  ..., -2.5699, -0.7317,  0.2441],
         ...,
         [ 0.0579,  6.5054, -0.1443,  ..., -0.9916, -1.0582, -0.7183],
         [ 0.0581,  6.5010, -0.1458,  ..., -1.0045, -1.0513, -0.7249],
         [ 0.0579,  6.5146, -0.1472,  ..., -1.0150, -1.0487, -0.7342]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2335, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2220, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 50.2% (5528 out of 11019)

Everytime after generating next logits 51.0% (5624 out of 11019)

Everytime after generating next logits 51.0% (5624 out of 11019)

Everytime after generating next logits 51.0% (5624 out of 11019)

Everytime after generating next logits 51.0% (5624 out of 11019)

Everytime after generating next logits 51.0% (5624 out of 11019)

Everytime after generating next logits 51.9% (5722 out of 11019)

Everytime after generating next logits 51.9% (5722 out of 11019)

Everytime after generating next logits 51.9% (5722 out of 11019)

Everytime after generating next logits 51.9% (5722 out of 11019)

Everytime after generating next logits 51.9% (5722 out of 11019)

Everytime after generating next logits 52.8% (5822 out of 11019)

Everytime after generating next logits 52.8% (5822 out of 11019)

Everytime after generating next logits 52.8% (5822 out of 11019)

Everytime after generating next logits 52.8% (5822 out of 11019)

Everytime after generating next logits 52.8% (5822 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 53.8% (5924 out of 11019)

Everytime after generating next logits 54.7% (6028 out of 11019)

Everytime after generating next logits 54.7% (6028 out of 11019)

Everytime after generating next logits 54.7% (6028 out of 11019)

Everytime after generating next logits 54.7% (6028 out of 11019)

Everytime after generating next logits 54.7% (6028 out of 11019)

Everytime after generating next logits 55.7% (6134 out of 11019)

Everytime after generating next logits 55.7% (6134 out of 11019)

Everytime after generating next logits 55.7% (6134 out of 11019)

Everytime after generating next logits 55.7% (6134 out of 11019)

Everytime after generating next logits 55.7% (6134 out of 11019)

Everytime after generating next logits 56.6% (6242 out of 11019)

Everytime after generating next logits 56.6% (6242 out of 11019)

Everytime after generating next logits 56.6% (6242 out of 11019)

Everytime after generating next logits 56.6% (6242 out of 11019)

Everytime after generating next logits 56.6% (6242 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 57.6% (6352 out of 11019)

Everytime after generating next logits 58.7% (6464 out of 11019)

Everytime after generating next logits 58.7% (6464 out of 11019)

Everytime after generating next logits 58.7% (6464 out of 11019)

Everytime after generating next logits 58.7% (6464 out of 11019)

Everytime after generating next logits 58.7% (6464 out of 11019)

Everytime after generating next logits 59.7% (6578 out of 11019)

Everytime after generating next logits 59.7% (6578 out of 11019)

Everytime after generating next logits 59.7% (6578 out of 11019)

Everytime after generating next logits 59.7% (6578 out of 11019)

Everytime after generating next logits 59.7% (6578 out of 11019)

Everytime after generating next logits 60.7% (6694 out of 11019)

Everytime after generating next logits 60.7% (6694 out of 11019)

Everytime after generating next logits 60.7% (6694 out of 11019)

Everytime after generating next logits 60.7% (6694 out of 11019)

Everytime after generating next logits 60.7% (6694 out of 11019)

Everytime after generating next logits 61.8% (6812 out of 11019)

Everytime after generating next logits 61.8% (6812 out of 11019)

Everytime after generating next logits 61.8% (6812 out of 11019)

Everytime after generating next logits 61.8% (6812 out of 11019)

Everytime after generating next logits 61.8% (6812 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 62.9% (6932 out of 11019)

Everytime after generating next logits 64.0% (7054 out of 11019)

Everytime after generating next logits 64.0% (7054 out of 11019)

Everytime after generating next logits 64.0% (7054 out of 11019)

Everytime after generating next logits 64.0% (7054 out of 11019)

Everytime after generating next logits 64.0% (7054 out of 11019)

Everytime after generating next logits 65.1% (7178 out of 11019)

Everytime after generating next logits 65.1% (7178 out of 11019)

Everytime after generating next logits 65.1% (7178 out of 11019)

Everytime after generating next logits 65.1% (7178 out of 11019)

Everytime after generating next logits 65.1% (7178 out of 11019)

Everytime after generating next logits 66.3% (7304 out of 11019)

Everytime after generating next logits 66.3% (7304 out of 11019)

Everytime after generating next logits 66.3% (7304 out of 11019)

Everytime after generating next logits 66.3% (7304 out of 11019)

Everytime after generating next logits 66.3% (7304 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 67.4% (7432 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 68.6% (7562 out of 11019)

Everytime after generating next logits 69.8% (7694 out of 11019)

Everytime after generating next logits 69.8% (7694 out of 11019)

Everytime after generating next logits 69.8% (7694 out of 11019)

Everytime after generating next logits 69.8% (7694 out of 11019)

Everytime after generating next logits 69.8% (7694 out of 11019)

Everytime after generating next logits 71.0% (7828 out of 11019)

Everytime after generating next logits 71.0% (7828 out of 11019)

Everytime after generating next logits 71.0% (7828 out of 11019)

Everytime after generating next logits 71.0% (7828 out of 11019)

Everytime after generating next logits 71.0% (7828 out of 11019)

Everytime after generating next logits 72.3% (7964 out of 11019)

Everytime after generating next logits 72.3% (7964 out of 11019)

Everytime after generating next logits 72.3% (7964 out of 11019)

Everytime after generating next logits 72.3% (7964 out of 11019)

Everytime after generating next logits 72.3% (7964 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 73.5% (8102 out of 11019)

Everytime after generating next logits 74.8% (8242 out of 11019)

Everytime after generating next logits 74.8% (8242 out of 11019)

Everytime after generating next logits 74.8% (8242 out of 11019)

Everytime after generating next logits 74.8% (8242 out of 11019)

Everytime after generating next logits 74.8% (8242 out of 11019)

Everytime after generating next logits 76.1% (8384 out of 11019)

Everytime after generating next logits 76.1% (8384 out of 11019)

Everytime after generating next logits 76.1% (8384 out of 11019)

Everytime after generating next logits 76.1% (8384 out of 11019)

Everytime after generating next logits 76.1% (8384 out of 11019)

Everytime after generating next logits 77.4% (8528 out of 11019)

Everytime after generating next logits 77.4% (8528 out of 11019)

Everytime after generating next logits 77.4% (8528 out of 11019)

Everytime after generating next logits 77.4% (8528 out of 11019)

Everytime after generating next logits 77.4% (8528 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 78.7% (8674 out of 11019)

Everytime after generating next logits 80.1% (8822 out of 11019)

Everytime after generating next logits 80.1% (8822 out of 11019)

Everytime after generating next logits 80.1% (8822 out of 11019)

Everytime after generating next logits 80.1% (8822 out of 11019)

Everytime after generating next logits 80.1% (8822 out of 11019)

Everytime after generating next logits 81.4% (8972 out of 11019)

Everytime after generating next logits 81.4% (8972 out of 11019)

Everytime after generating next logits 81.4% (8972 out of 11019)

Everytime after generating next logits 81.4% (8972 out of 11019)

Everytime after generating next logits 81.4% (8972 out of 11019)

Everytime after generating next logits 82.8% (9124 out of 11019)

Everytime after generating next logits 82.8% (9124 out of 11019)

Everytime after generating next logits 82.8% (9124 out of 11019)

Everytime after generating next logits 82.8% (9124 out of 11019)

Everytime after generating next logits 82.8% (9124 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 84.2% (9278 out of 11019)

Everytime after generating next logits 85.6% (9434 out of 11019)

Everytime after generating next logits 85.6% (9434 out of 11019)

Everytime after generating next logits 85.6% (9434 out of 11019)

Everytime after generating next logits 85.6% (9434 out of 11019)

Everytime after generating next logits 85.6% (9434 out of 11019)

Everytime after generating next logits 87.0% (9592 out of 11019)

Everytime after generating next logits 87.0% (9592 out of 11019)

Everytime after generating next logits 87.0% (9592 out of 11019)

Everytime after generating next logits 87.0% (9592 out of 11019)

Everytime after generating next logits 87.0% (9592 out of 11019)

Everytime after generating next logits 88.5% (9752 out of 11019)

Everytime after generating next logits 88.5% (9752 out of 11019)

Everytime after generating next logits 88.5% (9752 out of 11019)

Everytime after generating next logits 88.5% (9752 out of 11019)

Everytime after generating next logits 88.5% (9752 out of 11019)

Everytime after generating next logits 90.0% (9914 out of 11019)

Everytime after generating next logits 90.0% (9914 out of 11019)

Everytime after generating next logits 90.0% (9914 out of 11019)

Everytime after generating next logits 90.0% (9914 out of 11019)

Everytime after generating next logits 90.0% (9914 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 91.5% (10078 out of 11019)

Everytime after generating next logits 93.0% (10244 out of 11019)

Everytime after generating next logits 93.0% (10244 out of 11019)

Everytime after generating next logits 93.0% (10244 out of 11019)

Everytime after generating next logits 93.0% (10244 out of 11019)

Everytime after generating next logits 93.0% (10244 out of 11019)

Everytime after generating next logits 94.5% (10412 out of 11019)

Everytime after generating next logits 94.5% (10412 out of 11019)

Everytime after generating next logits 94.5% (10412 out of 11019)

Everytime after generating next logits 94.5% (10412 out of 11019)

Everytime after generating next logits 94.5% (10412 out of 11019)

Everytime after generating next logits 96.0% (10582 out of 11019)

Everytime after generating next logits 96.0% (10582 out of 11019)

Everytime after generating next logits 96.0% (10582 out of 11019)

Everytime after generating next logits 96.0% (10582 out of 11019)

Everytime after generating next logits 96.0% (10582 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 97.6% (10754 out of 11019)

Everytime after generating next logits 99.2% (10928 out of 11019)

Everytime after generating next logits 99.2% (10928 out of 11019)

Everytime after generating next logits 99.2% (10928 out of 11019)

Everytime after generating next logits 99.2% (10928 out of 11019)

Everytime after generating next logits 99.2% (10928 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)
SharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesShares
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0141,  3.3694,  0.1507,  ..., -3.6794,  1.7867, -1.4560],
         [ 0.1392,  2.6156,  0.1744,  ..., -2.4486, -0.7771,  0.5412],
         [ 0.1338,  2.8352,  0.1338,  ..., -2.5047, -0.7122,  0.2475],
         ...,
         [ 0.0551,  6.4899, -0.1372,  ..., -1.0270, -1.0451, -0.6886],
         [ 0.0551,  6.4859, -0.1389,  ..., -1.0393, -1.0389, -0.6956],
         [ 0.0550,  6.4993, -0.1403,  ..., -1.0512, -1.0360, -0.7049]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2794, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.2029, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)
SharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesShares
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0175,  3.3370,  0.1542,  ..., -3.6962,  1.8067, -1.4574],
         [ 0.1413,  2.5127,  0.1629,  ..., -2.4806, -0.7586,  0.5284],
         [ 0.1326,  2.7719,  0.1187,  ..., -2.5206, -0.7052,  0.2369],
         ...,
         [ 0.0544,  6.2744, -0.1389,  ..., -1.0958, -0.9987, -0.6235],
         [ 0.0545,  6.2717, -0.1403,  ..., -1.1092, -0.9918, -0.6297],
         [ 0.0544,  6.2869, -0.1412,  ..., -1.1210, -0.9891, -0.6386]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3574, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1847, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 50.2% (5534 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 51.1% (5630 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.0% (5728 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 52.9% (5828 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 53.8% (5930 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 54.8% (6034 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 55.7% (6140 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 56.7% (6248 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 57.7% (6358 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 58.7% (6470 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 59.8% (6584 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 60.8% (6700 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 61.9% (6818 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 63.0% (6938 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 64.1% (7060 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 65.2% (7184 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 66.3% (7310 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 67.5% (7438 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 68.7% (7568 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 69.9% (7700 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 71.1% (7834 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 72.3% (7970 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 73.6% (8108 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 74.9% (8248 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 76.1% (8390 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 77.4% (8534 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 78.8% (8680 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 80.1% (8828 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 81.5% (8978 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 82.9% (9130 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 84.3% (9284 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 85.7% (9440 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 87.1% (9598 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 88.6% (9758 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 90.0% (9920 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 91.5% (10084 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 93.0% (10250 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 94.5% (10418 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 96.1% (10588 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 97.6% (10760 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 99.2% (10934 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)
SharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesShares
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0217,  3.2788,  0.1589,  ..., -3.6883,  1.7918, -1.4335],
         [ 0.1431,  2.3971,  0.1446,  ..., -2.5350, -0.7551,  0.4726],
         [ 0.1327,  2.6769,  0.0987,  ..., -2.5664, -0.7070,  0.2091],
         ...,
         [ 0.0583,  5.9633, -0.1339,  ..., -1.1495, -0.9399, -0.5174],
         [ 0.0585,  5.9603, -0.1352,  ..., -1.1630, -0.9329, -0.5241],
         [ 0.0584,  5.9719, -0.1363,  ..., -1.1765, -0.9292, -0.5315]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4905, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.1424, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.1% (5626 out of 11019)

Everytime after generating next logits 51.9% (5724 out of 11019)

Everytime after generating next logits 51.9% (5724 out of 11019)

Everytime after generating next logits 51.9% (5724 out of 11019)

Everytime after generating next logits 51.9% (5724 out of 11019)

Everytime after generating next logits 51.9% (5724 out of 11019)

Everytime after generating next logits 52.9% (5824 out of 11019)

Everytime after generating next logits 52.9% (5824 out of 11019)

Everytime after generating next logits 52.9% (5824 out of 11019)

Everytime after generating next logits 52.9% (5824 out of 11019)

Everytime after generating next logits 52.9% (5824 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 53.8% (5926 out of 11019)

Everytime after generating next logits 54.7% (6030 out of 11019)

Everytime after generating next logits 54.7% (6030 out of 11019)

Everytime after generating next logits 54.7% (6030 out of 11019)

Everytime after generating next logits 54.7% (6030 out of 11019)

Everytime after generating next logits 54.7% (6030 out of 11019)

Everytime after generating next logits 55.7% (6136 out of 11019)

Everytime after generating next logits 55.7% (6136 out of 11019)

Everytime after generating next logits 55.7% (6136 out of 11019)

Everytime after generating next logits 55.7% (6136 out of 11019)

Everytime after generating next logits 55.7% (6136 out of 11019)

Everytime after generating next logits 56.7% (6244 out of 11019)

Everytime after generating next logits 56.7% (6244 out of 11019)

Everytime after generating next logits 56.7% (6244 out of 11019)

Everytime after generating next logits 56.7% (6244 out of 11019)

Everytime after generating next logits 56.7% (6244 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 57.7% (6354 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 58.7% (6466 out of 11019)

Everytime after generating next logits 59.7% (6580 out of 11019)

Everytime after generating next logits 59.7% (6580 out of 11019)

Everytime after generating next logits 59.7% (6580 out of 11019)

Everytime after generating next logits 59.7% (6580 out of 11019)

Everytime after generating next logits 59.7% (6580 out of 11019)

Everytime after generating next logits 60.8% (6696 out of 11019)

Everytime after generating next logits 60.8% (6696 out of 11019)

Everytime after generating next logits 60.8% (6696 out of 11019)

Everytime after generating next logits 60.8% (6696 out of 11019)

Everytime after generating next logits 60.8% (6696 out of 11019)

Everytime after generating next logits 61.8% (6814 out of 11019)

Everytime after generating next logits 61.8% (6814 out of 11019)

Everytime after generating next logits 61.8% (6814 out of 11019)

Everytime after generating next logits 61.8% (6814 out of 11019)

Everytime after generating next logits 61.8% (6814 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 62.9% (6934 out of 11019)

Everytime after generating next logits 64.0% (7056 out of 11019)

Everytime after generating next logits 64.0% (7056 out of 11019)

Everytime after generating next logits 64.0% (7056 out of 11019)

Everytime after generating next logits 64.0% (7056 out of 11019)

Everytime after generating next logits 64.0% (7056 out of 11019)

Everytime after generating next logits 65.2% (7180 out of 11019)

Everytime after generating next logits 65.2% (7180 out of 11019)

Everytime after generating next logits 65.2% (7180 out of 11019)

Everytime after generating next logits 65.2% (7180 out of 11019)

Everytime after generating next logits 65.2% (7180 out of 11019)

Everytime after generating next logits 66.3% (7306 out of 11019)

Everytime after generating next logits 66.3% (7306 out of 11019)

Everytime after generating next logits 66.3% (7306 out of 11019)

Everytime after generating next logits 66.3% (7306 out of 11019)

Everytime after generating next logits 66.3% (7306 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 67.5% (7434 out of 11019)

Everytime after generating next logits 68.6% (7564 out of 11019)

Everytime after generating next logits 68.6% (7564 out of 11019)

Everytime after generating next logits 68.6% (7564 out of 11019)

Everytime after generating next logits 68.6% (7564 out of 11019)

Everytime after generating next logits 68.6% (7564 out of 11019)

Everytime after generating next logits 69.8% (7696 out of 11019)

Everytime after generating next logits 69.8% (7696 out of 11019)

Everytime after generating next logits 69.8% (7696 out of 11019)

Everytime after generating next logits 69.8% (7696 out of 11019)

Everytime after generating next logits 69.8% (7696 out of 11019)

Everytime after generating next logits 71.1% (7830 out of 11019)

Everytime after generating next logits 71.1% (7830 out of 11019)

Everytime after generating next logits 71.1% (7830 out of 11019)

Everytime after generating next logits 71.1% (7830 out of 11019)

Everytime after generating next logits 71.1% (7830 out of 11019)

Everytime after generating next logits 72.3% (7966 out of 11019)

Everytime after generating next logits 72.3% (7966 out of 11019)

Everytime after generating next logits 72.3% (7966 out of 11019)

Everytime after generating next logits 72.3% (7966 out of 11019)

Everytime after generating next logits 72.3% (7966 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 73.5% (8104 out of 11019)

Everytime after generating next logits 74.8% (8244 out of 11019)

Everytime after generating next logits 74.8% (8244 out of 11019)

Everytime after generating next logits 74.8% (8244 out of 11019)

Everytime after generating next logits 74.8% (8244 out of 11019)

Everytime after generating next logits 74.8% (8244 out of 11019)

Everytime after generating next logits 76.1% (8386 out of 11019)

Everytime after generating next logits 76.1% (8386 out of 11019)

Everytime after generating next logits 76.1% (8386 out of 11019)

Everytime after generating next logits 76.1% (8386 out of 11019)

Everytime after generating next logits 76.1% (8386 out of 11019)

Everytime after generating next logits 77.4% (8530 out of 11019)

Everytime after generating next logits 77.4% (8530 out of 11019)

Everytime after generating next logits 77.4% (8530 out of 11019)

Everytime after generating next logits 77.4% (8530 out of 11019)

Everytime after generating next logits 77.4% (8530 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 78.7% (8676 out of 11019)

Everytime after generating next logits 80.1% (8824 out of 11019)

Everytime after generating next logits 80.1% (8824 out of 11019)

Everytime after generating next logits 80.1% (8824 out of 11019)

Everytime after generating next logits 80.1% (8824 out of 11019)

Everytime after generating next logits 80.1% (8824 out of 11019)

Everytime after generating next logits 81.4% (8974 out of 11019)

Everytime after generating next logits 81.4% (8974 out of 11019)

Everytime after generating next logits 81.4% (8974 out of 11019)

Everytime after generating next logits 81.4% (8974 out of 11019)

Everytime after generating next logits 81.4% (8974 out of 11019)

Everytime after generating next logits 82.8% (9126 out of 11019)

Everytime after generating next logits 82.8% (9126 out of 11019)

Everytime after generating next logits 82.8% (9126 out of 11019)

Everytime after generating next logits 82.8% (9126 out of 11019)

Everytime after generating next logits 82.8% (9126 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 84.2% (9280 out of 11019)

Everytime after generating next logits 85.6% (9436 out of 11019)

Everytime after generating next logits 85.6% (9436 out of 11019)

Everytime after generating next logits 85.6% (9436 out of 11019)

Everytime after generating next logits 85.6% (9436 out of 11019)

Everytime after generating next logits 85.6% (9436 out of 11019)

Everytime after generating next logits 87.1% (9594 out of 11019)

Everytime after generating next logits 87.1% (9594 out of 11019)

Everytime after generating next logits 87.1% (9594 out of 11019)

Everytime after generating next logits 87.1% (9594 out of 11019)

Everytime after generating next logits 87.1% (9594 out of 11019)

Everytime after generating next logits 88.5% (9754 out of 11019)

Everytime after generating next logits 88.5% (9754 out of 11019)

Everytime after generating next logits 88.5% (9754 out of 11019)

Everytime after generating next logits 88.5% (9754 out of 11019)

Everytime after generating next logits 88.5% (9754 out of 11019)

Everytime after generating next logits 90.0% (9916 out of 11019)

Everytime after generating next logits 90.0% (9916 out of 11019)

Everytime after generating next logits 90.0% (9916 out of 11019)

Everytime after generating next logits 90.0% (9916 out of 11019)

Everytime after generating next logits 90.0% (9916 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 91.5% (10080 out of 11019)

Everytime after generating next logits 93.0% (10246 out of 11019)

Everytime after generating next logits 93.0% (10246 out of 11019)

Everytime after generating next logits 93.0% (10246 out of 11019)

Everytime after generating next logits 93.0% (10246 out of 11019)

Everytime after generating next logits 93.0% (10246 out of 11019)

Everytime after generating next logits 94.5% (10414 out of 11019)

Everytime after generating next logits 94.5% (10414 out of 11019)

Everytime after generating next logits 94.5% (10414 out of 11019)

Everytime after generating next logits 94.5% (10414 out of 11019)

Everytime after generating next logits 94.5% (10414 out of 11019)

Everytime after generating next logits 96.1% (10584 out of 11019)

Everytime after generating next logits 96.1% (10584 out of 11019)

Everytime after generating next logits 96.1% (10584 out of 11019)

Everytime after generating next logits 96.1% (10584 out of 11019)

Everytime after generating next logits 96.1% (10584 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 97.6% (10756 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 99.2% (10930 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 44.3% (4882 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 45.9% (5060 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 47.6% (5240 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 49.2% (5422 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 50.9% (5606 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 52.6% (5792 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)

Everytime after generating next logits 54.3% (5980 out of 11019)
SharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesSharesShares
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0268,  3.1938,  0.1645,  ..., -3.6554,  1.7572, -1.4008],
         [ 0.1444,  2.2516,  0.1179,  ..., -2.6015, -0.7378,  0.4267],
         [ 0.1320,  2.5507,  0.0710,  ..., -2.6120, -0.7152,  0.1785],
         ...,
         [ 0.0625,  5.6220, -0.1310,  ..., -1.1694, -0.8866, -0.4137],
         [ 0.0625,  5.6194, -0.1325,  ..., -1.1819, -0.8794, -0.4197],
         [ 0.0623,  5.6299, -0.1341,  ..., -1.1944, -0.8762, -0.4246]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6927, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.0907, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3788,   110,   108,   258,   111,  1183,   109,  4193,   120,  5887,
            119,  3788, 22017,  3249,  2309,   114,  4340,   132,  2162,   110,
            108,   132,   989,  6502,   115,   150,   545,  1771,  6180,   114,
           4340,   493,   126,   586,   112,   258,   165,   241,   111,   173,
            157,   133,  6502,   110,   107, 14845,   127,  1661,   115,   156,
            295,   110,   108,  2063,   119,  1235,   111,   400,   489,   110,
            107, 21556,   116,  4170, 16036,   762, 14567,  1736,   651,  1265,
           1185,  2652,   110,   108,  3013,   111,  9792,  5297,  5299,  2346,
           3601,  2567,  7499,   114,  1736,   266,  1678,   115,   109, 11319,
            124,   109, 16036,   762, 14567,   110,   107,  2346,  3601,  2567,
            898,  6949,   120,   142,  8635,   933,   113,  1647,   196,   506,
            174,  9889,   110,   108,   155,   701, 51098,   192,   129,   656,
            130,  6031,  1219,   115,  4190,  6500,  3381,   113, 43278,   110,
            107,   139,   657,   148, 18097,   112,   110,   105,   543,   109,
           2919,   113,   219,  6209,   702, 16837,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)

Everytime after generating next logits 50.2% (5530 out of 11019)
Peer Peer
iter = 0 reward = 0
final_logits =  tensor([[[ 0.0870,  5.6592,  0.3759,  ..., -0.8399, -1.0756, -2.2213],
         [ 0.0518, 11.6842, -0.3409,  ..., -0.4639, -2.4174, -2.0725],
         [ 0.0318, 11.6843, -0.3831,  ..., -0.0967, -2.0823, -1.6883]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8812, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9610, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 39.3% (4334 out of 11019)

Everytime after generating next logits 39.3% (4334 out of 11019)

Everytime after generating next logits 39.3% (4334 out of 11019)

Everytime after generating next logits 39.3% (4334 out of 11019)
Peer Peer
iter = 1 reward = 0
final_logits =  tensor([[[ 0.0928,  5.6147,  0.3734,  ..., -0.8369, -1.0711, -2.2092],
         [ 0.0528, 11.6737, -0.3420,  ..., -0.4566, -2.4337, -2.0410],
         [ 0.0324, 11.6780, -0.3848,  ..., -0.0898, -2.1033, -1.6553]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.8779, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.9050, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 39.3% (4332 out of 11019)

Everytime after generating next logits 39.3% (4332 out of 11019)

Everytime after generating next logits 39.3% (4332 out of 11019)
Peer
iter = 2 reward = 0
final_logits =  tensor([[[ 0.1032,  5.5156,  0.3693,  ..., -0.8169, -1.0403, -2.1813],
         [ 0.0553, 11.6669, -0.3421,  ..., -0.4328, -2.4507, -1.9837]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9198, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.8494, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Peer
iter = 3 reward = 0
final_logits =  tensor([[[ 0.1117,  5.4153,  0.3728,  ..., -0.7526, -0.9618, -2.1000],
         [ 0.0610, 11.6796, -0.3332,  ..., -0.3751, -2.4209, -1.8937]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9135, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7801, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
Peer
iter = 4 reward = 0
final_logits =  tensor([[[ 0.1218,  5.2732,  0.3838,  ..., -0.5791, -0.8261, -2.0093],
         [ 0.0708, 11.6936, -0.3263,  ..., -0.2823, -2.3137, -1.7988]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9180, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.7089, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1428,  1307,  2652,  2882,  2033,   134, 84838,   726, 17403,  4596,
          16036,   148,  1939,   114,   177, 14464,  3889,   124,   109, 14154,
           7175,   113,  3064,   762,   210,   110,   108,   301,  2662,   416,
            110,   107,   168,   117,  8549,   109,   177,  3889,   138,   923,
            109,  8186,   111,  3155,   109,   762,   269,   154,   113,   126,
            137,  6218,   190,   109,  1917,   155,   126,   256,   129,   372,
            228,   390,   269, 16036,   235,   682,   109,   807,  2353,   117,
           1147,   110,   107,   139, 11335,   113,   109, 81065, 18308, 13773,
            115,   960,  3040,  1073,   200,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)
13 killed killed in the 2010 cap explosion  .
iter = 0 reward = 1
final_logits =  tensor([[[-0.2111,  6.6940,  0.1711,  ..., -2.5258,  0.9405, -0.5299],
         [-0.2368,  5.6954, -0.3359,  ..., -1.0355, -0.3460, -1.2811],
         [-0.2122,  4.9527, -0.5270,  ..., -1.5519, -0.6446, -1.6188],
         ...,
         [-0.1655,  8.8507,  0.1333,  ..., -1.5095,  0.5565,  1.7757],
         [-0.2207,  9.5025,  0.0647,  ..., -2.2217,  0.2760,  1.5359],
         [-0.2166, 13.3905, -0.0642,  ..., -1.6949, -0.8328,  0.6117]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2835, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3206, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
13 killed killed in the 2010 cap explosion  .
iter = 1 reward = 1
final_logits =  tensor([[[-0.2062,  6.6862,  0.1749,  ..., -2.5231,  0.9137, -0.5350],
         [-0.2337,  5.6922, -0.3306,  ..., -1.0425, -0.3545, -1.2781],
         [-0.2091,  4.9450, -0.5228,  ..., -1.5500, -0.6522, -1.6237],
         ...,
         [-0.1622,  8.8459,  0.1370,  ..., -1.4989,  0.5460,  1.7725],
         [-0.2171,  9.4997,  0.0678,  ..., -2.2072,  0.2638,  1.5328],
         [-0.2138, 13.3860, -0.0638,  ..., -1.6735, -0.8531,  0.6019]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.2371, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3061, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
13 killed killed in the 2010 cap explosion  .
iter = 2 reward = 1
final_logits =  tensor([[[-0.2001,  6.6639,  0.1782,  ..., -2.5248,  0.8593, -0.5464],
         [-0.2294,  5.6680, -0.3245,  ..., -1.0628, -0.3750, -1.2800],
         [-0.2052,  4.9176, -0.5177,  ..., -1.5522, -0.6737, -1.6374],
         ...,
         [-0.1585,  8.8190,  0.1399,  ..., -1.4917,  0.5210,  1.7677],
         [-0.2130,  9.4674,  0.0711,  ..., -2.1937,  0.2375,  1.5240],
         [-0.2113, 13.3657, -0.0657,  ..., -1.6450, -0.8839,  0.5888]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1995, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2948, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
13 killed killed in the 2010 cap explosion  .
iter = 3 reward = 1
final_logits =  tensor([[[-0.1937,  6.6291,  0.1781,  ..., -2.5229,  0.7833, -0.5771],
         [-0.2247,  5.6180, -0.3191,  ..., -1.0949, -0.4020, -1.2860],
         [-0.2006,  4.8704, -0.5127,  ..., -1.5543, -0.7021, -1.6578],
         ...,
         [-0.1548,  8.7704,  0.1412,  ..., -1.4833,  0.4950,  1.7586],
         [-0.2090,  9.4056,  0.0743,  ..., -2.1801,  0.2112,  1.5045],
         [-0.2104, 13.3341, -0.0687,  ..., -1.6077, -0.9138,  0.5812]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1710, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2856, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
13 killed in the 2010 explosion .
iter = 4 reward = 0
final_logits =  tensor([[[-0.1856,  6.5555,  0.1738,  ..., -2.5108,  0.6656, -0.6623],
         [-0.2178,  5.5275, -0.3138,  ..., -1.1595, -0.4466, -1.2934],
         [-0.1937,  4.7860, -0.5082,  ..., -1.5573, -0.7515, -1.7150],
         ...,
         [-0.2628,  6.3271, -0.9161,  ..., -2.7680, -0.1887, -0.3900],
         [-0.1658,  8.8014,  0.0720,  ..., -1.5674,  0.3648,  1.1328],
         [-0.2578, 11.9310, -0.3280,  ..., -1.1229,  0.0218,  0.1689]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.9585, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3240, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[16036,   762, 14567,   114,   711,   113,   110,   105,  2111,  1057,
            395,  1034,   139, 21549, 16036,   762, 14567,   115,   109,  7175,
            113,  3064,   148, 50233,   109,  4170,   160,  3079,   644,  2175,
            110,   108,   155,   109,  1319,  1977,   113, 11461,   649,   109,
          14567,   140,   109,   711,   113,  1025, 46366,   110,   107,  1084,
          44907, 41534,   140,  1977,   113, 11461,  1034,   116,   655,   260,
            135,  5109,   112,  3390,   111,   148,   243,   223,   644,   524,
            632,   112,   823,   114,   110,   105, 30493,   824,   113,   109,
           2379,   110,   107, 16837,   125,   116,  1086,   734,   112,   145,
           1321,  1110,   299,   114,   300,   121,  1704,  6030,   112, 11881,
          13922,   110,   152,   325,   117,   461,   762,   297,   113,   109,
            951,   110,   108,   132,   109,   575,   110,   152,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
The 2008 2005 fossil business solutions sharpened the the U.
iter = 0 reward = 0
final_logits =  tensor([[[-9.0760e-04,  3.5957e+00,  7.0772e-01,  ..., -2.7192e+00,
          -2.4229e-01, -8.0210e-01],
         [-1.3597e-01,  9.2327e+00, -5.9048e-02,  ..., -3.2569e+00,
          -7.8714e-02, -2.0710e+00],
         [-9.9766e-02,  9.3225e+00,  1.1549e-01,  ..., -1.5063e+00,
           1.2781e+00, -1.4957e+00],
         ...,
         [ 6.9791e-02,  7.9010e+00,  2.9765e-01,  ..., -4.0453e+00,
          -1.4559e+00, -6.4770e-01],
         [-2.2488e-03,  8.1622e+00,  3.9030e-01,  ..., -2.0426e+00,
          -9.8764e-01, -2.4503e+00],
         [-2.3614e-01,  1.3513e+01, -3.9136e-01,  ..., -1.5570e+00,
           1.6805e-02, -1.1588e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.0970, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3793, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)

Everytime after generating next logits 38.2% (4204 out of 11019)
The 2008fossfoss fuel solutions sharpened the the the
iter = 1 reward = 0
final_logits =  tensor([[[-1.2836e-03,  3.6285e+00,  7.0835e-01,  ..., -2.7196e+00,
          -2.5556e-01, -7.8402e-01],
         [-1.3555e-01,  9.2940e+00, -5.6248e-02,  ..., -3.2843e+00,
          -9.0348e-02, -2.0355e+00],
         [-1.0007e-01,  9.3963e+00,  1.0976e-01,  ..., -1.4942e+00,
           1.2784e+00, -1.4724e+00],
         ...,
         [ 4.6050e-02,  8.1286e+00,  1.5131e-01,  ..., -4.0177e+00,
          -1.3598e+00, -8.4022e-01],
         [ 2.6998e-02,  8.5426e+00,  1.4917e-01,  ..., -3.9817e+00,
          -1.3434e+00, -8.9302e-01],
         [-2.5374e-02,  9.1689e+00,  1.0231e-01,  ..., -4.0782e+00,
          -1.5314e+00, -1.0876e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.5283, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3519, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
The 2008foss fuels fuel choice 
iter = 2 reward = 0
final_logits =  tensor([[[-2.4906e-03,  3.6505e+00,  7.0467e-01,  ..., -2.7443e+00,
          -2.9581e-01, -7.5142e-01],
         [-1.3447e-01,  9.3485e+00, -5.4515e-02,  ..., -3.2974e+00,
          -9.5954e-02, -2.0022e+00],
         [-1.0506e-01,  9.5544e+00,  1.0383e-01,  ..., -1.4837e+00,
           1.2841e+00, -1.4699e+00],
         ...,
         [-8.3497e-02,  7.4860e+00, -3.3621e-01,  ..., -2.4971e+00,
           8.3453e-02, -4.8632e-01],
         [-5.2653e-02,  8.1128e+00, -5.3448e-01,  ..., -2.7551e+00,
          -5.1888e-02, -1.2317e+00],
         [-1.6013e-01,  1.1481e+01, -1.9161e-01,  ..., -1.9901e+00,
          -8.4072e-01, -3.6597e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.4152, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3076, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 4.2282e-06,  3.6215e+00,  7.0003e-01,  ..., -2.7806e+00,
          -3.1615e-01, -7.5849e-01],
         [-1.3224e-01,  9.3559e+00, -5.3248e-02,  ..., -3.3132e+00,
          -6.6818e-02, -2.0158e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2757, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2481, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
The
iter = 4 reward = 0
final_logits =  tensor([[[ 1.1218e-02,  3.4954e+00,  6.9380e-01,  ..., -2.8713e+00,
          -2.8067e-01, -8.1843e-01],
         [-1.2578e-01,  9.3240e+00, -5.6482e-02,  ..., -3.3646e+00,
           2.3902e-03, -2.0649e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-1.2600, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.2245, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 1346,  6661,   118,   762, 14567,   945,   139,  2800,  1728,   112,
           2555,   110,   105, 41638, 16837,  1003,   121,   768,  1739,   120,
            133,   174,   263,   115,   109,  7175,   113,  3064,   139,  1346,
           6661,  2800,   110,   108,   229,   606,   118,  6957,   109,   808,
          70959,   503,   110,   108,   148,  2365,   114,  3662, 13602,   604,
            762,  1003,   121,   768,  1459,   110,   107,   139,  2800,   110,
            108,   162,  1653,   120,   203,  1962,  2560,   117,   110,   105,
            112,   650,   160,  8695, 33237,   118,   109,  1280,   113,  7633,
          16837,  1487,   203,   807,  4086,   134,   114,  1833,  1792,   115,
           1741,  3710,   110,   107,   182,   117,   203,  6932,   110,   105,
            698,  9501,  1702, 16837,   110,   107,  1810,  1518,   137,  2337,
            118,   109,  1702,   430,   960,  2651,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1]]])}

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
Platform
iter = 0 reward = 0
final_logits =  tensor([[[ 0.2846,  4.4712,  0.4794,  ..., -3.9328, -0.2777, -0.7277],
         [-0.0701, 12.3799, -0.3253,  ..., -1.4685, -0.7960, -1.4656]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4463, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1558, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
Platform
iter = 1 reward = 0
final_logits =  tensor([[[ 0.2871,  4.4847,  0.4824,  ..., -3.9266, -0.2718, -0.7342],
         [-0.0670, 12.3510, -0.3233,  ..., -1.5492, -0.7947, -1.5071]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4672, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1355, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
breakthroughs
iter = 2 reward = 0
final_logits =  tensor([[[ 0.2900,  4.5003,  0.4864,  ..., -3.9163, -0.2651, -0.7455],
         [-0.1101, 12.9609, -0.4465,  ..., -0.7077, -0.3355, -1.1336]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4589, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1234, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
winners
iter = 3 reward = 0
final_logits =  tensor([[[ 0.2916,  4.5315,  0.4838,  ..., -3.8795, -0.2579, -0.8174],
         [-0.0474, 12.3744, -0.5905,  ..., -0.8630,  0.1268, -1.3066]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4291, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1060, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)
winners
iter = 4 reward = 0
final_logits =  tensor([[[ 0.2921,  4.5664,  0.4807,  ..., -3.8297, -0.2536, -0.8895],
         [-0.0422, 12.3486, -0.5884,  ..., -0.8423,  0.1198, -1.3594]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4454, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0907, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 3211,  1307,  2652,  2882,  2033,   134,   280, 85536, 17403,  4596,
            398, 16036,  1034,   116, 11599,  2664,   109,   519,   113,   114,
           6033,   124,  9134,  9600,   110,   108,   109, 12220,   113, 14645,
           9727,   135,   109,   762, 14567,   115,   109,  7175,   113,  3064,
            148,  9380,   164,   115,   114,  2043, 22369,   115, 10792,   110,
            107,   353,  1761,  7690,   355,  1854,   199,   109, 18191,   113,
          14645,   246,   129,  8626,   122,   110,   107,  9903, 90966,  1574,
            135,   351,   859,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.6% (4146 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)

Everytime after generating next logits 37.8% (4166 out of 11019)
Lawsuits dealing dealing dealing with the spill .
iter = 0 reward = 4
final_logits =  tensor([[[ 9.2956e-03,  3.5698e+00,  5.4440e-01,  ...,  2.0105e+00,
           4.2929e-01, -4.9801e-01],
         [-9.5099e-02,  7.5437e+00, -3.3735e-01,  ..., -1.4132e-01,
          -6.5648e-01, -1.3520e+00],
         [ 3.6463e-02,  5.7645e+00, -4.3840e-01,  ...,  1.0189e+00,
          -9.7975e-01, -2.0986e+00],
         ...,
         [-6.1907e-02,  6.5773e+00, -8.4057e-01,  ...,  2.5536e-01,
          -1.0674e+00, -1.4474e+00],
         [-4.7308e-02,  9.4064e+00, -1.8281e-01,  ...,  5.2100e-01,
          -7.5763e-01, -2.1471e-01],
         [-2.0504e-01,  1.3543e+01, -6.4654e-01,  ...,  1.7902e-03,
          -4.5275e-01, -2.0497e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(3.4505, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(7.2460, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)

Everytime after generating next logits 38.2% (4206 out of 11019)
The 2VerdictVerdictVerdict of 2 July 2 federal lawsuits were resolved in Idaho .
iter = 1 reward = 1
final_logits =  tensor([[[ 3.8830e-02,  3.5778e+00,  5.9669e-01,  ...,  2.1133e+00,
           3.9987e-01, -2.5202e-01],
         [-1.1013e-02,  7.8530e+00,  9.0218e-02,  ...,  1.0767e+00,
          -3.2320e-01, -1.9474e+00],
         [-3.4617e-02,  6.7411e+00, -5.4086e-02,  ...,  9.2209e-01,
          -1.6550e+00, -1.9505e+00],
         ...,
         [-4.0134e-02,  7.9313e+00, -4.8926e-01,  ...,  1.2035e+00,
          -1.4166e+00, -1.4467e+00],
         [-7.9882e-02,  1.0589e+01, -1.6759e-01,  ...,  2.7954e-02,
          -1.0469e+00,  2.7000e-02],
         [-1.8796e-01,  1.3437e+01, -5.1780e-01,  ..., -2.7560e-01,
          -7.0009e-01, -1.2465e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.4218, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.3253, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)

Everytime after generating next logits 38.2% (4214 out of 11019)
The
iter = 2 reward = 0
final_logits =  tensor([[[ 0.0633,  4.4250,  0.6370,  ...,  2.0073,  0.6115, -0.2137],
         [-0.0729, 11.4252, -0.1948,  ...,  0.7931, -0.5071, -1.6634]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3073, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
The
iter = 3 reward = 0
final_logits =  tensor([[[ 0.0431,  3.8319,  0.6134,  ...,  2.0347,  0.4009, -0.3772],
         [-0.0661, 10.7154, -0.1904,  ...,  0.7594, -0.5122, -1.8747]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.3804, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0364, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 37.8% (4164 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.0% (4184 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.2% (4208 out of 11019)

Everytime after generating next logits 38.3% (4222 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.4% (4236 out of 11019)

Everytime after generating next logits 38.6% (4252 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.7% (4268 out of 11019)

Everytime after generating next logits 38.9% (4286 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.1% (4304 out of 11019)

Everytime after generating next logits 39.2% (4324 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.4% (4344 out of 11019)

Everytime after generating next logits 39.8% (4388 out of 11019)

Everytime after generating next logits 40.2% (4432 out of 11019)

Everytime after generating next logits 40.2% (4432 out of 11019)

Everytime after generating next logits 40.2% (4432 out of 11019)

Everytime after generating next logits 40.2% (4432 out of 11019)
VolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumeVolumes
iter = 4 reward = 0
final_logits =  tensor([[[ 0.0433,  3.5297,  0.6799,  ...,  1.6111,  0.3369, -0.5369],
         [-0.1480,  4.7781, -0.0966,  ...,  0.9700, -0.8081, -1.0702],
         [-0.1692,  5.2825, -0.1586,  ...,  0.6473, -1.1211, -1.2883],
         ...,
         [-0.2941,  9.1950,  0.2218,  ..., -0.9644, -3.9883, -2.1953],
         [-0.2990,  9.3598,  0.2275,  ..., -0.9314, -3.8941, -2.1958],
         [-0.2753,  8.6348, -0.0338,  ..., -1.0356, -3.0467, -3.2179]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.1947, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
{'input_ids': tensor([[[ 2571,  1508,  2652,  2882,  2033,   134,   305, 49218, 17403,  4596,
            222,  6358,   109, 40522, 34524,  4820,   164,   299,  4027,  1034,
            116, 62223,   454,  3682,  3793,   156,   113,   109,   278,  1034,
            116,  3741,   762, 12802,   110,   107,  1478,   115,   109,  5569,
            110,   108,  3070,   111,   176,  3217, 17659,   109,  1322,   192,
            394,  5097,   110,   107,   343, 62223,   148,   174, 71731,   115,
            109,  1965, 43983,   231,   110,   108,   112,   253,   142,  4156,
            120,   126,   117,   744,   130,   175,   109,  2648,   394,  2032,
            110,   107,   168,   117,  8549, 62223,  1034,   116,   584,   256,
            319,  2520,   118,   274,   115,   109,  7175,   113,  3064,   170,
            127, 48322,   120,   157,   138,   521,  5097,   135,   109,  2926,
          16036,   762, 14567,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1]]])}

Before Sampling 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)

Everytime after generating next logits 39.1% (4308 out of 11019)
Galicia region in 2010 disaster 
iter = 0 reward = 2
final_logits =  tensor([[[-0.1474,  3.2779,  0.4197,  ..., -5.4924,  0.4582, -3.4395],
         [-0.4414,  4.8948, -0.6025,  ..., -5.9944, -1.8230, -3.1972],
         [-0.2928,  6.8401, -0.9011,  ..., -5.0932, -0.6652, -4.0519],
         ...,
         [-0.3644,  5.4139, -0.4333,  ..., -5.5490,  0.4250, -3.2491],
         [-0.2166,  4.3842, -0.7198,  ..., -3.6117, -0.5272, -4.4246],
         [-0.2156,  9.9017,  0.0511,  ..., -3.7400,  0.0860, -3.0747]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.0459, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6399, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Galicia region in 2010 disaster 
iter = 1 reward = 2
final_logits =  tensor([[[-0.1464,  3.2880,  0.4246,  ..., -5.4916,  0.4514, -3.4201],
         [-0.4438,  4.9429, -0.6031,  ..., -6.0089, -1.7959, -3.1778],
         [-0.2947,  6.9001, -0.9033,  ..., -5.1065, -0.6596, -4.0731],
         ...,
         [-0.3696,  5.4219, -0.4373,  ..., -5.5426,  0.4189, -3.2280],
         [-0.2184,  4.4130, -0.7223,  ..., -3.6388, -0.5163, -4.4421],
         [-0.2182,  9.9475,  0.0496,  ..., -3.7437,  0.0769, -3.0636]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(2.0114, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6426, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)

Everytime after generating next logits 38.1% (4198 out of 11019)
Galicia region in 2010 disaster 
iter = 2 reward = 2
final_logits =  tensor([[[-0.1473,  3.3081,  0.4298,  ..., -5.4749,  0.4410, -3.4012],
         [-0.4488,  4.9962, -0.6041,  ..., -6.0183, -1.7441, -3.1487],
         [-0.2998,  6.9682, -0.9049,  ..., -5.1294, -0.6431, -4.0995],
         ...,
         [-0.3795,  5.4208, -0.4421,  ..., -5.5319,  0.4161, -3.1931],
         [-0.2231,  4.4565, -0.7228,  ..., -3.6880, -0.5047, -4.4608],
         [-0.2240, 10.0010,  0.0475,  ..., -3.7526,  0.0728, -3.0425]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.9446, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6368, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
Galicia region in 2010 disaster 
iter = 3 reward = 2
final_logits =  tensor([[[-0.1494,  3.3518,  0.4347,  ..., -5.4668,  0.4317, -3.4126],
         [-0.4544,  5.1169, -0.6094,  ..., -6.0212, -1.6913, -3.1266],
         [-0.3066,  7.1314, -0.9098,  ..., -5.1427, -0.6327, -4.1224],
         ...,
         [-0.3932,  5.5002, -0.4537,  ..., -5.5120,  0.3983, -3.1676],
         [-0.2315,  4.5612, -0.7326,  ..., -3.7350, -0.4849, -4.4773],
         [-0.2330, 10.1513,  0.0369,  ..., -3.7244,  0.0728, -3.0116]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.8456, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6229, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
Galicia region in 2010 disaster 
iter = 4 reward = 2
final_logits =  tensor([[[-0.1532,  3.3813,  0.4451,  ..., -5.4561,  0.4145, -3.4261],
         [-0.4584,  5.2338, -0.6125,  ..., -6.0243, -1.6482, -3.1128],
         [-0.3126,  7.2977, -0.9130,  ..., -5.1520, -0.6103, -4.1379],
         ...,
         [-0.4057,  5.5766, -0.4626,  ..., -5.5010,  0.3803, -3.1645],
         [-0.2400,  4.6646, -0.7433,  ..., -3.7744, -0.4512, -4.4768],
         [-0.2422, 10.3035,  0.0240,  ..., -3.6952,  0.0760, -2.9866]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(1.7406, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(1.6025, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  2
2
{'input_ids': tensor([[[  787, 17984,   116, 16036,   204,  7175,   113,  3064,   762,  5135,
           1195,  1408,  2652,  2882,  2033,   134, 79386,   914, 17403,  4596,
            139,   706,  1013,   117,   112, 17984, 16036,   111,  1965,   176,
            524,   204,   114,  1124,   762, 14567,   115,   109,  7175,   113,
           3064,   110,   107,   139,   657,   243,   126,   192,  1137,   109,
           3358,  1069,  9873,   118,   109, 13353,   113,  2729,  1363,   124,
           1496,   164,   109,  3741,  2249,  5135,   115,   787,   689,   110,
            107, 36347,  1024,  2342,   115,   109, 11335,   124,   109, 81065,
          18308,  9600, 13773,   115,   960,   110,   107,   139,  6442,  1034,
            116, 55065, 66707,  1574,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1]]])}

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
BBC
iter = 0 reward = 1
final_logits =  tensor([[[-0.1835,  5.1340,  0.3847,  ..., -4.9619,  2.4999, -2.3098],
         [-0.2121, 12.3879, -0.1415,  ..., -4.2015, -1.4905, -2.4903]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3745, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5744, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)

Everytime after generating next logits 37.6% (4144 out of 11019)
BBC
iter = 1 reward = 1
final_logits =  tensor([[[-0.1896,  5.1498,  0.3800,  ..., -4.9845,  2.4398, -2.2773],
         [-0.2105, 12.4080, -0.1641,  ..., -4.0991, -1.4525, -2.4323]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.3044, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5532, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
BBC
iter = 2 reward = 1
final_logits =  tensor([[[-0.1967,  5.1684,  0.3725,  ..., -5.0339,  2.3539, -2.2232],
         [-0.2069, 12.4443, -0.1886,  ..., -3.9962, -1.3978, -2.3621]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2443, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5302, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)

Everytime after generating next logits 37.6% (4148 out of 11019)
BBC
iter = 3 reward = 1
final_logits =  tensor([[[-0.2044,  5.1967,  0.3654,  ..., -5.1112,  2.2455, -2.1578],
         [-0.2020, 12.4582, -0.2112,  ..., -3.8744, -1.3290, -2.3051]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.2082, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.5049, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)
BBC
iter = 4 reward = 1
final_logits =  tensor([[[-0.2102,  5.2049,  0.3550,  ..., -5.1643,  2.1640, -2.0905],
         [-0.1976, 12.4515, -0.2374,  ..., -3.6734, -1.2212, -2.2891]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(0.1877, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.4796, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  1
1
{'input_ids': tensor([[[ 7915, 26939,  4355,  1194,   244, 16036,   762, 14567,  5823,  8437,
            117,   364,   109, 19954,   113,   109,  7175,   113,  3064,   235,
            149,   314,   210,   110,   107,   139,   908,   317,  6299,   111,
           1174,   117,  8988,   153, 19347,   578,   110,   107,   343,   136,
            232,   205,   113,   109, 27736,   127,  2609,   110,   107,   139,
          27736,   127,   146,  1622,   115,   762,   110,   108,   130,   109,
           6442,  1034,   116,  2040,  9518,  1574,   135,  7915,   110,   108,
            155,  3040,   299,   141,  2926, 21615, 22611,   116,   120,   195,
           2443,   112,  2512,   109, 15737,   110,   107,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])}

Before Sampling 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.7% (4150 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)

Everytime after generating next logits 37.8% (4170 out of 11019)
economically economically economically economically economically economically economically 
iter = 0 reward = 0
final_logits =  tensor([[[-0.4066,  6.2661,  0.3113,  ..., -3.8550,  0.0500, -0.8636],
         [-0.4132,  7.2745, -0.3526,  ..., -2.8443, -0.3348, -0.4917],
         [-0.4106,  8.1123, -0.4072,  ..., -2.9056, -0.2593, -0.5345],
         ...,
         [-0.3793,  7.7512, -0.3800,  ..., -3.2985, -0.3825, -0.5491],
         [-0.3730,  7.6792, -0.3374,  ..., -3.2104, -0.2759, -0.5996],
         [-0.4114, 11.1961, -0.2966,  ..., -3.6410, -1.6216, -0.0524]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.4431, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0923, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)

Everytime after generating next logits 38.1% (4196 out of 11019)
economically economically economically economically economically economically economically 
iter = 1 reward = 0
final_logits =  tensor([[[-0.4081,  6.2620,  0.3134,  ..., -3.8417,  0.0448, -0.8444],
         [-0.4199,  7.7907, -0.3495,  ..., -2.7574, -0.3047, -0.4702],
         [-0.4179,  8.7700, -0.4127,  ..., -2.8303, -0.2401, -0.5236],
         ...,
         [-0.3855,  8.2672, -0.3954,  ..., -3.2365, -0.3940, -0.6072],
         [-0.3780,  8.2121, -0.3597,  ..., -3.1573, -0.2933, -0.6702],
         [-0.4086, 11.5296, -0.3134,  ..., -3.5388, -1.5909, -0.0438]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5376, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1013, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)

Everytime after generating next logits 38.1% (4202 out of 11019)
transponder transponder transponder transponder transponder transponder
iter = 2 reward = 0
final_logits =  tensor([[[-0.4124,  6.2569,  0.3202,  ..., -3.8195,  0.0561, -0.7945],
         [-0.4847,  9.0584, -0.6590,  ..., -3.6453, -1.3337, -1.8738],
         [-0.4935,  9.7221, -0.7576,  ..., -3.6762, -1.5583, -2.2908],
         ...,
         [-0.4825, 10.3154, -0.8139,  ..., -3.6823, -1.7508, -2.6574],
         [-0.4727, 10.4281, -0.8241,  ..., -3.6495, -1.8335, -2.7580],
         [-0.4620, 10.4618, -0.8314,  ..., -3.6045, -1.9339, -2.8513]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5381, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1629, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)

Everytime after generating next logits 38.1% (4200 out of 11019)
transponder transponder transponder transponder
iter = 3 reward = 0
final_logits =  tensor([[[-0.4142,  6.2534,  0.3187,  ..., -3.8382,  0.0350, -0.7995],
         [-0.4843,  9.2148, -0.6854,  ..., -3.6868, -1.4058, -1.9392],
         [-0.4921,  9.8963, -0.7782,  ..., -3.7315, -1.6409, -2.3708],
         [-0.4855, 10.2737, -0.8140,  ..., -3.7355, -1.7611, -2.5862],
         [-0.4773, 10.4588, -0.8264,  ..., -3.7003, -1.8448, -2.6939]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.5924, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.1600, device='cuda:0', grad_fn=<MseLossBackward>)

Before Sampling 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)

Everytime after generating next logits 37.9% (4178 out of 11019)
economically
iter = 4 reward = 0
final_logits =  tensor([[[-0.4152,  6.2397,  0.3053,  ..., -3.9077,  0.0100, -0.8550],
         [-0.4320,  9.7589, -0.3518,  ..., -2.5853, -0.2049, -0.3062]]],
       device='cuda:0', grad_fn=<AddBackward0>)
actor_loss =  tensor(-0.6515, device='cuda:0', grad_fn=<NegBackward>)
critic_loss =  tensor(0.0674, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  0
0
