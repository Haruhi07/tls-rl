 
 University of Bristol ACRC HPC Bluepebble Service
 -------------------------------------------------
 Job tls_rl, jobid 3495371.bp1, username hs20307 - started execution at 23:01:14 Sun 01/08/21 on node bp1-gpu00011.data.bp.acrc.priv
 
length =  48
env initialized...
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         [ 0.0000,  4.1696,  0.0675,  ...,  0.7519,  0.2523, -1.0552]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         [ 0.0000,  4.1696,  0.0675,  ...,  0.7519,  0.2523, -1.0552],
         [ 0.0000,  2.4066,  0.0061,  ..., -1.7051, -1.8958, -1.8161]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         [ 0.0000,  4.1696,  0.0675,  ...,  0.7519,  0.2523, -1.0552],
         [ 0.0000,  2.4066,  0.0061,  ..., -1.7051, -1.8958, -1.8161],
         [ 0.0000,  3.1492, -0.2295,  ..., -1.7801,  0.8852, -1.0484]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.4066,  0.0061,  ..., -1.7051, -1.8958, -1.8161],
         [ 0.0000,  3.1492, -0.2295,  ..., -1.7801,  0.8852, -1.0484],
         [ 0.0000,  3.1214,  0.4454,  ..., -2.2158, -0.1808, -0.2003]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.1492, -0.2295,  ..., -1.7801,  0.8852, -1.0484],
         [ 0.0000,  3.1214,  0.4454,  ..., -2.2158, -0.1808, -0.2003],
         [ 0.0000,  0.6093,  0.0198,  ..., -1.6751,  0.6736, -3.0628]]],
       device='cuda:0')
action =  tensor(150, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.1214,  0.4454,  ..., -2.2158, -0.1808, -0.2003],
         [ 0.0000,  0.6093,  0.0198,  ..., -1.6751,  0.6736, -3.0628],
         [ 0.0000,  2.7296,  0.3619,  ..., -0.6966, -1.3147, -2.1311]]],
       device='cuda:0')
action =  tensor(5407, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  0.6093,  0.0198,  ..., -1.6751,  0.6736, -3.0628],
         [ 0.0000,  2.7296,  0.3619,  ..., -0.6966, -1.3147, -2.1311],
         [ 0.0000,  2.3609, -0.0556,  ..., -2.3953, -0.2764, -1.3193]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.7296,  0.3619,  ..., -0.6966, -1.3147, -2.1311],
         [ 0.0000,  2.3609, -0.0556,  ..., -2.3953, -0.2764, -1.3193],
         [ 0.0000,  1.4667, -0.0295,  ..., -2.8412,  0.4777, -2.2374]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.3609, -0.0556,  ..., -2.3953, -0.2764, -1.3193],
         [ 0.0000,  1.4667, -0.0295,  ..., -2.8412,  0.4777, -2.2374],
         [ 0.0000,  2.3375, -0.3432,  ...,  0.4922, -1.1801, -1.8188]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.4667, -0.0295,  ..., -2.8412,  0.4777, -2.2374],
         [ 0.0000,  2.3375, -0.3432,  ...,  0.4922, -1.1801, -1.8188],
         [ 0.0000,  2.6149,  0.9491,  ...,  1.6586, -0.5384,  0.1419]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.3375, -0.3432,  ...,  0.4922, -1.1801, -1.8188],
         [ 0.0000,  2.6149,  0.9491,  ...,  1.6586, -0.5384,  0.1419],
         [ 0.0000,  4.7541,  0.3675,  ...,  1.0342, -0.3925, -2.1053]]],
       device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.6149,  0.9491,  ...,  1.6586, -0.5385,  0.1419],
         [ 0.0000,  4.7541,  0.3675,  ...,  1.0342, -0.3925, -2.1053],
         [ 0.0000,  2.5118, -0.3643,  ..., -2.1090,  1.2945, -2.8759]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.7541,  0.3675,  ...,  1.0342, -0.3925, -2.1053],
         [ 0.0000,  2.5118, -0.3643,  ..., -2.1090,  1.2945, -2.8759],
         [ 0.0000,  8.4143, -0.5694,  ..., -1.0023,  0.4493, -4.0441]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.5118, -0.3643,  ..., -2.1090,  1.2945, -2.8758],
         [ 0.0000,  8.4143, -0.5694,  ..., -1.0023,  0.4493, -4.0441],
         [ 0.0000, -0.6068,  0.4263,  ..., -2.9205,  1.4843, -0.9019]]],
       device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  8.4143, -0.5694,  ..., -1.0023,  0.4493, -4.0441],
         [ 0.0000, -0.6068,  0.4263,  ..., -2.9205,  1.4843, -0.9019],
         [ 0.0000,  0.9475,  0.1532,  ..., -4.0278,  1.6624, -0.0695]]],
       device='cuda:0')
action =  tensor(274, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000, -0.6068,  0.4263,  ..., -2.9205,  1.4843, -0.9019],
         [ 0.0000,  0.9475,  0.1532,  ..., -4.0278,  1.6624, -0.0695],
         [ 0.0000,  3.0444,  0.6838,  ..., -2.5680,  0.4675,  0.1130]]],
       device='cuda:0')
action =  tensor(2790, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  0.9475,  0.1532,  ..., -4.0278,  1.6624, -0.0695],
         [ 0.0000,  3.0444,  0.6838,  ..., -2.5680,  0.4675,  0.1130],
         [ 0.0000,  3.3793, -0.3891,  ..., -1.0340, -0.0934, -0.1964]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.0444,  0.6838,  ..., -2.5680,  0.4675,  0.1130],
         [ 0.0000,  3.3793, -0.3891,  ..., -1.0340, -0.0934, -0.1964],
         [ 0.0000,  3.7218, -0.2121,  ..., -0.2523, -0.0364, -0.0734]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.3793, -0.3891,  ..., -1.0340, -0.0934, -0.1964],
         [ 0.0000,  3.7218, -0.2121,  ..., -0.2523, -0.0364, -0.0734],
         [ 0.0000,  8.6006,  0.3621,  ..., -1.5011,  1.8082, -0.2237]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.7218, -0.2121,  ..., -0.2523, -0.0364, -0.0734],
         [ 0.0000,  8.6006,  0.3621,  ..., -1.5011,  1.8082, -0.2237],
         [ 0.0000,  2.2485, -0.1874,  ..., -1.9040, -0.6929, -1.0808]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  8.6006,  0.3621,  ..., -1.5011,  1.8082, -0.2237],
         [ 0.0000,  2.2485, -0.1874,  ..., -1.9040, -0.6929, -1.0808],
         [ 0.0000,  1.5073,  0.0644,  ..., -1.8200,  3.1853, -1.9503]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.2485, -0.1874,  ..., -1.9040, -0.6929, -1.0808],
         [ 0.0000,  1.5073,  0.0644,  ..., -1.8200,  3.1853, -1.9503],
         [ 0.0000,  3.9117,  0.4143,  ...,  0.2618, -0.9304, -2.2156]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.5073,  0.0644,  ..., -1.8200,  3.1853, -1.9503],
         [ 0.0000,  3.9117,  0.4143,  ...,  0.2618, -0.9304, -2.2156],
         [ 0.0000,  3.4354,  0.1478,  ..., -0.2281, -1.0086, -0.4924]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.9117,  0.4143,  ...,  0.2618, -0.9304, -2.2156],
         [ 0.0000,  3.4354,  0.1478,  ..., -0.2281, -1.0086, -0.4924],
         [ 0.0000,  1.3775, -0.2339,  ..., -1.2015,  0.8382, -1.9551]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.4354,  0.1478,  ..., -0.2281, -1.0086, -0.4924],
         [ 0.0000,  1.3775, -0.2339,  ..., -1.2015,  0.8382, -1.9551],
         [ 0.0000,  3.6320,  0.3575,  ..., -2.1510,  1.0240, -2.4390]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.3775, -0.2339,  ..., -1.2015,  0.8382, -1.9551],
         [ 0.0000,  3.6320,  0.3575,  ..., -2.1510,  1.0240, -2.4390],
         [ 0.0000,  2.3760,  0.4866,  ..., -1.0065, -1.0011, -0.4245]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.6320,  0.3575,  ..., -2.1510,  1.0240, -2.4390],
         [ 0.0000,  2.3760,  0.4866,  ..., -1.0065, -1.0011, -0.4245],
         [ 0.0000,  2.5562, -0.0570,  ..., -0.2116,  1.7192, -0.9052]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.3760,  0.4866,  ..., -1.0065, -1.0011, -0.4245],
         [ 0.0000,  2.5562, -0.0570,  ..., -0.2116,  1.7192, -0.9052],
         [ 0.0000,  2.3846,  0.4816,  ..., -0.6099,  2.3120, -1.7462]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.5562, -0.0570,  ..., -0.2116,  1.7192, -0.9052],
         [ 0.0000,  2.3846,  0.4816,  ..., -0.6099,  2.3120, -1.7462],
         [ 0.0000,  2.8428,  0.6368,  ...,  0.3934,  1.0475, -1.9785]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.3846,  0.4816,  ..., -0.6099,  2.3120, -1.7462],
         [ 0.0000,  2.8428,  0.6368,  ...,  0.3934,  1.0475, -1.9785],
         [ 0.0000,  3.5992,  0.0149,  ..., -1.2726, -0.9603, -0.6525]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.8428,  0.6368,  ...,  0.3934,  1.0475, -1.9785],
         [ 0.0000,  3.5992,  0.0149,  ..., -1.2726, -0.9603, -0.6525],
         [ 0.0000,  2.6192, -0.1814,  ..., -0.1546,  1.0007, -1.2797]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.5992,  0.0149,  ..., -1.2726, -0.9603, -0.6525],
         [ 0.0000,  2.6192, -0.1814,  ..., -0.1546,  1.0007, -1.2797],
         [ 0.0000,  3.8294,  0.2460,  ..., -1.1963, -1.3737, -3.6306]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.6192, -0.1814,  ..., -0.1546,  1.0007, -1.2797],
         [ 0.0000,  3.8294,  0.2460,  ..., -1.1963, -1.3737, -3.6306],
         [ 0.0000,  3.4806,  0.5530,  ..., -1.4821, -0.5717, -2.4925]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.8294,  0.2460,  ..., -1.1963, -1.3737, -3.6306],
         [ 0.0000,  3.4806,  0.5530,  ..., -1.4821, -0.5717, -2.4925],
         [ 0.0000,  3.3885, -0.0543,  ..., -0.1529,  0.4463, -0.8387]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  3.4806e+00,  5.5300e-01,  ..., -1.4821e+00,
          -5.7173e-01, -2.4925e+00],
         [ 0.0000e+00,  3.3885e+00, -5.4317e-02,  ..., -1.5291e-01,
           4.4628e-01, -8.3869e-01],
         [ 0.0000e+00,  3.2601e+00, -1.3227e-03,  ...,  6.0094e-01,
          -8.4654e-01, -2.3155e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  3.3885e+00, -5.4317e-02,  ..., -1.5291e-01,
           4.4628e-01, -8.3869e-01],
         [ 0.0000e+00,  3.2601e+00, -1.3227e-03,  ...,  6.0094e-01,
          -8.4654e-01, -2.3155e+00],
         [ 0.0000e+00,  1.0753e+00,  3.2641e-01,  ..., -7.3393e-01,
           1.2525e+00,  1.7808e+00]]], device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  3.2601e+00, -1.3227e-03,  ...,  6.0094e-01,
          -8.4654e-01, -2.3155e+00],
         [ 0.0000e+00,  1.0753e+00,  3.2641e-01,  ..., -7.3393e-01,
           1.2525e+00,  1.7808e+00],
         [ 0.0000e+00,  1.2010e+00, -1.4557e-01,  ..., -1.7187e+00,
           3.7614e-01,  7.7624e-01]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.0753,  0.3264,  ..., -0.7339,  1.2525,  1.7808],
         [ 0.0000,  1.2010, -0.1456,  ..., -1.7187,  0.3761,  0.7762],
         [ 0.0000,  1.8664,  0.1929,  ..., -1.2071,  1.4363,  1.4504]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.2010, -0.1456,  ..., -1.7187,  0.3761,  0.7762],
         [ 0.0000,  1.8664,  0.1929,  ..., -1.2071,  1.4363,  1.4504],
         [ 0.0000,  1.8499, -0.6102,  ..., -0.6727,  0.0862, -0.1993]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.8664,  0.1929,  ..., -1.2071,  1.4363,  1.4504],
         [ 0.0000,  1.8499, -0.6102,  ..., -0.6727,  0.0862, -0.1993],
         [ 0.0000,  4.0782, -0.2331,  ..., -0.3045,  0.0642,  0.0300]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.8499, -0.6102,  ..., -0.6727,  0.0862, -0.1993],
         [ 0.0000,  4.0782, -0.2331,  ..., -0.3045,  0.0642,  0.0300],
         [ 0.0000,  9.8818,  0.3154,  ..., -1.3764,  2.4350,  0.0245]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.0782, -0.2331,  ..., -0.3045,  0.0642,  0.0300],
         [ 0.0000,  9.8818,  0.3154,  ..., -1.3764,  2.4350,  0.0245],
         [ 0.0000,  3.1532, -0.1258,  ..., -1.3651, -0.2610, -1.5992]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  9.8818,  0.3154,  ..., -1.3764,  2.4350,  0.0245],
         [ 0.0000,  3.1532, -0.1258,  ..., -1.3651, -0.2610, -1.5992],
         [ 0.0000,  0.6105, -0.4444,  ..., -2.7739,  1.2074, -0.0377]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.1532, -0.1258,  ..., -1.3651, -0.2610, -1.5992],
         [ 0.0000,  0.6105, -0.4444,  ..., -2.7739,  1.2074, -0.0377],
         [ 0.0000,  2.6870, -0.2562,  ...,  0.0320,  0.8553,  0.8999]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  0.6105, -0.4444,  ..., -2.7739,  1.2074, -0.0377],
         [ 0.0000,  2.6870, -0.2562,  ...,  0.0320,  0.8553,  0.8999],
         [ 0.0000,  1.1837,  0.0430,  ..., -1.1149,  1.3289, -0.1948]]],
       device='cuda:0')
action =  tensor(129, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.6870, -0.2562,  ...,  0.0320,  0.8553,  0.8999],
         [ 0.0000,  1.1837,  0.0430,  ..., -1.1149,  1.3289, -0.1948],
         [ 0.0000,  1.6752,  0.2098,  ..., -2.8951,  1.0076, -2.3317]]],
       device='cuda:0')
action =  tensor(1900, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.1837,  0.0430,  ..., -1.1149,  1.3289, -0.1948],
         [ 0.0000,  1.6752,  0.2098,  ..., -2.8951,  1.0076, -2.3317],
         [ 0.0000,  0.5096, -0.2213,  ...,  0.3973, -0.9046, -0.8082]]],
       device='cuda:0')
action =  tensor(269, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  1.6752e+00,  2.0977e-01,  ..., -2.8951e+00,
           1.0076e+00, -2.3317e+00],
         [ 0.0000e+00,  5.0960e-01, -2.2129e-01,  ...,  3.9725e-01,
          -9.0464e-01, -8.0823e-01],
         [ 0.0000e+00,  1.7143e+00, -2.2325e-03,  ..., -1.4559e+00,
           4.6596e-01, -2.7824e+00]]], device='cuda:0')
action =  tensor(847, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  5.0960e-01, -2.2129e-01,  ...,  3.9725e-01,
          -9.0464e-01, -8.0823e-01],
         [ 0.0000e+00,  1.7143e+00, -2.2325e-03,  ..., -1.4559e+00,
           4.6596e-01, -2.7824e+00],
         [ 0.0000e+00,  2.1835e+00, -1.2203e-01,  ...,  3.2337e-02,
          -2.7434e-01, -1.1175e+00]]], device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  1.7143e+00, -2.2325e-03,  ..., -1.4559e+00,
           4.6596e-01, -2.7824e+00],
         [ 0.0000e+00,  2.1835e+00, -1.2203e-01,  ...,  3.2337e-02,
          -2.7434e-01, -1.1175e+00],
         [ 0.0000e+00,  1.7705e+00,  1.9997e-01,  ...,  1.0356e+00,
           6.9092e-01, -3.2400e-01]]], device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.1835, -0.1220,  ...,  0.0323, -0.2743, -1.1175],
         [ 0.0000,  1.7705,  0.2000,  ...,  1.0356,  0.6909, -0.3240],
         [ 0.0000,  1.8618,  1.7445,  ...,  2.3534,  1.0066,  0.5497]]],
       device='cuda:0')
action =  tensor(5891, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.7705,  0.2000,  ...,  1.0356,  0.6909, -0.3240],
         [ 0.0000,  1.8618,  1.7445,  ...,  2.3534,  1.0066,  0.5497],
         [ 0.0000,  4.1113,  0.3823,  ..., -1.2248, -0.1061, -1.1724]]],
       device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.8618,  1.7445,  ...,  2.3534,  1.0066,  0.5497],
         [ 0.0000,  4.1113,  0.3823,  ..., -1.2248, -0.1061, -1.1724],
         [ 0.0000,  2.4219, -0.1104,  ..., -0.2942,  1.3562, -0.7649]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.1113,  0.3823,  ..., -1.2248, -0.1061, -1.1724],
         [ 0.0000,  2.4219, -0.1104,  ..., -0.2942,  1.3562, -0.7649],
         [ 0.0000,  4.3801,  0.1169,  ...,  1.6197,  2.6672, -2.9376]]],
       device='cuda:0')
action =  tensor(5469, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.4219, -0.1104,  ..., -0.2942,  1.3562, -0.7649],
         [ 0.0000,  4.3801,  0.1169,  ...,  1.6197,  2.6672, -2.9376],
         [ 0.0000,  3.9920, -0.5000,  ..., -0.7225,  0.4790, -1.5589]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.3801,  0.1169,  ...,  1.6197,  2.6672, -2.9376],
         [ 0.0000,  3.9920, -0.5000,  ..., -0.7225,  0.4790, -1.5589],
         [ 0.0000,  3.4418,  0.3923,  ..., -0.1148,  0.8619, -1.6183]]],
       device='cuda:0')
action =  tensor(4800, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.9920, -0.5000,  ..., -0.7225,  0.4790, -1.5589],
         [ 0.0000,  3.4418,  0.3923,  ..., -0.1148,  0.8619, -1.6183],
         [ 0.0000,  3.8330, -0.3361,  ..., -0.1308, -0.1622,  0.8697]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.4418,  0.3923,  ..., -0.1148,  0.8619, -1.6183],
         [ 0.0000,  3.8330, -0.3361,  ..., -0.1308, -0.1622,  0.8697],
         [ 0.0000,  3.1101,  0.1968,  ...,  0.1019,  1.1575,  1.8381]]],
       device='cuda:0')
action =  tensor(8186, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.8330, -0.3361,  ..., -0.1308, -0.1622,  0.8697],
         [ 0.0000,  3.1101,  0.1968,  ...,  0.1019,  1.1575,  1.8381],
         [ 0.0000,  2.9225, -0.4789,  ...,  0.7060,  0.2183, -0.8858]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.1101,  0.1968,  ...,  0.1019,  1.1575,  1.8381],
         [ 0.0000,  2.9225, -0.4789,  ...,  0.7060,  0.2183, -0.8858],
         [ 0.0000,  4.0236, -0.2720,  ..., -0.1299,  0.0753, -0.1118]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.9225, -0.4789,  ...,  0.7060,  0.2183, -0.8858],
         [ 0.0000,  4.0236, -0.2720,  ..., -0.1299,  0.0753, -0.1118],
         [ 0.0000, 11.4790,  0.1999,  ..., -1.2556,  1.7099,  0.4861]]],
       device='cuda:0')
action =  tensor(1276, device='cuda:0')
reward =  10
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.0236, -0.2720,  ..., -0.1299,  0.0753, -0.1118],
         [ 0.0000, 11.4790,  0.1999,  ..., -1.2556,  1.7099,  0.4861],
         [ 0.0000,  4.9002,  0.0261,  ..., -2.1270,  0.5307, -0.2666]]],
       device='cuda:0')
action =  tensor(3531, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000, 11.4790,  0.1999,  ..., -1.2556,  1.7099,  0.4861],
         [ 0.0000,  4.9002,  0.0261,  ..., -2.1270,  0.5307, -0.2666],
         [ 0.0000,  4.5606, -0.1588,  ..., -4.2006,  0.1112, -0.7637]]],
       device='cuda:0')
action =  tensor(8350, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.9002,  0.0261,  ..., -2.1270,  0.5307, -0.2666],
         [ 0.0000,  4.5606, -0.1588,  ..., -4.2006,  0.1112, -0.7637],
         [ 0.0000,  2.4971, -0.1573,  ..., -2.4664, -0.2434, -0.0244]]],
       device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.5606, -0.1588,  ..., -4.2006,  0.1112, -0.7637],
         [ 0.0000,  2.4971, -0.1573,  ..., -2.4664, -0.2434, -0.0244],
         [ 0.0000,  1.7781,  0.2031,  ..., -2.6404,  0.0670, -0.5903]]],
       device='cuda:0')
action =  tensor(7915, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.4971, -0.1573,  ..., -2.4664, -0.2434, -0.0244],
         [ 0.0000,  1.7781,  0.2031,  ..., -2.6404,  0.0670, -0.5903],
         [ 0.0000,  3.2868, -0.4003,  ..., -2.2969, -1.6328, -0.8635]]],
       device='cuda:0')
action =  tensor(118, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  1.7781,  0.2031,  ..., -2.6404,  0.0670, -0.5903],
         [ 0.0000,  3.2868, -0.4003,  ..., -2.2969, -1.6328, -0.8635],
         [ 0.0000,  2.6390, -0.3081,  ..., -1.6116, -1.0466, -0.0987]]],
       device='cuda:0')
action =  tensor(169, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.2868, -0.4003,  ..., -2.2969, -1.6328, -0.8635],
         [ 0.0000,  2.6390, -0.3081,  ..., -1.6116, -1.0466, -0.0987],
         [ 0.0000,  2.7996, -0.1077,  ...,  1.3571, -1.8760,  1.7177]]],
       device='cuda:0')
action =  tensor(776, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.6390, -0.3081,  ..., -1.6116, -1.0466, -0.0987],
         [ 0.0000,  2.7996, -0.1077,  ...,  1.3571, -1.8760,  1.7177],
         [ 0.0000,  3.3071, -0.0126,  ..., -1.4252,  0.3197,  0.4499]]],
       device='cuda:0')
action =  tensor(558, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.7996, -0.1077,  ...,  1.3571, -1.8760,  1.7177],
         [ 0.0000,  3.3071, -0.0126,  ..., -1.4252,  0.3197,  0.4499],
         [ 0.0000,  2.9281, -0.4658,  ..., -1.1601, -0.2560, -0.3472]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  3.3071, -0.0126,  ..., -1.4252,  0.3197,  0.4499],
         [ 0.0000,  2.9281, -0.4658,  ..., -1.1601, -0.2560, -0.3472],
         [ 0.0000, -0.0744,  0.0609,  ..., -3.9876,  0.8903,  0.8873]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.9281, -0.4658,  ..., -1.1601, -0.2560, -0.3472],
         [ 0.0000, -0.0744,  0.0609,  ..., -3.9876,  0.8903,  0.8873],
         [ 0.0000,  0.9056,  0.1343,  ..., -4.0651,  2.9619,  0.6831]]],
       device='cuda:0')
action =  tensor(1322, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000, -0.0744,  0.0609,  ..., -3.9876,  0.8903,  0.8873],
         [ 0.0000,  0.9056,  0.1343,  ..., -4.0651,  2.9619,  0.6831],
         [ 0.0000,  4.4500, -0.3143,  ..., -1.5690, -1.6911, -0.0121]]],
       device='cuda:0')
action =  tensor(381, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  0.9056,  0.1343,  ..., -4.0651,  2.9619,  0.6831],
         [ 0.0000,  4.4500, -0.3143,  ..., -1.5690, -1.6911, -0.0121],
         [ 0.0000,  2.3598, -0.0411,  ..., -1.6064,  0.8928,  1.8159]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  4.4500, -0.3143,  ..., -1.5690, -1.6911, -0.0121],
         [ 0.0000,  2.3598, -0.0411,  ..., -1.6064,  0.8928,  1.8159],
         [ 0.0000,  2.4132,  0.3722,  ..., -1.9516,  2.3281,  1.9812]]],
       device='cuda:0')
action =  tensor(3533, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.3598, -0.0411,  ..., -1.6064,  0.8928,  1.8159],
         [ 0.0000,  2.4132,  0.3722,  ..., -1.9516,  2.3281,  1.9812],
         [ 0.0000,  4.4518, -0.0272,  ..., -1.3117,  0.5028, -1.1983]]],
       device='cuda:0')
action =  tensor(1219, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.0000,  2.3614,  0.5242,  ..., -2.9460,  2.5879, -0.0654],
         [ 0.0000,  2.4879,  0.2427,  ..., -0.5994, -0.3524, -0.9791],
         [ 0.0000,  2.8408, -0.1127,  ..., -1.2080, -0.3715, -2.0895],
         ...,
         [ 0.0000,  2.4132,  0.3722,  ..., -1.9516,  2.3281,  1.9812],
         [ 0.0000,  4.4518, -0.0272,  ..., -1.3117,  0.5028, -1.1983],
         [ 0.0000,  4.3467, -0.3310,  ..., -0.5728, -0.1217, -0.7034]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  4.4518e+00, -2.7190e-02,  ..., -1.3117e+00,
           5.0283e-01, -1.1983e+00],
         [ 0.0000e+00,  4.3467e+00, -3.3100e-01,  ..., -5.7283e-01,
          -1.2166e-01, -7.0341e-01],
         [ 0.0000e+00,  4.4766e+00, -2.1107e-01,  ..., -3.9244e-01,
          -3.1879e-02,  3.6711e-03]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  4.3467e+00, -3.3100e-01,  ..., -5.7283e-01,
          -1.2166e-01, -7.0341e-01],
         [ 0.0000e+00,  4.4766e+00, -2.1107e-01,  ..., -3.9244e-01,
          -3.1879e-02,  3.6711e-03],
         [ 0.0000e+00,  1.3314e+01, -7.8158e-03,  ..., -1.5791e+00,
           5.4516e-01,  1.8787e-01]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  13
Interior Secretary Ken Salazar pledges to keep our boot on BP 's neck' to help those affected . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . BP says it will be Wednesday before trying a 'top kill' bid to plug the leak . President Obama arrives in Louisiana for his third visit to the region since the crisis began .
last_state =  tensor([ 0.0000e+00,  1.3314e+01, -7.8158e-03,  ..., -1.5791e+00,
         5.4516e-01,  1.8787e-01], device='cuda:0')
final_logits =  tensor([[[ 0.0000e+00,  2.3614e+00,  5.2421e-01,  ..., -2.9460e+00,
           2.5879e+00, -6.5375e-02],
         [ 0.0000e+00,  2.4879e+00,  2.4269e-01,  ..., -5.9940e-01,
          -3.5243e-01, -9.7910e-01],
         [ 0.0000e+00,  2.8408e+00, -1.1267e-01,  ..., -1.2080e+00,
          -3.7150e-01, -2.0895e+00],
         ...,
         [ 0.0000e+00,  4.3467e+00, -3.3100e-01,  ..., -5.7283e-01,
          -1.2166e-01, -7.0341e-01],
         [ 0.0000e+00,  4.4766e+00, -2.1107e-01,  ..., -3.9244e-01,
          -3.1879e-02,  3.6711e-03],
         [ 0.0000e+00,  1.3314e+01, -7.8158e-03,  ..., -1.5791e+00,
           5.4516e-01,  1.8787e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-1.9353], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1241], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2881], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1373], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8909], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2994], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1534], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4490], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1142], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0767], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1943], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6326], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9101], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9012], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1552], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4623], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6451], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4132], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1514], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1958], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0955], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1247], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6955], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1398], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1542], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2553], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4620], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0804], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0146], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3150], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0467], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5301], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0364], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3341], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1063], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0211], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1867], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0979], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1638], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5509], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5417], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7946], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0956], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.3099], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4169], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3492], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6199], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6213], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.8203], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1724], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6106], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3685], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9563], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1110], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1948], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1451], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4355], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4252], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1137], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2867], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4513], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3865], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0980], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.1441], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2528], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0464], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2018], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2560], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2620], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8140], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0872], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1888], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3205], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5184], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7269], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2171], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3752], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.8681], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1391], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0999], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0953], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5121], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-1.9353, -0.1241, -0.2881, -0.1373, -0.8909, -0.2994, -0.1534, -1.4490,
        -0.1142, -0.0767, -0.1943, -0.6326, -0.9101, -0.9012, -0.1552, -1.4623,
        -0.6451, -1.4132, -0.1514, -0.1958, -0.0955, -1.1247, -0.6955, -0.1398,
        -0.1542, -0.2553, -0.4620, -0.0804, -0.0146, -0.3150, -0.0467, -0.5301,
        -0.0364, -0.3341, -0.1063, -0.0211, -0.1867, -1.0979, -0.1638, -0.5509,
        -0.5417, -0.7946, -0.0956, -2.3099, -1.4169, -0.3492, -0.6199, -1.6213,
        -2.8203, -0.1724, -1.6106, -0.3685, -0.9563, -0.1110, -0.1948, -0.1451,
        -0.4355, -0.4252, -0.1137, -0.2867, -0.4513, -0.3865, -0.0980, -2.1441,
        -0.2528, -1.0464, -0.2018, -0.2560, -0.2620, -0.8140, -0.0872, -0.1888,
        -0.3205, -0.5184, -0.7269, -0.2171, -0.3752, -1.8681, -0.1391, -0.0999,
        -0.0953, -0.5121], device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,
         2.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,
         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,  4.,  5.,  5.,
         5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,  6.,
         7.,  7.,  8.,  8.,  9.,  9.,  9., 10., 11., 11., 11., 11., 11., 11.,
        11., 11., 11., 11., 12., 12., 12., 12., 13., 13., 13., 13.],
       device='cuda:0')
log_probs size =  torch.Size([82])
values size =  torch.Size([82])
returns size =  torch.Size([82])
advantages =  tensor([ 0.4727,  0.0525,  0.3618, -0.1683,  1.4310,  1.4037,  1.3655,  1.3664,
         1.3987,  1.3710,  2.1989,  2.6858,  2.5458,  2.6797,  2.3934,  2.4430,
         3.5823,  3.5250,  3.4325,  3.0866,  3.1536,  3.3617,  3.2611,  3.1235,
         3.0931,  2.4078,  2.8942,  2.7069,  2.8543,  3.0377,  3.0403,  3.0235,
         3.3638,  2.8503,  3.4420,  3.4330,  3.1981,  3.2407,  4.3273,  4.1252,
         5.0473,  5.3339,  5.4140,  4.9282,  5.9618,  6.0731,  5.8401,  5.7501,
         5.9571,  6.1089,  6.1442,  6.0369,  6.0507,  5.8894,  7.1985,  5.6620,
         6.8437,  6.6504,  8.3042,  8.3516,  9.4131,  9.0698,  9.3327, 10.9451,
        11.4827, 11.1325, 11.3276, 11.0688, 11.0649, 10.7658, 11.0226, 10.8862,
        11.2212, 11.0759, 12.3287, 12.0017, 12.2867, 12.6227, 13.3993, 13.6054,
        13.2643, 13.3199], device='cuda:0')
actor_loss =  tensor(3.1983, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(4018.6763, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  1
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         [-0.0373,  3.5096,  0.4620,  ...,  0.3616, -1.1619, -2.1670]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         [-0.0373,  3.5096,  0.4620,  ...,  0.3616, -1.1619, -2.1670],
         [-0.0255,  3.1567,  0.0978,  ..., -0.4480, -1.3702, -0.4386]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         [-0.0373,  3.5096,  0.4620,  ...,  0.3616, -1.1619, -2.1670],
         [-0.0255,  3.1567,  0.0978,  ..., -0.4480, -1.3702, -0.4386],
         [-0.0504,  0.9119, -0.3108,  ..., -1.1762,  0.6307, -2.0847]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0255,  3.1567,  0.0978,  ..., -0.4480, -1.3702, -0.4386],
         [-0.0504,  0.9119, -0.3108,  ..., -1.1762,  0.6307, -2.0847],
         [-0.0227,  3.8747,  0.3548,  ..., -2.2270,  0.7985, -2.2318]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0504,  0.9119, -0.3108,  ..., -1.1762,  0.6307, -2.0847],
         [-0.0227,  3.8747,  0.3548,  ..., -2.2270,  0.7985, -2.2318],
         [-0.0130,  2.3475,  0.4319,  ..., -0.8183, -1.0269, -0.3949]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0227,  3.8747,  0.3548,  ..., -2.2270,  0.7985, -2.2318],
         [-0.0130,  2.3475,  0.4319,  ..., -0.8183, -1.0269, -0.3949],
         [-0.0319,  2.4241, -0.1078,  ..., -0.1644,  1.5075, -1.1441]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0130,  2.3475,  0.4319,  ..., -0.8183, -1.0269, -0.3949],
         [-0.0319,  2.4241, -0.1078,  ..., -0.1644,  1.5075, -1.1441],
         [-0.0198,  2.3779,  0.6547,  ..., -0.2687,  1.8991, -1.8201]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0319,  2.4241, -0.1078,  ..., -0.1644,  1.5075, -1.1441],
         [-0.0198,  2.3779,  0.6547,  ..., -0.2687,  1.8991, -1.8201],
         [-0.0330,  2.9112,  0.6689,  ...,  0.7924,  1.1019, -1.6872]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0198,  2.3779,  0.6547,  ..., -0.2687,  1.8991, -1.8201],
         [-0.0330,  2.9112,  0.6689,  ...,  0.7924,  1.1019, -1.6872],
         [-0.0195,  3.3170,  0.0802,  ..., -1.1634, -1.1179, -0.5332]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0330,  2.9112,  0.6689,  ...,  0.7924,  1.1019, -1.6872],
         [-0.0195,  3.3170,  0.0802,  ..., -1.1634, -1.1179, -0.5332],
         [-0.0418,  2.6302, -0.2081,  ..., -0.4039,  0.7088, -1.0422]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0195,  3.3170,  0.0802,  ..., -1.1634, -1.1179, -0.5332],
         [-0.0418,  2.6302, -0.2081,  ..., -0.4039,  0.7088, -1.0422],
         [-0.0237,  3.9924,  0.2590,  ..., -1.0505, -0.9997, -3.4013]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0418,  2.6302, -0.2081,  ..., -0.4039,  0.7088, -1.0422],
         [-0.0237,  3.9924,  0.2590,  ..., -1.0505, -0.9996, -3.4013],
         [-0.0169,  3.6192,  0.4922,  ..., -1.5156, -0.7817, -2.3523]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0237,  3.9924,  0.2590,  ..., -1.0505, -0.9996, -3.4013],
         [-0.0169,  3.6192,  0.4922,  ..., -1.5156, -0.7817, -2.3523],
         [-0.0350,  3.2136, -0.1035,  ..., -0.3198,  0.1926, -0.7608]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0169,  3.6192,  0.4922,  ..., -1.5156, -0.7817, -2.3523],
         [-0.0350,  3.2136, -0.1035,  ..., -0.3198,  0.1926, -0.7608],
         [-0.0458,  3.2776,  0.2024,  ...,  0.4640, -1.1495, -2.7012]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0350,  3.2136, -0.1035,  ..., -0.3198,  0.1926, -0.7608],
         [-0.0458,  3.2776,  0.2024,  ...,  0.4640, -1.1495, -2.7012],
         [-0.0314,  4.5311,  0.6346,  ..., -1.2917,  0.0183, -0.6361]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0458,  3.2776,  0.2024,  ...,  0.4640, -1.1495, -2.7012],
         [-0.0314,  4.5311,  0.6346,  ..., -1.2917,  0.0183, -0.6361],
         [-0.0230,  3.5261, -0.1520,  ..., -1.2062, -1.6206, -0.7061]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0314,  4.5311,  0.6346,  ..., -1.2917,  0.0183, -0.6361],
         [-0.0230,  3.5261, -0.1520,  ..., -1.2062, -1.6206, -0.7061],
         [-0.0498,  3.0366, -0.3933,  ..., -0.8248, -0.3076, -1.2964]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0230,  3.5261, -0.1520,  ..., -1.2062, -1.6206, -0.7061],
         [-0.0498,  3.0366, -0.3933,  ..., -0.8248, -0.3076, -1.2964],
         [-0.0295,  4.3395,  0.1477,  ..., -1.0707, -2.4217, -4.7699]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0498,  3.0366, -0.3933,  ..., -0.8248, -0.3076, -1.2964],
         [-0.0295,  4.3395,  0.1477,  ..., -1.0707, -2.4217, -4.7699],
         [-0.0193,  4.0246,  0.3665,  ..., -1.5363, -1.5308, -2.3905]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0295,  4.3395,  0.1477,  ..., -1.0707, -2.4217, -4.7699],
         [-0.0193,  4.0246,  0.3665,  ..., -1.5363, -1.5308, -2.3905],
         [-0.0368,  3.4595, -0.2066,  ..., -0.2865, -0.4390, -1.0818]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0193,  4.0246,  0.3665,  ..., -1.5363, -1.5308, -2.3905],
         [-0.0368,  3.4595, -0.2066,  ..., -0.2865, -0.4390, -1.0818],
         [-0.0508,  4.1220, -0.0817,  ...,  0.4962, -1.7729, -3.1724]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0368,  3.4595, -0.2066,  ..., -0.2865, -0.4390, -1.0818],
         [-0.0508,  4.1220, -0.0817,  ...,  0.4962, -1.7729, -3.1724],
         [-0.0364,  5.1100,  0.3987,  ..., -1.7932,  0.0503, -0.5074]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0508,  4.1220, -0.0817,  ...,  0.4962, -1.7729, -3.1724],
         [-0.0364,  5.1100,  0.3987,  ..., -1.7932,  0.0503, -0.5074],
         [-0.0577,  7.2835,  0.0465,  ..., -2.8362,  2.3376, -1.7728]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0364,  5.1100,  0.3987,  ..., -1.7932,  0.0503, -0.5074],
         [-0.0577,  7.2835,  0.0465,  ..., -2.8362,  2.3376, -1.7728],
         [-0.0685,  2.2827, -0.3118,  ..., -1.1961, -1.0214, -1.3147]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0577,  7.2835,  0.0465,  ..., -2.8362,  2.3376, -1.7728],
         [-0.0685,  2.2827, -0.3118,  ..., -1.1961, -1.0214, -1.3147],
         [-0.0872,  0.6766, -0.5604,  ..., -3.3050,  1.5740, -0.1148]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0685,  2.2827, -0.3118,  ..., -1.1961, -1.0214, -1.3147],
         [-0.0872,  0.6766, -0.5604,  ..., -3.3050,  1.5740, -0.1148],
         [-0.0464,  3.0209, -0.3740,  ...,  0.4616,  0.3999,  1.6630]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0872,  0.6766, -0.5604,  ..., -3.3050,  1.5740, -0.1148],
         [-0.0464,  3.0209, -0.3740,  ...,  0.4616,  0.3999,  1.6630],
         [-0.0621,  0.5763,  0.0118,  ..., -1.7174,  1.5064,  0.1175]]],
       device='cuda:0')
action =  tensor(129, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0464,  3.0209, -0.3740,  ...,  0.4616,  0.3999,  1.6630],
         [-0.0621,  0.5763,  0.0118,  ..., -1.7174,  1.5064,  0.1175],
         [-0.0671,  1.5056,  0.1321,  ..., -2.5239,  0.4847, -2.6875]]],
       device='cuda:0')
action =  tensor(1900, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0621,  0.5763,  0.0118,  ..., -1.7174,  1.5064,  0.1175],
         [-0.0671,  1.5056,  0.1321,  ..., -2.5239,  0.4847, -2.6875],
         [-0.0599,  0.1672, -0.3014,  ...,  0.0775, -1.2611, -1.1042]]],
       device='cuda:0')
action =  tensor(269, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0671,  1.5056,  0.1321,  ..., -2.5239,  0.4847, -2.6875],
         [-0.0599,  0.1672, -0.3014,  ...,  0.0775, -1.2611, -1.1042],
         [-0.0781,  1.2102, -0.1208,  ..., -1.5581,  0.2221, -3.0133]]],
       device='cuda:0')
action =  tensor(847, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0599,  0.1672, -0.3014,  ...,  0.0775, -1.2611, -1.1042],
         [-0.0781,  1.2102, -0.1208,  ..., -1.5581,  0.2221, -3.0133],
         [-0.0743,  2.1766, -0.2414,  ..., -0.1191, -0.5567, -1.2561]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0781,  1.2102, -0.1208,  ..., -1.5581,  0.2221, -3.0133],
         [-0.0743,  2.1766, -0.2414,  ..., -0.1191, -0.5567, -1.2561],
         [-0.0682,  1.5452,  0.1595,  ...,  1.0369,  0.3950, -0.4075]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0743,  2.1766, -0.2414,  ..., -0.1191, -0.5567, -1.2561],
         [-0.0682,  1.5452,  0.1595,  ...,  1.0369,  0.3950, -0.4075],
         [-0.0298,  1.5510,  1.7081,  ...,  2.3167,  0.8765,  0.4626]]],
       device='cuda:0')
action =  tensor(5891, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0682,  1.5452,  0.1595,  ...,  1.0369,  0.3950, -0.4075],
         [-0.0298,  1.5510,  1.7081,  ...,  2.3167,  0.8765,  0.4626],
         [-0.0445,  3.9869,  0.3268,  ..., -1.0911, -0.2478, -1.1826]]],
       device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  4
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0298,  1.5510,  1.7081,  ...,  2.3167,  0.8765,  0.4626],
         [-0.0445,  3.9869,  0.3268,  ..., -1.0911, -0.2478, -1.1826],
         [-0.0415,  2.0549, -0.1470,  ..., -0.3180,  1.2291, -0.8233]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0445,  3.9869,  0.3268,  ..., -1.0911, -0.2478, -1.1826],
         [-0.0415,  2.0549, -0.1470,  ..., -0.3180,  1.2291, -0.8233],
         [-0.0701,  4.0106,  0.0517,  ...,  1.5261,  2.2917, -2.9783]]],
       device='cuda:0')
action =  tensor(5469, device='cuda:0')
reward =  4
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0415,  2.0549, -0.1470,  ..., -0.3180,  1.2291, -0.8233],
         [-0.0701,  4.0106,  0.0517,  ...,  1.5261,  2.2917, -2.9783],
         [-0.0650,  3.4885, -0.5466,  ..., -0.9601,  0.4296, -1.4163]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  4
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0701,  4.0106,  0.0517,  ...,  1.5261,  2.2917, -2.9783],
         [-0.0650,  3.4885, -0.5466,  ..., -0.9601,  0.4296, -1.4163],
         [-0.0541,  3.1245,  0.2841,  ..., -0.4075,  0.7126, -1.9006]]],
       device='cuda:0')
action =  tensor(4800, device='cuda:0')
reward =  5
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0650,  3.4885, -0.5466,  ..., -0.9601,  0.4296, -1.4163],
         [-0.0541,  3.1245,  0.2841,  ..., -0.4075,  0.7126, -1.9006],
         [-0.0708,  3.1994, -0.3465,  ..., -0.0650, -0.2649,  0.8832]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  5
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0541,  3.1245,  0.2841,  ..., -0.4075,  0.7126, -1.9006],
         [-0.0708,  3.1994, -0.3465,  ..., -0.0650, -0.2649,  0.8832],
         [-0.0669,  2.9282,  0.1130,  ...,  0.1241,  1.1126,  1.6905]]],
       device='cuda:0')
action =  tensor(8186, device='cuda:0')
reward =  6
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0708,  3.1994, -0.3465,  ..., -0.0650, -0.2649,  0.8832],
         [-0.0669,  2.9282,  0.1130,  ...,  0.1241,  1.1126,  1.6905],
         [-0.0617,  1.8138, -0.5106,  ...,  0.5121,  0.0235, -0.7052]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  6
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0669,  2.9282,  0.1130,  ...,  0.1241,  1.1126,  1.6905],
         [-0.0617,  1.8138, -0.5106,  ...,  0.5121,  0.0235, -0.7052],
         [-0.0249,  3.7030, -0.2805,  ..., -0.2533,  0.0851, -0.0828]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  6
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-6.1650e-02,  1.8138e+00, -5.1059e-01,  ...,  5.1207e-01,
           2.3534e-02, -7.0516e-01],
         [-2.4881e-02,  3.7030e+00, -2.8051e-01,  ..., -2.5326e-01,
           8.5135e-02, -8.2831e-02],
         [-5.8181e-02,  9.9838e+00,  2.0081e-01,  ..., -9.7476e-01,
           2.1986e+00,  6.3884e-01]]], device='cuda:0')
action =  tensor(1276, device='cuda:0')
reward =  7
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-2.4881e-02,  3.7030e+00, -2.8051e-01,  ..., -2.5326e-01,
           8.5135e-02, -8.2831e-02],
         [-5.8181e-02,  9.9838e+00,  2.0081e-01,  ..., -9.7476e-01,
           2.1986e+00,  6.3884e-01],
         [-4.6726e-02,  4.1893e+00,  3.7611e-03,  ..., -1.9745e+00,
           5.1715e-01, -3.9707e-01]]], device='cuda:0')
action =  tensor(3531, device='cuda:0')
reward =  8
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-5.8181e-02,  9.9838e+00,  2.0081e-01,  ..., -9.7476e-01,
           2.1986e+00,  6.3884e-01],
         [-4.6726e-02,  4.1893e+00,  3.7611e-03,  ..., -1.9745e+00,
           5.1715e-01, -3.9707e-01],
         [-5.7434e-02,  3.7082e+00, -1.9433e-01,  ..., -4.3815e+00,
           1.1449e-02, -7.3287e-01]]], device='cuda:0')
action =  tensor(8350, device='cuda:0')
reward =  8
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-4.6726e-02,  4.1893e+00,  3.7611e-03,  ..., -1.9745e+00,
           5.1715e-01, -3.9707e-01],
         [-5.7434e-02,  3.7082e+00, -1.9433e-01,  ..., -4.3815e+00,
           1.1449e-02, -7.3287e-01],
         [-5.3305e-02,  1.9575e+00, -1.9404e-01,  ..., -2.4199e+00,
          -2.1845e-01,  2.7818e-03]]], device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  8
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-5.7434e-02,  3.7082e+00, -1.9433e-01,  ..., -4.3815e+00,
           1.1449e-02, -7.3287e-01],
         [-5.3305e-02,  1.9575e+00, -1.9404e-01,  ..., -2.4199e+00,
          -2.1845e-01,  2.7818e-03],
         [-5.4456e-02,  1.5476e+00,  1.5728e-01,  ..., -2.7599e+00,
           1.1821e-01, -5.2143e-01]]], device='cuda:0')
action =  tensor(7915, device='cuda:0')
reward =  8
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-5.3305e-02,  1.9575e+00, -1.9404e-01,  ..., -2.4199e+00,
          -2.1845e-01,  2.7818e-03],
         [-5.4456e-02,  1.5476e+00,  1.5728e-01,  ..., -2.7599e+00,
           1.1821e-01, -5.2143e-01],
         [-5.8447e-02,  2.9422e+00, -4.1007e-01,  ..., -2.3323e+00,
          -1.9018e+00, -6.4104e-01]]], device='cuda:0')
action =  tensor(118, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0545,  1.5476,  0.1573,  ..., -2.7599,  0.1182, -0.5214],
         [-0.0584,  2.9422, -0.4101,  ..., -2.3323, -1.9018, -0.6410],
         [-0.0620,  2.0983, -0.3522,  ..., -1.9269, -1.2782,  0.0413]]],
       device='cuda:0')
action =  tensor(169, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0584,  2.9422, -0.4101,  ..., -2.3323, -1.9018, -0.6410],
         [-0.0620,  2.0983, -0.3522,  ..., -1.9269, -1.2782,  0.0413],
         [-0.0462,  2.4151, -0.1620,  ...,  1.0037, -2.1991,  1.7693]]],
       device='cuda:0')
action =  tensor(776, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0620,  2.0983, -0.3522,  ..., -1.9269, -1.2782,  0.0413],
         [-0.0462,  2.4151, -0.1620,  ...,  1.0037, -2.1991,  1.7693],
         [-0.0580,  3.1782, -0.0683,  ..., -1.6069,  0.0453,  0.5974]]],
       device='cuda:0')
action =  tensor(558, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0462,  2.4151, -0.1620,  ...,  1.0037, -2.1991,  1.7693],
         [-0.0580,  3.1782, -0.0683,  ..., -1.6069,  0.0453,  0.5974],
         [-0.0612,  2.8323, -0.5152,  ..., -1.3607, -0.4451, -0.5376]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0580,  3.1782, -0.0683,  ..., -1.6069,  0.0453,  0.5974],
         [-0.0612,  2.8323, -0.5152,  ..., -1.3607, -0.4451, -0.5376],
         [-0.0793, -0.5610,  0.0045,  ..., -4.1863,  0.6919,  0.9838]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0612,  2.8323, -0.5152,  ..., -1.3607, -0.4451, -0.5376],
         [-0.0793, -0.5610,  0.0045,  ..., -4.1863,  0.6919,  0.9838],
         [-0.0695,  0.9177,  0.0290,  ..., -4.2071,  2.7067,  0.5551]]],
       device='cuda:0')
action =  tensor(1322, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0793, -0.5610,  0.0045,  ..., -4.1863,  0.6919,  0.9838],
         [-0.0695,  0.9177,  0.0290,  ..., -4.2071,  2.7067,  0.5551],
         [-0.0599,  4.0389, -0.3400,  ..., -1.5639, -1.8630, -0.0882]]],
       device='cuda:0')
action =  tensor(381, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0695,  0.9177,  0.0290,  ..., -4.2071,  2.7067,  0.5551],
         [-0.0599,  4.0389, -0.3400,  ..., -1.5639, -1.8630, -0.0882],
         [-0.0695,  2.0067, -0.1223,  ..., -1.5853,  0.8228,  1.7477]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0599,  4.0389, -0.3400,  ..., -1.5639, -1.8630, -0.0882],
         [-0.0695,  2.0067, -0.1223,  ..., -1.5853,  0.8228,  1.7477],
         [-0.0620,  2.0957,  0.2924,  ..., -1.9156,  2.1045,  1.7932]]],
       device='cuda:0')
action =  tensor(3533, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0695,  2.0067, -0.1223,  ..., -1.5853,  0.8228,  1.7477],
         [-0.0620,  2.0957,  0.2924,  ..., -1.9156,  2.1045,  1.7932],
         [-0.0542,  3.7802, -0.0890,  ..., -1.4647,  0.4252, -1.1633]]],
       device='cuda:0')
action =  tensor(1219, device='cuda:0')
reward =  10
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0620,  2.0957,  0.2924,  ..., -1.9156,  2.1045,  1.7932],
         [-0.0542,  3.7802, -0.0890,  ..., -1.4647,  0.4252, -1.1633],
         [-0.0515,  4.0266, -0.3772,  ..., -0.6316, -0.2323, -0.7433]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  10
logits =  tensor([[[-0.0496,  2.3849,  0.4930,  ..., -3.0198,  2.5602, -0.0267],
         [-0.0599,  2.2241, -0.2402,  ..., -2.5819, -0.7996, -1.2290],
         [-0.0644,  1.5753,  0.0092,  ..., -2.0775,  3.0344, -2.1061],
         ...,
         [-0.0542,  3.7802, -0.0890,  ..., -1.4647,  0.4252, -1.1633],
         [-0.0515,  4.0266, -0.3772,  ..., -0.6316, -0.2323, -0.7433],
         [-0.0244,  4.4823, -0.2363,  ..., -0.4436, -0.1074, -0.0484]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  10
logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-5.1482e-02,  4.0266e+00, -3.7716e-01,  ..., -6.3163e-01,
          -2.3227e-01, -7.4330e-01],
         [-2.4430e-02,  4.4823e+00, -2.3635e-01,  ..., -4.4365e-01,
          -1.0744e-01, -4.8391e-02],
         [-5.4068e-02,  1.3276e+01,  8.0863e-03,  ..., -1.4665e+00,
           6.1621e-01, -9.4735e-02]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  10
BP pledges $ 500m -LRB- #346m -RRB- 346m -RRB- . BP says it will be Wednesday before trying a 'top kill' bid to plug the leak . President Obama arrives in Louisiana for his third visit to the region since the crisis began .
last_state =  tensor([-5.4068e-02,  1.3276e+01,  8.0863e-03,  ..., -1.4665e+00,
         6.1621e-01, -9.4735e-02], device='cuda:0')
final_logits =  tensor([[[-4.9601e-02,  2.3849e+00,  4.9296e-01,  ..., -3.0198e+00,
           2.5602e+00, -2.6651e-02],
         [-5.9892e-02,  2.2241e+00, -2.4024e-01,  ..., -2.5819e+00,
          -7.9957e-01, -1.2290e+00],
         [-6.4442e-02,  1.5753e+00,  9.2286e-03,  ..., -2.0775e+00,
           3.0344e+00, -2.1061e+00],
         ...,
         [-5.1482e-02,  4.0266e+00, -3.7716e-01,  ..., -6.3163e-01,
          -2.3227e-01, -7.4330e-01],
         [-2.4430e-02,  4.4823e+00, -2.3635e-01,  ..., -4.4365e-01,
          -1.0744e-01, -4.8391e-02],
         [-5.4068e-02,  1.3276e+01,  8.0863e-03,  ..., -1.4665e+00,
           6.1621e-01, -9.4735e-02]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-1.7644], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2754], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1033], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1250], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1966], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4483], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0597], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0152], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3245], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0508], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4508], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0363], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3677], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1042], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0181], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1826], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3125], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0966], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0543], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2000], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1199], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0105], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1702], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2695], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2036], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3986], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2891], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3360], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8633], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8144], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1463], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1903], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7638], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3694], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9432], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0950], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1665], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1504], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2696], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4142], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1036], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3051], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4305], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2798], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0917], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4439], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2472], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2921], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1870], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2200], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2854], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6788], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0786], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1654], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4253], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5501], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4621], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2554], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3961], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3547], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1146], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0894], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0919], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5697], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-1.7644, -0.2754, -0.1033, -0.1250, -0.1966, -0.4483, -0.0597, -0.0152,
        -0.3245, -0.0508, -0.4508, -0.0363, -0.3677, -0.1042, -0.0181, -0.1826,
        -1.3125, -0.0966, -0.0543, -0.2000, -0.1199, -0.0105, -0.1702, -1.2695,
        -0.2036, -1.3986, -1.2891, -0.3360, -0.8633, -0.8144, -1.1463, -0.1903,
        -1.7638, -0.3694, -0.9432, -0.0950, -0.1665, -0.1504, -0.2696, -0.4142,
        -0.1036, -0.3051, -0.4305, -0.2798, -0.0917, -1.4439, -0.2472, -1.2921,
        -0.1870, -0.2200, -0.2854, -0.6788, -0.0786, -0.1654, -0.4253, -0.5501,
        -0.4621, -0.2554, -0.3961, -1.3547, -0.1146, -0.0894, -0.0919, -0.5697],
       device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([ 1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,
         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,  3.,  4.,  4.,  5.,  5.,
         6.,  6.,  6.,  7.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         9.,  9.,  9.,  9., 10., 10., 10., 10.], device='cuda:0')
log_probs size =  torch.Size([64])
values size =  torch.Size([64])
returns size =  torch.Size([64])
advantages =  tensor([-320.5066,  -61.8523, -182.7013, -300.2883, -289.4471, -343.7104,
        -236.0924, -328.5565, -403.1449, -250.9995, -310.5028, -270.3833,
        -345.3937, -266.4134, -298.8039, -200.7073, -296.4149, -228.1013,
        -345.7494,  -69.0921, -363.2744, -394.8703, -389.7677, -329.2841,
        -277.5601, -441.2362, -199.4394, -334.9923,  -64.1297, -365.9561,
        -356.4792, -408.6618, -367.0482, -337.6376, -313.3344, -314.5403,
        -524.4199, -473.3309, -504.5213, -192.3351, -495.0843, -252.9443,
        -245.8990, -402.9374, -386.3040, -221.2679, -157.6727, -458.8041,
        -233.0671, -246.7614, -319.9812, -322.6167, -200.3047, -289.2755,
        -381.3221, -271.8803, -259.2172, -361.9923, -425.3637, -166.3106,
        -291.2031, -429.7533, -437.7926, -321.2025], device='cuda:0')
actor_loss =  tensor(-136.0625, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(6816735., device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         [-0.0077,  4.1715,  0.0541,  ...,  0.7475,  0.2315, -1.0836]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2297e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         [-7.6949e-03,  4.1715e+00,  5.4090e-02,  ...,  7.4754e-01,
           2.3154e-01, -1.0836e+00],
         [-1.3225e-02,  2.4262e+00, -1.4069e-03,  ..., -1.7105e+00,
          -1.9229e+00, -1.8523e+00]]], device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         [-7.6949e-03,  4.1715e+00,  5.4090e-02,  ...,  7.4754e-01,
           2.3154e-01, -1.0836e+00],
         [-1.3225e-02,  2.4262e+00, -1.4067e-03,  ..., -1.7105e+00,
          -1.9229e+00, -1.8523e+00],
         [-1.3795e-02,  3.2292e+00, -2.4764e-01,  ..., -1.8261e+00,
           8.7050e-01, -1.0792e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.3225e-02,  2.4262e+00, -1.4067e-03,  ..., -1.7105e+00,
          -1.9229e+00, -1.8523e+00],
         [-1.3795e-02,  3.2292e+00, -2.4764e-01,  ..., -1.8261e+00,
           8.7050e-01, -1.0792e+00],
         [-8.0498e-03,  3.1717e+00,  4.3386e-01,  ..., -2.2700e+00,
          -1.6488e-01, -2.5902e-01]]], device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0138,  3.2292, -0.2476,  ..., -1.8261,  0.8705, -1.0792],
         [-0.0080,  3.1717,  0.4339,  ..., -2.2700, -0.1649, -0.2590],
         [-0.0227,  0.6761, -0.0099,  ..., -1.7001,  0.6661, -3.0702]]],
       device='cuda:0')
action =  tensor(150, device='cuda:0')
reward =  1
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0080,  3.1717,  0.4339,  ..., -2.2700, -0.1649, -0.2590],
         [-0.0227,  0.6761, -0.0099,  ..., -1.7001,  0.6661, -3.0702],
         [-0.0093,  2.7520,  0.3476,  ..., -0.7084, -1.3470, -2.2070]]],
       device='cuda:0')
action =  tensor(5407, device='cuda:0')
reward =  1
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0227,  0.6761, -0.0099,  ..., -1.7001,  0.6661, -3.0702],
         [-0.0093,  2.7520,  0.3476,  ..., -0.7084, -1.3470, -2.2070],
         [-0.0076,  2.4104, -0.0608,  ..., -2.4098, -0.2813, -1.2894]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0093,  2.7520,  0.3476,  ..., -0.7084, -1.3470, -2.2070],
         [-0.0076,  2.4104, -0.0608,  ..., -2.4098, -0.2813, -1.2894],
         [-0.0192,  1.4784, -0.0541,  ..., -2.8512,  0.4879, -2.2675]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0076,  2.4104, -0.0608,  ..., -2.4098, -0.2813, -1.2894],
         [-0.0192,  1.4784, -0.0541,  ..., -2.8512,  0.4879, -2.2675],
         [-0.0183,  2.3851, -0.3587,  ...,  0.4726, -1.2661, -1.8302]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  2
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0192,  1.4784, -0.0541,  ..., -2.8512,  0.4879, -2.2675],
         [-0.0183,  2.3851, -0.3587,  ...,  0.4726, -1.2661, -1.8302],
         [-0.0041,  2.5913,  0.8970,  ...,  1.5905, -0.6620,  0.0099]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  2
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2296e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.8312e-02,  2.3851e+00, -3.5868e-01,  ...,  4.7263e-01,
          -1.2661e+00, -1.8302e+00],
         [-4.1421e-03,  2.5913e+00,  8.9696e-01,  ...,  1.5905e+00,
          -6.6201e-01,  9.9416e-03],
         [-8.5108e-03,  4.7978e+00,  2.2711e-01,  ...,  6.9927e-01,
          -6.7504e-01, -1.5196e+00]]], device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  2
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2297e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-4.1421e-03,  2.5913e+00,  8.9696e-01,  ...,  1.5905e+00,
          -6.6201e-01,  9.9442e-03],
         [-8.5108e-03,  4.7978e+00,  2.2711e-01,  ...,  6.9927e-01,
          -6.7505e-01, -1.5196e+00],
         [-1.0045e-02,  2.5811e+00, -3.6642e-01,  ..., -2.1090e+00,
           1.3105e+00, -2.8789e+00]]], device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  2
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2297e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-8.5108e-03,  4.7978e+00,  2.2711e-01,  ...,  6.9927e-01,
          -6.7505e-01, -1.5196e+00],
         [-1.0045e-02,  2.5811e+00, -3.6642e-01,  ..., -2.1090e+00,
           1.3105e+00, -2.8789e+00],
         [-1.4841e-02,  8.5226e+00, -5.6764e-01,  ..., -9.9033e-01,
           5.0742e-01, -4.0159e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  2
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.0045e-02,  2.5811e+00, -3.6642e-01,  ..., -2.1090e+00,
           1.3105e+00, -2.8789e+00],
         [-1.4841e-02,  8.5226e+00, -5.6764e-01,  ..., -9.9033e-01,
           5.0742e-01, -4.0159e+00],
         [-2.5170e-02, -4.8348e-01,  4.0740e-01,  ..., -2.8603e+00,
           1.4493e+00, -8.2042e-01]]], device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.4841e-02,  8.5226e+00, -5.6764e-01,  ..., -9.9033e-01,
           5.0742e-01, -4.0159e+00],
         [-2.5170e-02, -4.8348e-01,  4.0740e-01,  ..., -2.8603e+00,
           1.4493e+00, -8.2042e-01],
         [-3.0858e-02,  1.0372e+00,  1.3432e-01,  ..., -4.0087e+00,
           1.6325e+00, -6.6865e-02]]], device='cuda:0')
action =  tensor(274, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0252, -0.4835,  0.4074,  ..., -2.8603,  1.4493, -0.8204],
         [-0.0309,  1.0372,  0.1343,  ..., -4.0087,  1.6325, -0.0669],
         [-0.0218,  3.1018,  0.6607,  ..., -2.5290,  0.4832,  0.1003]]],
       device='cuda:0')
action =  tensor(2790, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0309,  1.0372,  0.1343,  ..., -4.0087,  1.6325, -0.0669],
         [-0.0218,  3.1018,  0.6607,  ..., -2.5290,  0.4832,  0.1003],
         [-0.0153,  3.3966, -0.3987,  ..., -1.0254, -0.1107, -0.1927]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0218,  3.1018,  0.6607,  ..., -2.5290,  0.4832,  0.1003],
         [-0.0153,  3.3966, -0.3987,  ..., -1.0254, -0.1107, -0.1927],
         [-0.0066,  3.7636, -0.2228,  ..., -0.2688, -0.0403, -0.0932]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.5272e-02,  3.3966e+00, -3.9873e-01,  ..., -1.0254e+00,
          -1.1073e-01, -1.9272e-01],
         [-6.6187e-03,  3.7636e+00, -2.2285e-01,  ..., -2.6877e-01,
          -4.0349e-02, -9.3151e-02],
         [-1.1270e-02,  8.7545e+00,  3.4639e-01,  ..., -1.5006e+00,
           1.7903e+00, -2.7296e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-6.6187e-03,  3.7636e+00, -2.2285e-01,  ..., -2.6877e-01,
          -4.0349e-02, -9.3151e-02],
         [-1.1270e-02,  8.7545e+00,  3.4639e-01,  ..., -1.5006e+00,
           1.7903e+00, -2.7296e-01],
         [-1.5694e-02,  2.2655e+00, -2.0587e-01,  ..., -1.8951e+00,
          -7.1058e-01, -1.1047e+00]]], device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.1270e-02,  8.7545e+00,  3.4639e-01,  ..., -1.5006e+00,
           1.7903e+00, -2.7296e-01],
         [-1.5694e-02,  2.2655e+00, -2.0587e-01,  ..., -1.8951e+00,
          -7.1058e-01, -1.1047e+00],
         [-1.4396e-02,  1.6106e+00,  4.3717e-02,  ..., -1.7925e+00,
           3.1992e+00, -1.9829e+00]]], device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0157,  2.2655, -0.2059,  ..., -1.8951, -0.7106, -1.1047],
         [-0.0144,  1.6106,  0.0437,  ..., -1.7925,  3.1992, -1.9829],
         [-0.0042,  3.9448,  0.4050,  ...,  0.2706, -0.8564, -2.1969]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0144,  1.6106,  0.0437,  ..., -1.7925,  3.1992, -1.9829],
         [-0.0042,  3.9448,  0.4050,  ...,  0.2706, -0.8564, -2.1969],
         [-0.0046,  3.4795,  0.1417,  ..., -0.2447, -1.0174, -0.5002]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-4.2498e-03,  3.9448e+00,  4.0495e-01,  ...,  2.7058e-01,
          -8.5641e-01, -2.1969e+00],
         [-4.5552e-03,  3.4795e+00,  1.4168e-01,  ..., -2.4467e-01,
          -1.0174e+00, -5.0022e-01],
         [-1.5736e-03,  1.4610e+00, -2.2948e-01,  ..., -1.1635e+00,
           9.1177e-01, -2.0048e+00]]], device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-4.5552e-03,  3.4795e+00,  1.4168e-01,  ..., -2.4467e-01,
          -1.0174e+00, -5.0022e-01],
         [-1.5736e-03,  1.4610e+00, -2.2948e-01,  ..., -1.1635e+00,
           9.1177e-01, -2.0048e+00],
         [ 1.0077e-03,  3.7529e+00,  3.5994e-01,  ..., -2.1218e+00,
           9.7027e-01, -2.3716e+00]]], device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.5736e-03,  1.4610e+00, -2.2948e-01,  ..., -1.1635e+00,
           9.1177e-01, -2.0048e+00],
         [ 1.0077e-03,  3.7529e+00,  3.5994e-01,  ..., -2.1218e+00,
           9.7027e-01, -2.3716e+00],
         [ 7.0342e-03,  2.3823e+00,  4.8786e-01,  ..., -9.7030e-01,
          -1.0160e+00, -4.2278e-01]]], device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 1.0077e-03,  3.7529e+00,  3.5994e-01,  ..., -2.1218e+00,
           9.7027e-01, -2.3716e+00],
         [ 7.0342e-03,  2.3823e+00,  4.8786e-01,  ..., -9.7030e-01,
          -1.0160e+00, -4.2278e-01],
         [ 4.4448e-03,  2.6079e+00, -5.5472e-02,  ..., -1.8508e-01,
           1.6941e+00, -9.0692e-01]]], device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [ 0.0070,  2.3823,  0.4879,  ..., -0.9703, -1.0160, -0.4228],
         [ 0.0044,  2.6079, -0.0555,  ..., -0.1851,  1.6941, -0.9069],
         [ 0.0116,  2.4822,  0.4438,  ..., -0.5530,  2.2988, -1.7794]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 4.4448e-03,  2.6079e+00, -5.5472e-02,  ..., -1.8508e-01,
           1.6941e+00, -9.0692e-01],
         [ 1.1558e-02,  2.4822e+00,  4.4375e-01,  ..., -5.5295e-01,
           2.2988e+00, -1.7794e+00],
         [-2.2507e-04,  2.8372e+00,  6.6673e-01,  ...,  5.0228e-01,
           1.0556e+00, -2.0051e+00]]], device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 1.1558e-02,  2.4822e+00,  4.4376e-01,  ..., -5.5295e-01,
           2.2988e+00, -1.7794e+00],
         [-2.2506e-04,  2.8372e+00,  6.6673e-01,  ...,  5.0228e-01,
           1.0556e+00, -2.0051e+00],
         [ 2.9546e-04,  3.6275e+00,  2.0682e-02,  ..., -1.2359e+00,
          -9.4481e-01, -6.6604e-01]]], device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-2.2506e-04,  2.8372e+00,  6.6673e-01,  ...,  5.0228e-01,
           1.0556e+00, -2.0051e+00],
         [ 2.9546e-04,  3.6275e+00,  2.0682e-02,  ..., -1.2359e+00,
          -9.4481e-01, -6.6604e-01],
         [ 1.0331e-03,  2.6581e+00, -1.8820e-01,  ..., -1.1099e-01,
           9.4890e-01, -1.3306e+00]]], device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 2.9546e-04,  3.6275e+00,  2.0682e-02,  ..., -1.2359e+00,
          -9.4481e-01, -6.6604e-01],
         [ 1.0331e-03,  2.6581e+00, -1.8820e-01,  ..., -1.1099e-01,
           9.4890e-01, -1.3306e+00],
         [ 2.7544e-03,  3.7866e+00,  2.6443e-01,  ..., -1.1960e+00,
          -1.3898e+00, -3.5512e+00]]], device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 1.0331e-03,  2.6581e+00, -1.8820e-01,  ..., -1.1099e-01,
           9.4890e-01, -1.3306e+00],
         [ 2.7544e-03,  3.7866e+00,  2.6443e-01,  ..., -1.1960e+00,
          -1.3898e+00, -3.5512e+00],
         [ 7.0380e-03,  3.4992e+00,  5.5367e-01,  ..., -1.5212e+00,
          -6.0733e-01, -2.4952e+00]]], device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 2.7544e-03,  3.7866e+00,  2.6443e-01,  ..., -1.1960e+00,
          -1.3898e+00, -3.5512e+00],
         [ 7.0380e-03,  3.4992e+00,  5.5367e-01,  ..., -1.5212e+00,
          -6.0733e-01, -2.4952e+00],
         [ 3.3370e-03,  3.3648e+00, -6.5168e-02,  ..., -1.1905e-01,
           3.6067e-01, -8.5696e-01]]], device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 7.0380e-03,  3.4992e+00,  5.5367e-01,  ..., -1.5212e+00,
          -6.0733e-01, -2.4952e+00],
         [ 3.3370e-03,  3.3648e+00, -6.5168e-02,  ..., -1.1905e-01,
           3.6067e-01, -8.5696e-01],
         [ 3.1854e-03,  3.2843e+00, -1.4802e-01,  ...,  4.7792e-01,
          -8.4624e-01, -1.4316e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 3.3370e-03,  3.3648e+00, -6.5168e-02,  ..., -1.1905e-01,
           3.6067e-01, -8.5696e-01],
         [ 3.1854e-03,  3.2843e+00, -1.4802e-01,  ...,  4.7792e-01,
          -8.4624e-01, -1.4316e+00],
         [-9.6632e-03,  1.0915e+00,  3.0866e-01,  ..., -6.7606e-01,
           1.0911e+00,  1.7357e+00]]], device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [ 3.1854e-03,  3.2843e+00, -1.4802e-01,  ...,  4.7792e-01,
          -8.4624e-01, -1.4316e+00],
         [-9.6632e-03,  1.0915e+00,  3.0866e-01,  ..., -6.7606e-01,
           1.0911e+00,  1.7357e+00],
         [-2.6701e-02,  1.2947e+00, -1.7930e-01,  ..., -1.7128e+00,
           3.1172e-01,  7.0065e-01]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0097,  1.0915,  0.3087,  ..., -0.6761,  1.0911,  1.7357],
         [-0.0267,  1.2947, -0.1793,  ..., -1.7128,  0.3117,  0.7006],
         [-0.0274,  1.8952,  0.1576,  ..., -1.2218,  1.3812,  1.3508]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0267,  1.2947, -0.1793,  ..., -1.7128,  0.3117,  0.7006],
         [-0.0274,  1.8952,  0.1576,  ..., -1.2218,  1.3812,  1.3508],
         [-0.0192,  1.9173, -0.6276,  ..., -0.7167,  0.0572, -0.2611]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0274,  1.8952,  0.1576,  ..., -1.2218,  1.3812,  1.3508],
         [-0.0192,  1.9173, -0.6276,  ..., -0.7167,  0.0572, -0.2611],
         [-0.0065,  4.0909, -0.2410,  ..., -0.3235,  0.0637,  0.0189]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.9166e-02,  1.9173e+00, -6.2763e-01,  ..., -7.1675e-01,
           5.7179e-02, -2.6105e-01],
         [-6.4928e-03,  4.0909e+00, -2.4102e-01,  ..., -3.2347e-01,
           6.3746e-02,  1.8886e-02],
         [-1.2758e-02,  9.9820e+00,  2.9500e-01,  ..., -1.2898e+00,
           2.4448e+00,  1.7375e-02]]], device='cuda:0')
action =  tensor(1276, device='cuda:0')
reward =  6
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-6.4928e-03,  4.0909e+00, -2.4102e-01,  ..., -3.2347e-01,
           6.3746e-02,  1.8886e-02],
         [-1.2758e-02,  9.9820e+00,  2.9500e-01,  ..., -1.2898e+00,
           2.4448e+00,  1.7375e-02],
         [-1.6378e-02,  4.1524e+00,  3.6604e-02,  ..., -2.0516e+00,
           6.0482e-01, -1.4006e-01]]], device='cuda:0')
action =  tensor(3531, device='cuda:0')
reward =  7
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.2758e-02,  9.9820e+00,  2.9500e-01,  ..., -1.2898e+00,
           2.4448e+00,  1.7375e-02],
         [-1.6378e-02,  4.1524e+00,  3.6604e-02,  ..., -2.0516e+00,
           6.0482e-01, -1.4006e-01],
         [-1.9265e-02,  3.8939e+00, -1.4026e-01,  ..., -4.2642e+00,
           1.7143e-01, -7.9700e-01]]], device='cuda:0')
action =  tensor(8350, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0164,  4.1524,  0.0366,  ..., -2.0516,  0.6048, -0.1401],
         [-0.0193,  3.8939, -0.1403,  ..., -4.2642,  0.1714, -0.7970],
         [-0.0185,  1.9815, -0.1511,  ..., -2.3840, -0.2269,  0.0869]]],
       device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0193,  3.8939, -0.1403,  ..., -4.2642,  0.1714, -0.7970],
         [-0.0185,  1.9815, -0.1511,  ..., -2.3840, -0.2269,  0.0869],
         [-0.0201,  1.5381,  0.2043,  ..., -2.6751,  0.0799, -0.5923]]],
       device='cuda:0')
action =  tensor(7915, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0185,  1.9815, -0.1511,  ..., -2.3840, -0.2269,  0.0869],
         [-0.0201,  1.5381,  0.2043,  ..., -2.6751,  0.0799, -0.5923],
         [-0.0220,  2.7670, -0.3859,  ..., -2.3644, -1.8033, -0.6090]]],
       device='cuda:0')
action =  tensor(118, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0201,  1.5381,  0.2043,  ..., -2.6751,  0.0799, -0.5923],
         [-0.0220,  2.7670, -0.3859,  ..., -2.3644, -1.8033, -0.6090],
         [-0.0254,  2.3670, -0.3009,  ..., -1.7287, -0.8762, -0.0583]]],
       device='cuda:0')
action =  tensor(169, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0220,  2.7670, -0.3859,  ..., -2.3644, -1.8033, -0.6090],
         [-0.0254,  2.3670, -0.3009,  ..., -1.7287, -0.8762, -0.0583],
         [-0.0162,  2.5054, -0.0944,  ...,  1.3868, -1.9689,  1.6516]]],
       device='cuda:0')
action =  tensor(776, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0254,  2.3670, -0.3009,  ..., -1.7287, -0.8762, -0.0583],
         [-0.0162,  2.5054, -0.0944,  ...,  1.3868, -1.9689,  1.6516],
         [-0.0230,  3.1369, -0.0245,  ..., -1.3934,  0.2397,  0.5089]]],
       device='cuda:0')
action =  tensor(558, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0162,  2.5054, -0.0944,  ...,  1.3868, -1.9689,  1.6516],
         [-0.0230,  3.1369, -0.0245,  ..., -1.3934,  0.2397,  0.5089],
         [-0.0208,  2.5239, -0.4785,  ..., -1.2792, -0.2785, -0.4392]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0230,  3.1369, -0.0245,  ..., -1.3934,  0.2397,  0.5089],
         [-0.0208,  2.5239, -0.4785,  ..., -1.2792, -0.2785, -0.4392],
         [-0.0349, -0.4677,  0.0894,  ..., -4.0772,  0.7669,  0.9072]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  7
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0208,  2.5239, -0.4785,  ..., -1.2792, -0.2785, -0.4392],
         [-0.0349, -0.4677,  0.0894,  ..., -4.0772,  0.7669,  0.9072],
         [-0.0291,  0.6658,  0.1089,  ..., -4.2256,  2.7387,  0.5700]]],
       device='cuda:0')
action =  tensor(1322, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0349, -0.4677,  0.0894,  ..., -4.0772,  0.7669,  0.9072],
         [-0.0291,  0.6658,  0.1089,  ..., -4.2256,  2.7387,  0.5700],
         [-0.0211,  3.8076, -0.3050,  ..., -1.7483, -1.6727,  0.0355]]],
       device='cuda:0')
action =  tensor(381, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0291,  0.6658,  0.1089,  ..., -4.2256,  2.7387,  0.5700],
         [-0.0211,  3.8076, -0.3050,  ..., -1.7483, -1.6727,  0.0355],
         [-0.0330,  2.0904, -0.0558,  ..., -1.8339,  0.8726,  1.7386]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0211,  3.8076, -0.3050,  ..., -1.7483, -1.6727,  0.0355],
         [-0.0330,  2.0904, -0.0558,  ..., -1.8339,  0.8726,  1.7386],
         [-0.0302,  2.1365,  0.3481,  ..., -2.1752,  2.2249,  1.8518]]],
       device='cuda:0')
action =  tensor(3533, device='cuda:0')
reward =  8
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0330,  2.0904, -0.0558,  ..., -1.8339,  0.8726,  1.7386],
         [-0.0302,  2.1365,  0.3481,  ..., -2.1752,  2.2249,  1.8518],
         [-0.0219,  3.9473, -0.0488,  ..., -1.3767,  0.4013, -1.1844]]],
       device='cuda:0')
action =  tensor(1219, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0302,  2.1365,  0.3481,  ..., -2.1752,  2.2249,  1.8518],
         [-0.0219,  3.9473, -0.0488,  ..., -1.3767,  0.4013, -1.1844],
         [-0.0149,  4.0535, -0.3440,  ..., -0.5567, -0.2056, -0.7095]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  9
logits =  tensor([[[-0.0056,  2.4346,  0.5179,  ..., -2.9018,  2.5968, -0.0823],
         [-0.0066,  2.5252,  0.2336,  ..., -0.6207, -0.3603, -0.9883],
         [-0.0091,  2.8260, -0.1175,  ..., -1.2233, -0.3577, -2.0962],
         ...,
         [-0.0219,  3.9473, -0.0488,  ..., -1.3767,  0.4013, -1.1844],
         [-0.0149,  4.0535, -0.3440,  ..., -0.5567, -0.2056, -0.7095],
         [-0.0072,  4.4658, -0.2210,  ..., -0.4172, -0.1370, -0.0663]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  9
logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.4916e-02,  4.0535e+00, -3.4400e-01,  ..., -5.5666e-01,
          -2.0559e-01, -7.0951e-01],
         [-7.1546e-03,  4.4658e+00, -2.2103e-01,  ..., -4.1721e-01,
          -1.3701e-01, -6.6284e-02],
         [-1.4976e-02,  1.3121e+01,  9.5006e-02,  ..., -1.7694e+00,
           7.9783e-01, -1.6266e-01]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  9
Interior Secretary Ken Salazar pledges to keep our boot on BP 's neck' to help those affected . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . President Obama arrives in Louisiana for his third visit to the region since the crisis began .
last_state =  tensor([-0.0150, 13.1212,  0.0950,  ..., -1.7694,  0.7978, -0.1627],
       device='cuda:0')
final_logits =  tensor([[[-5.5680e-03,  2.4346e+00,  5.1792e-01,  ..., -2.9018e+00,
           2.5968e+00, -8.2298e-02],
         [-6.5556e-03,  2.5252e+00,  2.3359e-01,  ..., -6.2072e-01,
          -3.6026e-01, -9.8827e-01],
         [-9.1066e-03,  2.8260e+00, -1.1747e-01,  ..., -1.2233e+00,
          -3.5769e-01, -2.0962e+00],
         ...,
         [-1.4916e-02,  4.0535e+00, -3.4400e-01,  ..., -5.5666e-01,
          -2.0559e-01, -7.0951e-01],
         [-7.1546e-03,  4.4658e+00, -2.2103e-01,  ..., -4.1721e-01,
          -1.3701e-01, -6.6284e-02],
         [-1.4976e-02,  1.3121e+01,  9.5006e-02,  ..., -1.7694e+00,
           7.9783e-01, -1.6266e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-1.7431], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1189], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2680], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1367], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8111], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2887], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1481], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1002], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0955], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0736], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2100], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5549], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6373], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4616], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1682], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3632], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4116], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1634], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1260], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1869], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0935], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1455], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7184], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1082], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1481], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2473], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4303], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0667], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0146], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3192], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0477], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4183], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0352], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3338], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1065], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0211], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1852], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3787], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1466], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4986], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4854], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7382], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0938], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.2112], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2452], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9502], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1827], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2429], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2961], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8696], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0817], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1960], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3434], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5037], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5566], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2284], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4313], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5321], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1307], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0938], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0956], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7731], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-1.7431, -0.1189, -0.2680, -0.1367, -0.8111, -0.2887, -0.1481, -1.1002,
        -0.0955, -0.0736, -0.2100, -0.5549, -0.6373, -0.4616, -0.1682, -1.3632,
        -0.4116, -1.1634, -0.1260, -0.1869, -0.0935, -1.1455, -0.7184, -0.1082,
        -0.1481, -0.2473, -0.4303, -0.0667, -0.0146, -0.3192, -0.0477, -0.4183,
        -0.0352, -0.3338, -0.1065, -0.0211, -0.1852, -0.3787, -0.1466, -0.4986,
        -0.4854, -0.7382, -0.0938, -2.2112, -0.2452, -0.9502, -0.1827, -0.2429,
        -0.2961, -0.8696, -0.0817, -0.1960, -0.3434, -0.5037, -0.5566, -0.2284,
        -0.4313, -1.5321, -0.1307, -0.0938, -0.0956, -0.7731], device='cuda:0',
       grad_fn=<CatBackward>)
rewards =  tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 3., 3.,
        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 4., 4., 5., 5., 5., 6., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.,
        8., 8., 8., 8., 9., 9., 9., 9.], device='cuda:0')
log_probs size =  torch.Size([62])
values size =  torch.Size([62])
returns size =  torch.Size([62])
advantages =  tensor([ -90.9561,   -9.1432,  -31.2495,  -52.8220,  -68.8783,  -72.4454,
         -40.0838,  -68.4284,  -84.6308,  -37.9635,  -61.7328,  -50.7071,
         -67.2856,  -44.7523,  -61.1569,  -37.1497,  -59.0912,  -57.6840,
        -106.3842,   -6.8315,  -69.2363,  -77.0548,  -78.8939,  -63.3574,
         -81.9578,  -40.0182,  -49.9175,  -62.4019,  -54.2264,  -36.0479,
         -65.5369,  -84.6626,  -46.2333,  -51.5200,  -75.9424,  -75.7313,
         -34.8290,  -71.6891,  -89.7291,  -94.6315, -100.8846,   -5.3253,
         -39.1611,  -84.4112, -123.6675,  -94.1304, -129.4735,  -42.5384,
         -61.1813,  -54.8804,  -90.1165,  -82.7957,  -38.9267,  -86.5483,
        -106.1573,  -83.2278,  -82.6983,  -66.2786,  -32.2200,  -73.4047,
         -49.5464,  -93.6451], device='cuda:0')
actor_loss =  tensor(-29.7087, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(303662.1250, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         [ 0.0102,  4.1838,  0.0775,  ...,  0.7684,  0.2547, -1.0465]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         [ 0.0102,  4.1838,  0.0775,  ...,  0.7684,  0.2547, -1.0465],
         [ 0.0235,  2.3335,  0.0366,  ..., -1.7104, -1.8758, -1.7987]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         [ 0.0102,  4.1838,  0.0775,  ...,  0.7684,  0.2547, -1.0465],
         [ 0.0235,  2.3335,  0.0366,  ..., -1.7104, -1.8758, -1.7987],
         [ 0.0319,  3.1164, -0.1834,  ..., -1.7672,  0.9512, -1.0553]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0235,  2.3335,  0.0366,  ..., -1.7104, -1.8758, -1.7987],
         [ 0.0319,  3.1164, -0.1834,  ..., -1.7672,  0.9512, -1.0553],
         [ 0.0278,  3.0897,  0.4867,  ..., -2.1722, -0.1577, -0.1012]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0319,  3.1164, -0.1834,  ..., -1.7672,  0.9512, -1.0553],
         [ 0.0278,  3.0897,  0.4867,  ..., -2.1722, -0.1577, -0.1012],
         [ 0.0175,  0.5143,  0.0638,  ..., -1.6563,  0.6666, -3.0401]]],
       device='cuda:0')
action =  tensor(150, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0278,  3.0897,  0.4867,  ..., -2.1722, -0.1577, -0.1012],
         [ 0.0175,  0.5143,  0.0638,  ..., -1.6563,  0.6666, -3.0401],
         [ 0.0154,  2.6781,  0.3812,  ..., -0.6287, -1.2937, -2.1302]]],
       device='cuda:0')
action =  tensor(5407, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0175,  0.5143,  0.0638,  ..., -1.6563,  0.6666, -3.0401],
         [ 0.0154,  2.6781,  0.3812,  ..., -0.6287, -1.2937, -2.1302],
         [ 0.0211,  2.3720, -0.0377,  ..., -2.3711, -0.2894, -1.3179]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0154,  2.6781,  0.3812,  ..., -0.6287, -1.2937, -2.1302],
         [ 0.0211,  2.3720, -0.0377,  ..., -2.3711, -0.2894, -1.3179],
         [ 0.0158,  1.4216, -0.0118,  ..., -2.8475,  0.5284, -2.3153]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0211,  2.3720, -0.0377,  ..., -2.3711, -0.2894, -1.3179],
         [ 0.0158,  1.4216, -0.0118,  ..., -2.8475,  0.5284, -2.3153],
         [ 0.0212,  2.3112, -0.3246,  ...,  0.4755, -1.2142, -1.8503]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0158,  1.4216, -0.0118,  ..., -2.8475,  0.5284, -2.3153],
         [ 0.0212,  2.3112, -0.3246,  ...,  0.4755, -1.2142, -1.8503],
         [ 0.0089,  2.5785,  0.9260,  ...,  1.6972, -0.6196,  0.0660]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0212,  2.3112, -0.3246,  ...,  0.4755, -1.2142, -1.8503],
         [ 0.0089,  2.5785,  0.9260,  ...,  1.6972, -0.6196,  0.0660],
         [ 0.0049,  4.7349,  0.2802,  ...,  0.8125, -0.6343, -1.7408]]],
       device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0089,  2.5785,  0.9260,  ...,  1.6972, -0.6196,  0.0660],
         [ 0.0049,  4.7349,  0.2802,  ...,  0.8125, -0.6343, -1.7408],
         [ 0.0172,  2.5424, -0.3494,  ..., -2.0909,  1.2626, -2.8735]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  2
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 4.9032e-03,  4.7349e+00,  2.8023e-01,  ...,  8.1252e-01,
          -6.3426e-01, -1.7408e+00],
         [ 1.7225e-02,  2.5424e+00, -3.4944e-01,  ..., -2.0909e+00,
           1.2626e+00, -2.8735e+00],
         [ 3.4970e-02,  8.2730e+00, -5.2527e-01,  ..., -1.0391e+00,
           6.4461e-01, -3.9813e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0172,  2.5424, -0.3494,  ..., -2.0909,  1.2626, -2.8735],
         [ 0.0350,  8.2730, -0.5253,  ..., -1.0391,  0.6446, -3.9813],
         [ 0.0169, -0.6250,  0.4540,  ..., -2.8169,  1.6099, -0.7738]]],
       device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0350,  8.2730, -0.5253,  ..., -1.0391,  0.6446, -3.9813],
         [ 0.0169, -0.6250,  0.4540,  ..., -2.8169,  1.6099, -0.7738],
         [ 0.0167,  0.8551,  0.1674,  ..., -3.9456,  1.6971, -0.0794]]],
       device='cuda:0')
action =  tensor(274, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0169, -0.6250,  0.4540,  ..., -2.8169,  1.6099, -0.7738],
         [ 0.0167,  0.8551,  0.1674,  ..., -3.9456,  1.6971, -0.0794],
         [ 0.0118,  3.0151,  0.6964,  ..., -2.5187,  0.5419,  0.1213]]],
       device='cuda:0')
action =  tensor(2790, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0167,  0.8551,  0.1674,  ..., -3.9456,  1.6971, -0.0794],
         [ 0.0118,  3.0151,  0.6964,  ..., -2.5187,  0.5419,  0.1213],
         [ 0.0171,  3.3155, -0.3717,  ..., -1.0029, -0.0516, -0.1866]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0118,  3.0151,  0.6964,  ..., -2.5187,  0.5419,  0.1213],
         [ 0.0171,  3.3155, -0.3717,  ..., -1.0029, -0.0516, -0.1866],
         [ 0.0095,  3.6901, -0.1991,  ..., -0.2349, -0.0257, -0.0534]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0171,  3.3155, -0.3717,  ..., -1.0029, -0.0516, -0.1866],
         [ 0.0095,  3.6901, -0.1991,  ..., -0.2349, -0.0257, -0.0534],
         [ 0.0334,  8.4923,  0.3963,  ..., -1.4744,  1.8521, -0.2348]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0095,  3.6901, -0.1991,  ..., -0.2349, -0.0257, -0.0534],
         [ 0.0334,  8.4923,  0.3963,  ..., -1.4744,  1.8521, -0.2348],
         [ 0.0304,  2.2139, -0.1590,  ..., -1.8789, -0.7164, -1.0279]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0334,  8.4923,  0.3963,  ..., -1.4744,  1.8521, -0.2348],
         [ 0.0304,  2.2139, -0.1590,  ..., -1.8789, -0.7164, -1.0279],
         [ 0.0315,  1.5201,  0.0998,  ..., -1.7375,  3.2791, -1.9458]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0304,  2.2139, -0.1590,  ..., -1.8789, -0.7164, -1.0279],
         [ 0.0315,  1.5201,  0.0998,  ..., -1.7375,  3.2791, -1.9458],
         [ 0.0266,  3.9074,  0.4481,  ...,  0.3450, -0.8499, -2.1510]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0315,  1.5201,  0.0998,  ..., -1.7375,  3.2791, -1.9458],
         [ 0.0266,  3.9074,  0.4481,  ...,  0.3450, -0.8499, -2.1510],
         [ 0.0159,  3.4412,  0.1752,  ..., -0.1806, -0.9893, -0.4672]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0266,  3.9074,  0.4481,  ...,  0.3450, -0.8499, -2.1510],
         [ 0.0159,  3.4412,  0.1752,  ..., -0.1806, -0.9893, -0.4672],
         [ 0.0403,  1.4363, -0.1832,  ..., -1.0944,  0.9337, -1.9346]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0159,  3.4412,  0.1752,  ..., -0.1806, -0.9893, -0.4672],
         [ 0.0403,  1.4363, -0.1832,  ..., -1.0944,  0.9337, -1.9346],
         [ 0.0228,  3.6668,  0.3855,  ..., -2.0864,  0.9988, -2.3799]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0403,  1.4363, -0.1832,  ..., -1.0944,  0.9337, -1.9346],
         [ 0.0228,  3.6668,  0.3855,  ..., -2.0864,  0.9988, -2.3799],
         [ 0.0212,  2.3838,  0.5063,  ..., -0.9979, -1.0552, -0.4441]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0228,  3.6668,  0.3855,  ..., -2.0864,  0.9988, -2.3799],
         [ 0.0212,  2.3838,  0.5063,  ..., -0.9979, -1.0552, -0.4441],
         [ 0.0338,  2.5622, -0.0315,  ..., -0.1775,  1.7360, -0.8953]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0212,  2.3838,  0.5063,  ..., -0.9979, -1.0552, -0.4441],
         [ 0.0338,  2.5622, -0.0315,  ..., -0.1775,  1.7360, -0.8953],
         [ 0.0399,  2.4760,  0.4586,  ..., -0.5948,  2.2401, -1.8247]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0338,  2.5622, -0.0315,  ..., -0.1775,  1.7360, -0.8953],
         [ 0.0399,  2.4760,  0.4586,  ..., -0.5948,  2.2401, -1.8247],
         [ 0.0294,  2.8589,  0.6848,  ...,  0.5106,  1.0616, -1.9932]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0399,  2.4760,  0.4586,  ..., -0.5948,  2.2401, -1.8247],
         [ 0.0294,  2.8589,  0.6848,  ...,  0.5106,  1.0616, -1.9933],
         [ 0.0185,  3.6348,  0.0289,  ..., -1.1643, -0.9293, -0.6453]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0294,  2.8589,  0.6848,  ...,  0.5106,  1.0616, -1.9933],
         [ 0.0185,  3.6348,  0.0289,  ..., -1.1643, -0.9293, -0.6453],
         [ 0.0382,  2.6383, -0.1597,  ..., -0.0431,  0.9865, -1.3600]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0185,  3.6348,  0.0289,  ..., -1.1643, -0.9293, -0.6453],
         [ 0.0382,  2.6383, -0.1597,  ..., -0.0431,  0.9865, -1.3600],
         [ 0.0246,  3.7575,  0.2663,  ..., -1.1704, -1.5032, -3.6509]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0382,  2.6383, -0.1597,  ..., -0.0431,  0.9865, -1.3600],
         [ 0.0246,  3.7575,  0.2663,  ..., -1.1704, -1.5032, -3.6509],
         [ 0.0251,  3.5767,  0.5585,  ..., -1.5192, -0.7028, -2.4514]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0246,  3.7575,  0.2663,  ..., -1.1704, -1.5032, -3.6509],
         [ 0.0251,  3.5767,  0.5585,  ..., -1.5192, -0.7028, -2.4514],
         [ 0.0348,  3.3675, -0.0451,  ..., -0.0763,  0.3476, -0.9017]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0251,  3.5767,  0.5585,  ..., -1.5192, -0.7028, -2.4514],
         [ 0.0348,  3.3675, -0.0451,  ..., -0.0763,  0.3476, -0.9017],
         [ 0.0497,  3.4437, -0.1366,  ...,  0.4871, -0.8590, -1.3215]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0348,  3.3675, -0.0451,  ..., -0.0763,  0.3476, -0.9017],
         [ 0.0497,  3.4437, -0.1366,  ...,  0.4871, -0.8590, -1.3215],
         [ 0.0269,  1.1102,  0.3625,  ..., -0.6385,  1.0597,  1.7769]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0497,  3.4437, -0.1366,  ...,  0.4871, -0.8590, -1.3215],
         [ 0.0269,  1.1102,  0.3625,  ..., -0.6385,  1.0597,  1.7769],
         [ 0.0160,  1.2345, -0.1292,  ..., -1.6633,  0.3716,  0.8030]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0269,  1.1102,  0.3625,  ..., -0.6385,  1.0597,  1.7769],
         [ 0.0160,  1.2345, -0.1292,  ..., -1.6633,  0.3716,  0.8030],
         [ 0.0127,  1.8730,  0.1992,  ..., -1.1851,  1.4917,  1.4553]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0160,  1.2345, -0.1292,  ..., -1.6633,  0.3716,  0.8030],
         [ 0.0127,  1.8730,  0.1992,  ..., -1.1851,  1.4917,  1.4553],
         [ 0.0176,  1.9334, -0.5973,  ..., -0.6752,  0.1096, -0.1936]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0127,  1.8730,  0.1992,  ..., -1.1851,  1.4917,  1.4553],
         [ 0.0176,  1.9334, -0.5973,  ..., -0.6752,  0.1096, -0.1936],
         [ 0.0096,  4.0968, -0.2214,  ..., -0.2920,  0.0754,  0.0509]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.7584e-02,  1.9334e+00, -5.9734e-01,  ..., -6.7515e-01,
           1.0962e-01, -1.9362e-01],
         [ 9.5695e-03,  4.0968e+00, -2.2142e-01,  ..., -2.9197e-01,
           7.5387e-02,  5.0945e-02],
         [ 3.5779e-02,  9.8731e+00,  3.3853e-01,  ..., -1.3700e+00,
           2.3981e+00,  1.1897e-02]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  5
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 9.5695e-03,  4.0968e+00, -2.2142e-01,  ..., -2.9197e-01,
           7.5387e-02,  5.0945e-02],
         [ 3.5779e-02,  9.8731e+00,  3.3853e-01,  ..., -1.3700e+00,
           2.3981e+00,  1.1897e-02],
         [ 2.6279e-02,  3.1805e+00, -9.8169e-02,  ..., -1.2795e+00,
          -2.1814e-01, -1.6577e+00]]], device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0358,  9.8731,  0.3385,  ..., -1.3700,  2.3981,  0.0119],
         [ 0.0263,  3.1805, -0.0982,  ..., -1.2795, -0.2181, -1.6577],
         [ 0.0295,  0.6005, -0.4225,  ..., -2.7154,  1.2110, -0.0645]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0263,  3.1805, -0.0982,  ..., -1.2795, -0.2181, -1.6577],
         [ 0.0295,  0.6005, -0.4225,  ..., -2.7154,  1.2110, -0.0645],
         [ 0.0204,  2.6487, -0.2205,  ..., -0.0790,  0.9133,  0.7101]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0295,  0.6005, -0.4225,  ..., -2.7154,  1.2110, -0.0645],
         [ 0.0204,  2.6487, -0.2205,  ..., -0.0790,  0.9133,  0.7101],
         [ 0.0320,  1.2308,  0.0779,  ..., -1.0594,  1.2954, -0.2938]]],
       device='cuda:0')
action =  tensor(129, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0204,  2.6487, -0.2205,  ..., -0.0790,  0.9133,  0.7101],
         [ 0.0320,  1.2308,  0.0779,  ..., -1.0594,  1.2954, -0.2938],
         [ 0.0303,  1.7836,  0.2198,  ..., -2.7518,  0.8036, -2.4040]]],
       device='cuda:0')
action =  tensor(1900, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0320,  1.2308,  0.0779,  ..., -1.0594,  1.2954, -0.2938],
         [ 0.0303,  1.7836,  0.2198,  ..., -2.7518,  0.8036, -2.4040],
         [ 0.0265,  0.5589, -0.1789,  ...,  0.3370, -0.9492, -0.9276]]],
       device='cuda:0')
action =  tensor(269, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0303,  1.7836,  0.2198,  ..., -2.7518,  0.8036, -2.4040],
         [ 0.0265,  0.5589, -0.1789,  ...,  0.3370, -0.9492, -0.9276],
         [ 0.0286,  1.7547,  0.0154,  ..., -1.4511,  0.4401, -2.7851]]],
       device='cuda:0')
action =  tensor(847, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0265,  0.5589, -0.1789,  ...,  0.3370, -0.9492, -0.9276],
         [ 0.0286,  1.7547,  0.0154,  ..., -1.4511,  0.4401, -2.7851],
         [ 0.0333,  2.2331, -0.0865,  ...,  0.1272, -0.3272, -1.0529]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0286,  1.7547,  0.0154,  ..., -1.4511,  0.4401, -2.7851],
         [ 0.0333,  2.2331, -0.0865,  ...,  0.1272, -0.3272, -1.0529],
         [ 0.0337,  1.8024,  0.2140,  ...,  1.0559,  0.6337, -0.3101]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0333,  2.2331, -0.0865,  ...,  0.1272, -0.3272, -1.0529],
         [ 0.0337,  1.8024,  0.2140,  ...,  1.0559,  0.6337, -0.3101],
         [ 0.0212,  1.8935,  1.7725,  ...,  2.3567,  0.9644,  0.5686]]],
       device='cuda:0')
action =  tensor(5891, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0337,  1.8024,  0.2140,  ...,  1.0559,  0.6337, -0.3101],
         [ 0.0212,  1.8935,  1.7725,  ...,  2.3567,  0.9644,  0.5686],
         [ 0.0196,  4.1205,  0.4027,  ..., -1.2161, -0.1163, -1.1972]]],
       device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0212,  1.8935,  1.7725,  ...,  2.3567,  0.9644,  0.5686],
         [ 0.0196,  4.1205,  0.4027,  ..., -1.2161, -0.1163, -1.1972],
         [ 0.0181,  2.4395, -0.0826,  ..., -0.2985,  1.3949, -0.7807]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0196,  4.1205,  0.4027,  ..., -1.2161, -0.1163, -1.1972],
         [ 0.0181,  2.4395, -0.0826,  ..., -0.2985,  1.3949, -0.7807],
         [ 0.0263,  4.4696,  0.1872,  ...,  1.6190,  2.6502, -2.9063]]],
       device='cuda:0')
action =  tensor(5469, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0181,  2.4395, -0.0826,  ..., -0.2985,  1.3949, -0.7807],
         [ 0.0263,  4.4696,  0.1872,  ...,  1.6190,  2.6502, -2.9063],
         [ 0.0298,  4.0367, -0.4684,  ..., -0.6564,  0.5746, -1.5588]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0263,  4.4696,  0.1872,  ...,  1.6190,  2.6502, -2.9063],
         [ 0.0298,  4.0367, -0.4684,  ..., -0.6564,  0.5746, -1.5588],
         [ 0.0200,  3.6268,  0.4330,  ..., -0.0321,  0.8365, -1.4871]]],
       device='cuda:0')
action =  tensor(4800, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0298,  4.0367, -0.4684,  ..., -0.6564,  0.5746, -1.5588],
         [ 0.0200,  3.6268,  0.4330,  ..., -0.0321,  0.8365, -1.4871],
         [ 0.0144,  3.9300, -0.3197,  ..., -0.0980, -0.1618,  0.9655]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0200,  3.6268,  0.4330,  ..., -0.0321,  0.8365, -1.4871],
         [ 0.0144,  3.9300, -0.3197,  ..., -0.0980, -0.1618,  0.9655],
         [ 0.0125,  3.1652,  0.2235,  ...,  0.1080,  1.1084,  1.9622]]],
       device='cuda:0')
action =  tensor(8186, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0144,  3.9300, -0.3197,  ..., -0.0980, -0.1618,  0.9655],
         [ 0.0125,  3.1652,  0.2235,  ...,  0.1080,  1.1084,  1.9622],
         [ 0.0260,  3.0238, -0.4617,  ...,  0.6181,  0.1652, -0.8748]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0125,  3.1652,  0.2235,  ...,  0.1080,  1.1084,  1.9622],
         [ 0.0260,  3.0238, -0.4617,  ...,  0.6181,  0.1652, -0.8748],
         [ 0.0092,  4.0704, -0.2629,  ..., -0.1352,  0.0917, -0.0666]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  9
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 2.5953e-02,  3.0238e+00, -4.6172e-01,  ...,  6.1810e-01,
           1.6517e-01, -8.7482e-01],
         [ 9.2335e-03,  4.0704e+00, -2.6287e-01,  ..., -1.3524e-01,
           9.1687e-02, -6.6589e-02],
         [ 3.0283e-02,  1.1498e+01,  2.1242e-01,  ..., -1.3932e+00,
           1.7289e+00,  4.5259e-01]]], device='cuda:0')
action =  tensor(1276, device='cuda:0')
reward =  10
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 9.2335e-03,  4.0704e+00, -2.6287e-01,  ..., -1.3524e-01,
           9.1687e-02, -6.6590e-02],
         [ 3.0283e-02,  1.1498e+01,  2.1242e-01,  ..., -1.3932e+00,
           1.7289e+00,  4.5259e-01],
         [ 1.5199e-02,  4.9246e+00,  3.8137e-02,  ..., -2.1017e+00,
           5.6914e-01, -2.5781e-01]]], device='cuda:0')
action =  tensor(3531, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0303, 11.4977,  0.2124,  ..., -1.3932,  1.7289,  0.4526],
         [ 0.0152,  4.9246,  0.0381,  ..., -2.1017,  0.5691, -0.2578],
         [ 0.0171,  4.6232, -0.1446,  ..., -4.1421,  0.0637, -0.7414]]],
       device='cuda:0')
action =  tensor(8350, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0152,  4.9246,  0.0381,  ..., -2.1017,  0.5691, -0.2578],
         [ 0.0171,  4.6232, -0.1446,  ..., -4.1421,  0.0637, -0.7414],
         [ 0.0160,  2.6147, -0.1440,  ..., -2.4702, -0.2231, -0.0393]]],
       device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0171,  4.6232, -0.1446,  ..., -4.1421,  0.0637, -0.7414],
         [ 0.0160,  2.6147, -0.1440,  ..., -2.4702, -0.2231, -0.0393],
         [ 0.0142,  1.8482,  0.2203,  ..., -2.5453,  0.0132, -0.6370]]],
       device='cuda:0')
action =  tensor(7915, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0160,  2.6147, -0.1440,  ..., -2.4702, -0.2231, -0.0393],
         [ 0.0142,  1.8482,  0.2203,  ..., -2.5453,  0.0132, -0.6370],
         [ 0.0140,  3.3950, -0.3981,  ..., -2.2912, -1.6143, -0.8842]]],
       device='cuda:0')
action =  tensor(118, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0142,  1.8482,  0.2203,  ..., -2.5453,  0.0132, -0.6370],
         [ 0.0140,  3.3950, -0.3981,  ..., -2.2912, -1.6143, -0.8842],
         [ 0.0124,  2.7691, -0.2899,  ..., -1.4855, -1.1106, -0.0504]]],
       device='cuda:0')
action =  tensor(169, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0140,  3.3950, -0.3981,  ..., -2.2912, -1.6143, -0.8842],
         [ 0.0124,  2.7691, -0.2899,  ..., -1.4855, -1.1106, -0.0504],
         [ 0.0138,  2.8887, -0.1031,  ...,  1.3896, -1.8469,  1.7380]]],
       device='cuda:0')
action =  tensor(776, device='cuda:0')
reward =  11
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.2447e-02,  2.7691e+00, -2.8988e-01,  ..., -1.4855e+00,
          -1.1106e+00, -5.0402e-02],
         [ 1.3803e-02,  2.8887e+00, -1.0307e-01,  ...,  1.3896e+00,
          -1.8469e+00,  1.7380e+00],
         [ 1.3467e-02,  3.3807e+00, -1.4652e-04,  ..., -1.4172e+00,
           3.1954e-01,  4.5358e-01]]], device='cuda:0')
action =  tensor(558, device='cuda:0')
reward =  11
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.3803e-02,  2.8887e+00, -1.0307e-01,  ...,  1.3896e+00,
          -1.8469e+00,  1.7380e+00],
         [ 1.3467e-02,  3.3807e+00, -1.4652e-04,  ..., -1.4172e+00,
           3.1954e-01,  4.5358e-01],
         [ 1.7980e-02,  2.9990e+00, -4.5070e-01,  ..., -1.0608e+00,
          -2.2463e-01, -3.1139e-01]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  11
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.3467e-02,  3.3807e+00, -1.4652e-04,  ..., -1.4172e+00,
           3.1954e-01,  4.5358e-01],
         [ 1.7980e-02,  2.9990e+00, -4.5070e-01,  ..., -1.0608e+00,
          -2.2463e-01, -3.1139e-01],
         [ 1.2719e-02,  1.0447e-01,  6.4509e-02,  ..., -3.9564e+00,
           8.6821e-01,  8.9721e-01]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0180,  2.9990, -0.4507,  ..., -1.0608, -0.2246, -0.3114],
         [ 0.0127,  0.1045,  0.0645,  ..., -3.9564,  0.8682,  0.8972],
         [ 0.0126,  1.0749,  0.1397,  ..., -4.0983,  2.9633,  0.6958]]],
       device='cuda:0')
action =  tensor(1322, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0127,  0.1045,  0.0645,  ..., -3.9564,  0.8682,  0.8972],
         [ 0.0126,  1.0749,  0.1397,  ..., -4.0983,  2.9633,  0.6958],
         [ 0.0178,  4.6082, -0.3140,  ..., -1.5044, -1.6612, -0.0496]]],
       device='cuda:0')
action =  tensor(381, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0126,  1.0749,  0.1397,  ..., -4.0983,  2.9633,  0.6958],
         [ 0.0178,  4.6082, -0.3140,  ..., -1.5044, -1.6612, -0.0496],
         [ 0.0077,  2.4395, -0.0375,  ..., -1.5555,  0.8595,  1.8745]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0178,  4.6082, -0.3140,  ..., -1.5044, -1.6612, -0.0496],
         [ 0.0077,  2.4395, -0.0375,  ..., -1.5555,  0.8595,  1.8745],
         [ 0.0049,  2.5178,  0.3706,  ..., -1.8462,  2.3057,  2.0374]]],
       device='cuda:0')
action =  tensor(3533, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0077,  2.4395, -0.0375,  ..., -1.5555,  0.8595,  1.8745],
         [ 0.0049,  2.5178,  0.3706,  ..., -1.8462,  2.3057,  2.0374],
         [ 0.0103,  4.7009, -0.0258,  ..., -1.2603,  0.4595, -1.2656]]],
       device='cuda:0')
action =  tensor(1219, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0049,  2.5178,  0.3706,  ..., -1.8462,  2.3057,  2.0374],
         [ 0.0103,  4.7009, -0.0258,  ..., -1.2603,  0.4595, -1.2656],
         [ 0.0194,  4.4135, -0.3073,  ..., -0.5626, -0.0766, -0.6052]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.0372,  2.4389,  0.5657,  ..., -2.8642,  2.5858, -0.1032],
         [ 0.0140,  2.4586,  0.2675,  ..., -0.6051, -0.3715, -0.9575],
         [ 0.0245,  2.8175, -0.0795,  ..., -1.2437, -0.3386, -2.0575],
         ...,
         [ 0.0103,  4.7009, -0.0258,  ..., -1.2603,  0.4595, -1.2656],
         [ 0.0194,  4.4135, -0.3073,  ..., -0.5626, -0.0766, -0.6052],
         [ 0.0090,  4.5601, -0.2022,  ..., -0.3732, -0.0226,  0.0248]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  13
logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.9365e-02,  4.4135e+00, -3.0732e-01,  ..., -5.6258e-01,
          -7.6629e-02, -6.0516e-01],
         [ 9.0149e-03,  4.5601e+00, -2.0224e-01,  ..., -3.7319e-01,
          -2.2552e-02,  2.4824e-02],
         [ 2.5921e-02,  1.3284e+01,  1.0246e-02,  ..., -1.6264e+00,
           6.2764e-01,  1.8138e-01]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  13
Interior Secretary Ken Salazar pledges to keep our boot on BP 's neck' to help those affected . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . BP says it will be Wednesday before trying a 'top kill' bid to plug the leak . President Obama arrives in Louisiana for his third visit to the region since the crisis began .
last_state =  tensor([ 2.5921e-02,  1.3284e+01,  1.0246e-02,  ..., -1.6264e+00,
         6.2764e-01,  1.8138e-01], device='cuda:0')
final_logits =  tensor([[[ 3.7152e-02,  2.4389e+00,  5.6568e-01,  ..., -2.8642e+00,
           2.5858e+00, -1.0321e-01],
         [ 1.4037e-02,  2.4586e+00,  2.6747e-01,  ..., -6.0514e-01,
          -3.7148e-01, -9.5754e-01],
         [ 2.4465e-02,  2.8175e+00, -7.9545e-02,  ..., -1.2437e+00,
          -3.3861e-01, -2.0575e+00],
         ...,
         [ 1.9365e-02,  4.4135e+00, -3.0732e-01,  ..., -5.6258e-01,
          -7.6629e-02, -6.0516e-01],
         [ 9.0149e-03,  4.5601e+00, -2.0224e-01,  ..., -3.7319e-01,
          -2.2552e-02,  2.4824e-02],
         [ 2.5921e-02,  1.3284e+01,  1.0246e-02,  ..., -1.6264e+00,
           6.2764e-01,  1.8138e-01]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-1.8691], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1270], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2836], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1363], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9047], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3010], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1420], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5660], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1103], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0749], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1694], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5622], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6853], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6070], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1742], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3681], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5266], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3443], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1379], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2000], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0960], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1838], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6774], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1192], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1594], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2663], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4504], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0744], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0150], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3376], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0502], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5539], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0376], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3287], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1102], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0206], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1932], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3883], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1702], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5485], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5162], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7106], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0967], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.3938], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4775], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3769], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5661], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5255], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.5599], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1866], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7158], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3665], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0187], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1100], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2102], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1665], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4323], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4125], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1123], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2783], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4392], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3901], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0989], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.1047], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2492], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1671], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1984], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2699], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2748], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8417], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0861], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1942], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3148], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4802], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6970], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2184], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3581], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7384], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1408], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1002], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0964], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5427], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-1.8691, -0.1270, -0.2836, -0.1363, -0.9047, -0.3010, -0.1420, -1.5660,
        -0.1103, -0.0749, -0.1694, -0.5622, -0.6853, -0.6070, -0.1742, -1.3681,
        -0.5266, -1.3443, -0.1379, -0.2000, -0.0960, -1.1838, -0.6774, -0.1192,
        -0.1594, -0.2663, -0.4504, -0.0744, -0.0150, -0.3376, -0.0502, -0.5539,
        -0.0376, -0.3287, -0.1102, -0.0206, -0.1932, -0.3883, -0.1702, -0.5485,
        -0.5162, -0.7106, -0.0967, -2.3938, -1.4775, -0.3769, -0.5661, -1.5255,
        -2.5599, -0.1866, -1.7158, -0.3665, -1.0187, -0.1100, -0.2102, -0.1665,
        -0.4323, -0.4125, -0.1123, -0.2783, -0.4392, -0.3901, -0.0989, -2.1047,
        -0.2492, -1.1671, -0.1984, -0.2699, -0.2748, -0.8417, -0.0861, -0.1942,
        -0.3148, -0.4802, -0.6970, -0.2184, -0.3581, -1.7384, -0.1408, -0.1002,
        -0.0964, -0.5427], device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,
         2.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,
         3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,  4.,  5.,  5.,
         5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,  6.,
         7.,  7.,  8.,  8.,  9.,  9.,  9., 10., 11., 11., 11., 11., 11., 11.,
        11., 11., 11., 11., 12., 12., 12., 12., 13., 13., 13., 13.],
       device='cuda:0')
log_probs size =  torch.Size([82])
values size =  torch.Size([82])
returns size =  torch.Size([82])
advantages =  tensor([-6.6703e-02, -3.6234e-02, -3.6234e-02, -3.6234e-02,  9.6377e-01,
         9.6377e-01,  9.6377e-01,  9.6377e-01,  9.6377e-01,  9.6377e-01,
         1.9638e+00,  1.9638e+00,  1.9638e+00,  1.9638e+00,  1.9638e+00,
         1.9638e+00,  2.9638e+00,  2.9638e+00,  2.7561e+00,  2.9638e+00,
         2.9638e+00,  2.9638e+00,  2.9638e+00,  2.9638e+00,  2.9638e+00,
         2.9638e+00,  2.9638e+00,  2.9638e+00, -4.0640e+01,  2.9638e+00,
         2.9638e+00,  2.9638e+00,  2.9638e+00,  2.9638e+00,  2.9638e+00,
         2.9638e+00,  2.9638e+00,  2.9638e+00,  3.6130e+00,  3.9638e+00,
         4.9638e+00,  4.9638e+00,  4.9638e+00,  4.9638e+00,  5.9638e+00,
         5.9638e+00,  5.6766e+00,  5.9638e+00,  5.9638e+00,  5.9638e+00,
         5.9638e+00,  5.9638e+00,  5.9638e+00,  5.7693e+00,  6.9638e+00,
         5.9638e+00,  6.9638e+00,  6.9638e+00,  7.9638e+00,  7.9638e+00,
         8.6638e+00,  8.9638e+00,  8.9638e+00,  9.9638e+00,  1.0964e+01,
         1.0964e+01,  1.0964e+01,  1.0964e+01,  1.0518e+01, -2.5472e+01,
         1.0964e+01,  1.0964e+01,  1.0964e+01,  1.0964e+01,  1.1964e+01,
         1.1804e+01,  1.1964e+01,  1.1572e+01,  1.0971e+01,  1.2691e+01,
         1.2782e+01,  1.2749e+01], device='cuda:0')
actor_loss =  tensor(2.5808, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(5871.8613, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         [ 0.0246,  4.2300,  0.0997,  ...,  0.7782,  0.2705, -1.0226]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         [ 0.0246,  4.2300,  0.0997,  ...,  0.7782,  0.2705, -1.0226],
         [ 0.0526,  2.3339,  0.0607,  ..., -1.7030, -1.8500, -1.7550]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         [ 0.0246,  4.2300,  0.0997,  ...,  0.7782,  0.2705, -1.0226],
         [ 0.0526,  2.3339,  0.0607,  ..., -1.7030, -1.8500, -1.7550],
         [ 0.0690,  3.0920, -0.1351,  ..., -1.7400,  1.0610, -1.0215]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0526,  2.3339,  0.0607,  ..., -1.7030, -1.8500, -1.7550],
         [ 0.0690,  3.0920, -0.1351,  ..., -1.7400,  1.0610, -1.0215],
         [ 0.0562,  3.0918,  0.5168,  ..., -2.1473, -0.1062, -0.0119]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0690,  3.0920, -0.1351,  ..., -1.7400,  1.0610, -1.0215],
         [ 0.0562,  3.0918,  0.5168,  ..., -2.1473, -0.1062, -0.0119],
         [ 0.0503,  0.4996,  0.1181,  ..., -1.6423,  0.6692, -2.9966]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0562,  3.0918,  0.5168,  ..., -2.1473, -0.1062, -0.0119],
         [ 0.0503,  0.4996,  0.1181,  ..., -1.6423,  0.6692, -2.9966],
         [ 0.0185,  3.7157,  2.2588,  ...,  3.3938, -0.5258, -0.7723]]],
       device='cuda:0')
action =  tensor(18457, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0503,  0.4996,  0.1181,  ..., -1.6423,  0.6692, -2.9966],
         [ 0.0185,  3.7157,  2.2588,  ...,  3.3938, -0.5258, -0.7723],
         [ 0.0402,  2.4786,  0.2014,  ..., -3.6488, -0.3611, -1.9733]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0185,  3.7157,  2.2588,  ...,  3.3938, -0.5258, -0.7723],
         [ 0.0402,  2.4786,  0.2014,  ..., -3.6488, -0.3611, -1.9733],
         [ 0.0383,  1.4044, -0.1279,  ..., -3.8272,  1.1857, -2.1694]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0402,  2.4786,  0.2014,  ..., -3.6488, -0.3611, -1.9733],
         [ 0.0383,  1.4044, -0.1279,  ..., -3.8272,  1.1857, -2.1694],
         [ 0.0394,  2.1295, -0.1798,  ...,  0.4476, -0.8291, -1.0876]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0383,  1.4044, -0.1279,  ..., -3.8272,  1.1857, -2.1694],
         [ 0.0394,  2.1295, -0.1798,  ...,  0.4476, -0.8291, -1.0876],
         [ 0.0348,  5.3765, -0.4217,  ...,  0.1434, -0.3453, -2.1084]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0394,  2.1295, -0.1798,  ...,  0.4476, -0.8291, -1.0876],
         [ 0.0348,  5.3765, -0.4217,  ...,  0.1434, -0.3453, -2.1084],
         [ 0.0208,  4.3168,  0.0291,  ..., -0.3305, -0.5583, -0.2324]]],
       device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0348,  5.3765, -0.4217,  ...,  0.1434, -0.3453, -2.1084],
         [ 0.0208,  4.3168,  0.0291,  ..., -0.3305, -0.5583, -0.2324],
         [ 0.0424,  2.8473, -0.3792,  ..., -2.0511,  1.3812, -2.8534]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0002],
         ...,
         [ 0.0208,  4.3168,  0.0291,  ..., -0.3305, -0.5583, -0.2324],
         [ 0.0424,  2.8473, -0.3792,  ..., -2.0511,  1.3812, -2.8534],
         [ 0.0780,  8.2036, -0.4389,  ..., -2.0280,  1.0367, -2.2232]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0424,  2.8473, -0.3792,  ..., -2.0511,  1.3812, -2.8534],
         [ 0.0780,  8.2036, -0.4389,  ..., -2.0281,  1.0367, -2.2232],
         [ 0.0529, -0.4933,  0.5248,  ..., -2.9017,  1.8059, -0.0648]]],
       device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0780,  8.2036, -0.4389,  ..., -2.0281,  1.0367, -2.2232],
         [ 0.0529, -0.4933,  0.5248,  ..., -2.9017,  1.8059, -0.0648],
         [ 0.0564,  0.6382,  0.1758,  ..., -4.0507,  2.2563,  0.1341]]],
       device='cuda:0')
action =  tensor(274, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0529, -0.4933,  0.5248,  ..., -2.9017,  1.8059, -0.0648],
         [ 0.0564,  0.6382,  0.1758,  ..., -4.0507,  2.2563,  0.1341],
         [ 0.0400,  2.8483,  0.7427,  ..., -2.6284,  0.6228,  0.2598]]],
       device='cuda:0')
action =  tensor(2790, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0564,  0.6382,  0.1758,  ..., -4.0507,  2.2563,  0.1341],
         [ 0.0400,  2.8483,  0.7427,  ..., -2.6284,  0.6228,  0.2598],
         [ 0.0444,  3.2245, -0.3668,  ..., -1.0442,  0.2096, -0.1900]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0400,  2.8483,  0.7427,  ..., -2.6284,  0.6228,  0.2598],
         [ 0.0444,  3.2245, -0.3668,  ..., -1.0442,  0.2096, -0.1900],
         [ 0.0222,  3.6064, -0.1843,  ..., -0.2586,  0.0440, -0.0505]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0444,  3.2245, -0.3668,  ..., -1.0442,  0.2096, -0.1900],
         [ 0.0222,  3.6064, -0.1843,  ..., -0.2586,  0.0440, -0.0505],
         [ 0.0709,  8.5927,  0.4141,  ..., -1.4957,  2.0695, -0.1500]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0222,  3.6064, -0.1843,  ..., -0.2586,  0.0440, -0.0505],
         [ 0.0709,  8.5927,  0.4141,  ..., -1.4957,  2.0695, -0.1500],
         [ 0.0681,  2.2455, -0.1429,  ..., -1.9907, -0.6138, -1.0281]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0709,  8.5927,  0.4141,  ..., -1.4957,  2.0695, -0.1500],
         [ 0.0681,  2.2455, -0.1429,  ..., -1.9907, -0.6138, -1.0281],
         [ 0.0689,  1.5163,  0.1451,  ..., -1.7490,  3.3873, -1.8448]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0681,  2.2455, -0.1429,  ..., -1.9907, -0.6138, -1.0281],
         [ 0.0689,  1.5163,  0.1451,  ..., -1.7490,  3.3873, -1.8448],
         [ 0.0518,  3.9310,  0.4828,  ...,  0.3771, -0.7419, -2.0768]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0689,  1.5163,  0.1451,  ..., -1.7490,  3.3873, -1.8448],
         [ 0.0518,  3.9310,  0.4828,  ...,  0.3771, -0.7419, -2.0768],
         [ 0.0329,  3.4547,  0.1882,  ..., -0.1431, -0.9324, -0.4617]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0518,  3.9310,  0.4828,  ...,  0.3771, -0.7419, -2.0768],
         [ 0.0329,  3.4547,  0.1882,  ..., -0.1431, -0.9324, -0.4617],
         [ 0.0750,  1.5149, -0.1532,  ..., -1.0504,  1.0770, -1.8325]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0329,  3.4547,  0.1882,  ..., -0.1431, -0.9324, -0.4617],
         [ 0.0750,  1.5149, -0.1532,  ..., -1.0504,  1.0770, -1.8325],
         [ 0.0410,  3.6181,  0.4005,  ..., -2.0330,  1.1007, -2.4238]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0750,  1.5149, -0.1532,  ..., -1.0504,  1.0770, -1.8325],
         [ 0.0410,  3.6181,  0.4005,  ..., -2.0330,  1.1007, -2.4238],
         [ 0.0331,  2.4729,  0.5177,  ..., -1.0353, -1.0702, -0.4401]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0410,  3.6181,  0.4005,  ..., -2.0330,  1.1007, -2.4238],
         [ 0.0331,  2.4729,  0.5177,  ..., -1.0353, -1.0702, -0.4401],
         [ 0.0587,  2.6312, -0.0215,  ..., -0.1659,  1.8252, -0.8236]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0331,  2.4729,  0.5177,  ..., -1.0353, -1.0702, -0.4401],
         [ 0.0587,  2.6312, -0.0215,  ..., -0.1659,  1.8252, -0.8236],
         [ 0.0634,  2.5160,  0.5168,  ..., -0.5330,  2.1655, -1.8784]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0587,  2.6312, -0.0215,  ..., -0.1659,  1.8252, -0.8236],
         [ 0.0634,  2.5160,  0.5168,  ..., -0.5330,  2.1655, -1.8784],
         [ 0.0537,  2.9028,  0.7177,  ...,  0.5001,  1.0654, -1.9083]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0634,  2.5160,  0.5168,  ..., -0.5330,  2.1655, -1.8784],
         [ 0.0537,  2.9028,  0.7177,  ...,  0.5001,  1.0654, -1.9083],
         [ 0.0338,  3.7014,  0.0369,  ..., -1.0713, -0.8911, -0.6584]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0537,  2.9028,  0.7177,  ...,  0.5001,  1.0654, -1.9083],
         [ 0.0338,  3.7014,  0.0369,  ..., -1.0713, -0.8911, -0.6584],
         [ 0.0694,  2.7150, -0.1568,  ...,  0.0146,  1.0509, -1.4188]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0338,  3.7014,  0.0369,  ..., -1.0713, -0.8911, -0.6584],
         [ 0.0694,  2.7150, -0.1568,  ...,  0.0146,  1.0509, -1.4188],
         [ 0.0427,  3.7309,  0.2712,  ..., -1.1647, -1.6515, -3.6722]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0694,  2.7150, -0.1568,  ...,  0.0146,  1.0509, -1.4188],
         [ 0.0427,  3.7309,  0.2712,  ..., -1.1647, -1.6515, -3.6722],
         [ 0.0404,  3.6206,  0.5855,  ..., -1.4789, -0.6493, -2.4445]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0427,  3.7309,  0.2712,  ..., -1.1647, -1.6515, -3.6722],
         [ 0.0404,  3.6206,  0.5855,  ..., -1.4789, -0.6493, -2.4445],
         [ 0.0603,  3.4431, -0.0360,  ..., -0.1125,  0.5584, -0.9113]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0404,  3.6206,  0.5855,  ..., -1.4789, -0.6493, -2.4445],
         [ 0.0603,  3.4431, -0.0360,  ..., -0.1125,  0.5584, -0.9113],
         [ 0.0870,  3.5181, -0.0810,  ...,  0.4427, -0.6672, -1.1864]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0603,  3.4431, -0.0360,  ..., -0.1125,  0.5584, -0.9113],
         [ 0.0870,  3.5181, -0.0810,  ...,  0.4427, -0.6672, -1.1864],
         [ 0.0562,  1.0168,  0.4007,  ..., -0.5602,  1.1842,  1.8929]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0870,  3.5181, -0.0810,  ...,  0.4427, -0.6672, -1.1864],
         [ 0.0562,  1.0168,  0.4007,  ..., -0.5602,  1.1842,  1.8929],
         [ 0.0502,  1.2388, -0.0937,  ..., -1.6402,  0.5389,  0.9527]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0562,  1.0168,  0.4007,  ..., -0.5602,  1.1842,  1.8929],
         [ 0.0502,  1.2388, -0.0937,  ..., -1.6402,  0.5389,  0.9527],
         [ 0.0446,  1.8805,  0.2337,  ..., -1.0974,  1.6370,  1.5640]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0502,  1.2388, -0.0937,  ..., -1.6402,  0.5389,  0.9527],
         [ 0.0446,  1.8805,  0.2337,  ..., -1.0974,  1.6370,  1.5640],
         [ 0.0470,  2.0074, -0.5843,  ..., -0.6181,  0.2276, -0.1081]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0446,  1.8805,  0.2337,  ..., -1.0974,  1.6370,  1.5640],
         [ 0.0470,  2.0074, -0.5843,  ..., -0.6181,  0.2276, -0.1081],
         [ 0.0224,  4.1290, -0.2081,  ..., -0.2945,  0.1020,  0.0560]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0470,  2.0074, -0.5843,  ..., -0.6181,  0.2276, -0.1081],
         [ 0.0224,  4.1290, -0.2081,  ..., -0.2945,  0.1020,  0.0560],
         [ 0.0758, 10.1469,  0.3560,  ..., -1.3583,  2.5031,  0.0288]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0224,  4.1290, -0.2081,  ..., -0.2945,  0.1020,  0.0560],
         [ 0.0758, 10.1469,  0.3560,  ..., -1.3583,  2.5031,  0.0288],
         [ 0.0629,  3.2574, -0.0695,  ..., -1.2601, -0.1198, -1.6524]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0758, 10.1469,  0.3560,  ..., -1.3583,  2.5031,  0.0288],
         [ 0.0629,  3.2574, -0.0695,  ..., -1.2601, -0.1198, -1.6524],
         [ 0.0731,  0.6898, -0.3806,  ..., -2.6729,  1.2931, -0.0468]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0629,  3.2574, -0.0695,  ..., -1.2601, -0.1198, -1.6524],
         [ 0.0731,  0.6898, -0.3806,  ..., -2.6729,  1.2931, -0.0468],
         [ 0.0460,  2.6318, -0.1676,  ..., -0.2335,  1.0968,  0.2850]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0731,  0.6898, -0.3806,  ..., -2.6729,  1.2931, -0.0468],
         [ 0.0460,  2.6318, -0.1676,  ..., -0.2335,  1.0968,  0.2850],
         [ 0.0667,  1.3026,  0.1314,  ..., -1.0385,  1.2847, -0.2662]]],
       device='cuda:0')
action =  tensor(508, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0460,  2.6318, -0.1676,  ..., -0.2335,  1.0968,  0.2850],
         [ 0.0667,  1.3026,  0.1314,  ..., -1.0385,  1.2847, -0.2662],
         [ 0.0753,  1.6776, -0.1288,  ...,  0.1021, -0.3474, -0.8352]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0667,  1.3026,  0.1314,  ..., -1.0385,  1.2847, -0.2662],
         [ 0.0753,  1.6776, -0.1288,  ...,  0.1021, -0.3474, -0.8352],
         [ 0.0721,  1.8234,  0.1968,  ...,  0.8053,  0.9177,  0.0425]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0753,  1.6776, -0.1288,  ...,  0.1021, -0.3474, -0.8352],
         [ 0.0721,  1.8234,  0.1968,  ...,  0.8053,  0.9177,  0.0425],
         [ 0.0371,  1.7257,  1.7863,  ...,  2.4010,  1.0987,  0.6923]]],
       device='cuda:0')
action =  tensor(5891, device='cuda:0')
reward =  6
logits =  tensor([[[ 7.1302e-02,  2.4719e+00,  6.0181e-01,  ..., -2.8471e+00,
           2.5961e+00, -1.1472e-01],
         [ 3.0399e-02,  2.4571e+00,  2.9216e-01,  ..., -5.8210e-01,
          -3.7479e-01, -9.5087e-01],
         [ 5.1141e-02,  2.8639e+00, -5.2621e-02,  ..., -1.2783e+00,
          -3.2466e-01, -2.0001e+00],
         ...,
         [ 7.2144e-02,  1.8234e+00,  1.9683e-01,  ...,  8.0526e-01,
           9.1771e-01,  4.2470e-02],
         [ 3.7094e-02,  1.7257e+00,  1.7863e+00,  ...,  2.4010e+00,
           1.0987e+00,  6.9226e-01],
         [ 4.3314e-02,  3.5990e+00,  4.2258e-01,  ..., -1.4956e+00,
          -1.0212e-03, -1.1821e+00]]], device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  7
logits =  tensor([[[ 7.1302e-02,  2.4719e+00,  6.0181e-01,  ..., -2.8471e+00,
           2.5961e+00, -1.1472e-01],
         [ 3.0399e-02,  2.4571e+00,  2.9216e-01,  ..., -5.8210e-01,
          -3.7479e-01, -9.5087e-01],
         [ 5.1141e-02,  2.8639e+00, -5.2621e-02,  ..., -1.2783e+00,
          -3.2466e-01, -2.0001e+00],
         ...,
         [ 3.7094e-02,  1.7257e+00,  1.7863e+00,  ...,  2.4010e+00,
           1.0987e+00,  6.9226e-01],
         [ 4.3314e-02,  3.5990e+00,  4.2258e-01,  ..., -1.4956e+00,
          -1.0212e-03, -1.1821e+00],
         [ 3.9178e-02,  1.5972e+00, -1.4848e-01,  ..., -4.0175e-01,
           1.5428e+00, -8.7334e-01]]], device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  6
logits =  tensor([[[ 7.1302e-02,  2.4719e+00,  6.0181e-01,  ..., -2.8471e+00,
           2.5961e+00, -1.1472e-01],
         [ 3.0399e-02,  2.4571e+00,  2.9216e-01,  ..., -5.8210e-01,
          -3.7479e-01, -9.5087e-01],
         [ 5.1141e-02,  2.8639e+00, -5.2621e-02,  ..., -1.2783e+00,
          -3.2466e-01, -2.0001e+00],
         ...,
         [ 4.3314e-02,  3.5990e+00,  4.2258e-01,  ..., -1.4956e+00,
          -1.0212e-03, -1.1821e+00],
         [ 3.9178e-02,  1.5972e+00, -1.4848e-01,  ..., -4.0175e-01,
           1.5428e+00, -8.7334e-01],
         [ 6.4320e-02,  3.7322e+00, -2.3384e-02,  ...,  1.5225e+00,
           2.5856e+00, -2.9512e+00]]], device='cuda:0')
action =  tensor(5469, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0392,  1.5972, -0.1485,  ..., -0.4018,  1.5428, -0.8733],
         [ 0.0643,  3.7322, -0.0234,  ...,  1.5225,  2.5856, -2.9512],
         [ 0.0679,  2.2819, -0.5065,  ..., -0.3612, -0.0647, -1.9844]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0643,  3.7322, -0.0234,  ...,  1.5225,  2.5856, -2.9512],
         [ 0.0679,  2.2819, -0.5065,  ..., -0.3612, -0.0647, -1.9844],
         [ 0.0736,  1.0635, -0.1174,  ..., -0.1799,  0.4710,  0.1380]]],
       device='cuda:0')
action =  tensor(1900, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0679,  2.2819, -0.5065,  ..., -0.3612, -0.0647, -1.9844],
         [ 0.0736,  1.0635, -0.1174,  ..., -0.1799,  0.4710,  0.1380],
         [ 0.0663,  2.6291, -0.3449,  ...,  1.2950, -1.2460, -0.4367]]],
       device='cuda:0')
action =  tensor(269, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0736,  1.0635, -0.1174,  ..., -0.1799,  0.4710,  0.1380],
         [ 0.0663,  2.6291, -0.3449,  ...,  1.2950, -1.2460, -0.4367],
         [ 0.0686,  3.3475, -0.0636,  ..., -1.5380,  0.6922, -3.4725]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0663,  2.6291, -0.3449,  ...,  1.2950, -1.2460, -0.4367],
         [ 0.0686,  3.3475, -0.0636,  ..., -1.5380,  0.6922, -3.4725],
         [ 0.0543,  5.6327,  0.3095,  ..., -0.0096,  0.9219, -2.4478]]],
       device='cuda:0')
action =  tensor(6207, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0686,  3.3475, -0.0636,  ..., -1.5380,  0.6922, -3.4725],
         [ 0.0543,  5.6327,  0.3095,  ..., -0.0096,  0.9219, -2.4478],
         [ 0.0801,  3.4451, -0.1040,  ...,  0.8081,  0.4273, -0.8828]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0543,  5.6327,  0.3095,  ..., -0.0096,  0.9219, -2.4478],
         [ 0.0801,  3.4451, -0.1040,  ...,  0.8081,  0.4273, -0.8828],
         [ 0.0505,  3.8972,  0.4809,  ...,  0.2652,  0.1844, -1.2428]]],
       device='cuda:0')
action =  tensor(4800, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0801,  3.4451, -0.1040,  ...,  0.8081,  0.4273, -0.8828],
         [ 0.0505,  3.8972,  0.4809,  ...,  0.2652,  0.1844, -1.2428],
         [ 0.0476,  3.9200, -0.3163,  ..., -0.4050, -0.1145,  0.9629]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0505,  3.8972,  0.4809,  ...,  0.2652,  0.1844, -1.2428],
         [ 0.0476,  3.9200, -0.3163,  ..., -0.4050, -0.1145,  0.9629],
         [ 0.0430,  3.1636,  0.2635,  ..., -0.0719,  1.0425,  1.7626]]],
       device='cuda:0')
action =  tensor(8186, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0476,  3.9200, -0.3163,  ..., -0.4050, -0.1145,  0.9629],
         [ 0.0430,  3.1636,  0.2635,  ..., -0.0719,  1.0425,  1.7626],
         [ 0.0600,  3.5644, -0.4696,  ...,  0.6408,  0.1808, -1.2988]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0430,  3.1636,  0.2635,  ..., -0.0719,  1.0425,  1.7626],
         [ 0.0600,  3.5644, -0.4696,  ...,  0.6408,  0.1808, -1.2988],
         [ 0.0224,  4.2169, -0.2143,  ..., -0.1179,  0.0751, -0.0565]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0600,  3.5644, -0.4696,  ...,  0.6408,  0.1808, -1.2988],
         [ 0.0224,  4.2169, -0.2143,  ..., -0.1179,  0.0751, -0.0565],
         [ 0.0686, 11.7612,  0.2015,  ..., -1.5609,  1.4360,  0.0619]]],
       device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  9
Interior Secretary Ken Salazar pledges to keep 'boot on BP's neck' to help those affected . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . BP says it will try a 'top kill' bid on Wednesday before it tries to plug the leak .
last_state =  tensor([ 0.0686, 11.7612,  0.2015,  ..., -1.5609,  1.4360,  0.0619],
       device='cuda:0')
final_logits =  tensor([[[ 0.0713,  2.4719,  0.6018,  ..., -2.8471,  2.5961, -0.1147],
         [ 0.0304,  2.4571,  0.2922,  ..., -0.5821, -0.3748, -0.9509],
         [ 0.0511,  2.8639, -0.0526,  ..., -1.2783, -0.3247, -2.0001],
         ...,
         [ 0.0600,  3.5644, -0.4696,  ...,  0.6408,  0.1808, -1.2988],
         [ 0.0224,  4.2169, -0.2143,  ..., -0.1179,  0.0751, -0.0565],
         [ 0.0686, 11.7612,  0.2015,  ..., -1.5609,  1.4360,  0.0619]]],
       device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-1.9236], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1344], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2931], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1395], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9775], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3121], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1361], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.9016], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4289], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2269], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4914], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3520], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1762], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1636], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3348], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5937], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7742], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.8887], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1393], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2704], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0971], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1982], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6154], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1223], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1728], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2859], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4963], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0924], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0162], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3681], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0568], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6274], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0412], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3169], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1131], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0216], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2155], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3667], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1903], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6341], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5395], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6588], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0986], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.4339], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5530], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4235], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5490], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4824], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6791], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0715], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0938], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2299], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1705], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7851], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0992], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1367], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7810], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4727], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1457], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8087], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2283], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3744], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4378], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5427], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1007], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.9448], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-1.9236, -0.1344, -0.2931, -0.1395, -0.9775, -0.3121, -0.1361, -1.9016,
        -0.4289, -0.2269, -0.4914, -0.3520, -0.1762, -0.1636, -0.3348, -1.5937,
        -0.7742, -1.8887, -0.1393, -0.2704, -0.0971, -1.1982, -0.6154, -0.1223,
        -0.1728, -0.2859, -0.4963, -0.0924, -0.0162, -0.3681, -0.0568, -0.6274,
        -0.0412, -0.3169, -0.1131, -0.0216, -0.2155, -0.3667, -0.1903, -0.6341,
        -0.5395, -0.6588, -0.0986, -2.4339, -1.5530, -0.4235, -0.5490, -1.4824,
        -0.6791, -1.0715, -0.0938, -0.2299, -0.1705, -0.7851, -1.0992, -1.1367,
        -0.7810, -1.4727, -1.1457, -0.8087, -0.2283, -0.3744, -0.4378, -0.5427,
        -0.1007, -1.9448], device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 2., 2.,
        2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 3., 4., 4., 5., 5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 7., 6., 7.,
        7., 7., 7., 7., 7., 7., 8., 8., 9., 9., 9., 9.], device='cuda:0')
log_probs size =  torch.Size([66])
values size =  torch.Size([66])
returns size =  torch.Size([66])
advantages =  tensor([-3.5689e-02, -3.5689e-02, -3.5689e-02, -3.5689e-02,  9.6431e-01,
         9.6431e-01,  9.6431e-01,  9.6431e-01,  9.6431e-01,  9.6431e-01,
         1.9643e+00,  9.6431e-01,  9.6431e-01,  9.6431e-01,  9.6431e-01,
        -3.3406e+01,  1.9643e+00,  1.9643e+00,  1.9643e+00,  1.9643e+00,
         1.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,
         2.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,
         2.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,  2.9643e+00,
         2.9643e+00,  2.9643e+00,  2.9643e+00,  3.9643e+00,  3.9643e+00,
         4.9643e+00,  4.9643e+00,  4.9643e+00,  4.9643e+00,  5.9643e+00,
         5.9643e+00,  5.9643e+00,  5.9643e+00,  5.9643e+00,  5.9643e+00,
         5.9643e+00,  6.9643e+00,  5.9643e+00,  6.9643e+00,  6.9643e+00,
         6.9643e+00,  6.9643e+00, -6.1151e+01,  6.9643e+00,  6.9643e+00,
         7.9643e+00,  7.9643e+00,  8.4191e+00,  8.9643e+00,  8.9643e+00,
         8.9643e+00], device='cuda:0')
actor_loss =  tensor(0.2261, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(6230.1353, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         [ 0.0365,  4.2643,  0.1224,  ...,  0.7965,  0.2712, -0.9878]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         [ 0.0365,  4.2643,  0.1224,  ...,  0.7965,  0.2712, -0.9878],
         [ 0.0766,  2.3322,  0.0859,  ..., -1.6810, -1.8654, -1.6784]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         [ 0.0365,  4.2643,  0.1224,  ...,  0.7965,  0.2712, -0.9878],
         [ 0.0766,  2.3322,  0.0859,  ..., -1.6810, -1.8654, -1.6784],
         [ 0.1003,  3.0969, -0.0942,  ..., -1.7012,  1.1368, -0.9613]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0766,  2.3322,  0.0859,  ..., -1.6810, -1.8654, -1.6784],
         [ 0.1003,  3.0969, -0.0942,  ..., -1.7012,  1.1368, -0.9613],
         [ 0.0793,  3.1010,  0.5395,  ..., -2.1289, -0.0798,  0.0432]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1003,  3.0969, -0.0942,  ..., -1.7012,  1.1368, -0.9613],
         [ 0.0793,  3.1010,  0.5395,  ..., -2.1289, -0.0798,  0.0432],
         [ 0.0780,  0.5077,  0.1646,  ..., -1.6534,  0.6706, -2.9294]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0793,  3.1010,  0.5395,  ..., -2.1289, -0.0798,  0.0432],
         [ 0.0780,  0.5077,  0.1646,  ..., -1.6534,  0.6706, -2.9294],
         [ 0.0259,  3.7066,  2.3399,  ...,  3.5821, -0.4984, -0.6004]]],
       device='cuda:0')
action =  tensor(18457, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0780,  0.5077,  0.1646,  ..., -1.6534,  0.6706, -2.9294],
         [ 0.0259,  3.7066,  2.3399,  ...,  3.5821, -0.4984, -0.6004],
         [ 0.0564,  2.5538,  0.2238,  ..., -3.6637, -0.4131, -2.0355]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0259,  3.7066,  2.3399,  ...,  3.5821, -0.4984, -0.6004],
         [ 0.0564,  2.5538,  0.2238,  ..., -3.6637, -0.4131, -2.0355],
         [ 0.0598,  1.4652, -0.1006,  ..., -3.8403,  1.1769, -2.2017]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0564,  2.5538,  0.2238,  ..., -3.6637, -0.4131, -2.0355],
         [ 0.0598,  1.4652, -0.1006,  ..., -3.8403,  1.1769, -2.2017],
         [ 0.0604,  2.1389, -0.1635,  ...,  0.4184, -0.8816, -1.1241]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0598,  1.4652, -0.1006,  ..., -3.8403,  1.1769, -2.2017],
         [ 0.0604,  2.1389, -0.1635,  ...,  0.4184, -0.8816, -1.1241],
         [ 0.0547,  5.4486, -0.4230,  ...,  0.1165, -0.4281, -2.4260]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0604,  2.1389, -0.1635,  ...,  0.4184, -0.8816, -1.1241],
         [ 0.0547,  5.4486, -0.4230,  ...,  0.1165, -0.4281, -2.4260],
         [ 0.0325,  4.3480,  0.0483,  ..., -0.3383, -0.5699, -0.2570]]],
       device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0547,  5.4486, -0.4230,  ...,  0.1165, -0.4281, -2.4260],
         [ 0.0325,  4.3480,  0.0483,  ..., -0.3383, -0.5699, -0.2570],
         [ 0.0632,  2.9278, -0.3626,  ..., -2.0654,  1.4147, -2.8253]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0325,  4.3480,  0.0483,  ..., -0.3383, -0.5699, -0.2570],
         [ 0.0632,  2.9278, -0.3626,  ..., -2.0654,  1.4147, -2.8253],
         [ 0.1145,  8.3489, -0.4450,  ..., -2.0141,  0.9215, -2.3530]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0632,  2.9278, -0.3626,  ..., -2.0654,  1.4147, -2.8253],
         [ 0.1145,  8.3489, -0.4450,  ..., -2.0141,  0.9215, -2.3530],
         [ 0.0823, -0.4607,  0.5591,  ..., -2.8726,  1.8857,  0.0484]]],
       device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1145,  8.3489, -0.4450,  ..., -2.0141,  0.9215, -2.3530],
         [ 0.0823, -0.4607,  0.5591,  ..., -2.8726,  1.8857,  0.0484],
         [ 0.0895,  0.7020,  0.1971,  ..., -4.0328,  2.3683,  0.1998]]],
       device='cuda:0')
action =  tensor(4807, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0823, -0.4607,  0.5591,  ..., -2.8726,  1.8857,  0.0484],
         [ 0.0895,  0.7020,  0.1971,  ..., -4.0328,  2.3683,  0.1998],
         [ 0.0690,  1.7353,  0.1262,  ..., -2.0995,  0.8008,  0.8914]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0895,  0.7020,  0.1971,  ..., -4.0328,  2.3683,  0.1998],
         [ 0.0690,  1.7353,  0.1262,  ..., -2.0995,  0.8008,  0.8914],
         [ 0.0319,  3.5940, -0.1716,  ..., -0.4732,  0.1252, -0.0557]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0690,  1.7353,  0.1262,  ..., -2.0995,  0.8008,  0.8914],
         [ 0.0319,  3.5940, -0.1716,  ..., -0.4732,  0.1252, -0.0557],
         [ 0.1029,  8.9698,  0.4485,  ..., -1.6714,  2.1460, -0.1933]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0319,  3.5940, -0.1716,  ..., -0.4732,  0.1252, -0.0557],
         [ 0.1029,  8.9698,  0.4485,  ..., -1.6714,  2.1460, -0.1933],
         [ 0.0996,  2.3589, -0.1333,  ..., -2.0920, -0.4975, -1.1259]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1029,  8.9698,  0.4485,  ..., -1.6714,  2.1460, -0.1933],
         [ 0.0996,  2.3589, -0.1333,  ..., -2.0920, -0.4975, -1.1259],
         [ 0.1015,  1.6382,  0.1679,  ..., -1.7334,  3.4651, -1.8640]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0996,  2.3589, -0.1333,  ..., -2.0920, -0.4975, -1.1259],
         [ 0.1015,  1.6382,  0.1679,  ..., -1.7334,  3.4651, -1.8640],
         [ 0.0727,  4.0162,  0.5285,  ...,  0.4444, -0.6814, -2.0566]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1015,  1.6382,  0.1679,  ..., -1.7334,  3.4651, -1.8640],
         [ 0.0727,  4.0162,  0.5285,  ...,  0.4444, -0.6814, -2.0566],
         [ 0.0468,  3.4813,  0.2079,  ..., -0.1135, -0.9431, -0.4497]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0727,  4.0162,  0.5285,  ...,  0.4444, -0.6814, -2.0566],
         [ 0.0468,  3.4813,  0.2079,  ..., -0.1135, -0.9431, -0.4497],
         [ 0.1043,  1.5560, -0.1413,  ..., -1.0372,  1.1059, -1.7291]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0468,  3.4813,  0.2079,  ..., -0.1135, -0.9431, -0.4497],
         [ 0.1043,  1.5560, -0.1413,  ..., -1.0372,  1.1059, -1.7291],
         [ 0.0563,  3.6203,  0.4296,  ..., -2.0217,  1.0739, -2.4683]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1043,  1.5560, -0.1413,  ..., -1.0372,  1.1059, -1.7291],
         [ 0.0563,  3.6203,  0.4296,  ..., -2.0217,  1.0739, -2.4683],
         [ 0.0432,  2.5733,  0.5258,  ..., -1.0634, -1.1207, -0.4983]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0563,  3.6203,  0.4296,  ..., -2.0217,  1.0739, -2.4683],
         [ 0.0432,  2.5733,  0.5258,  ..., -1.0634, -1.1207, -0.4983],
         [ 0.0801,  2.7085, -0.0268,  ..., -0.2252,  1.8466, -0.7689]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0432,  2.5733,  0.5258,  ..., -1.0634, -1.1207, -0.4983],
         [ 0.0801,  2.7085, -0.0268,  ..., -0.2252,  1.8466, -0.7689],
         [ 0.0815,  2.6120,  0.6013,  ..., -0.4019,  2.0362, -1.8655]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0801,  2.7085, -0.0268,  ..., -0.2252,  1.8466, -0.7689],
         [ 0.0815,  2.6120,  0.6013,  ..., -0.4019,  2.0362, -1.8655],
         [ 0.0744,  2.9481,  0.7361,  ...,  0.4953,  1.0592, -1.8740]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0815,  2.6120,  0.6013,  ..., -0.4019,  2.0362, -1.8655],
         [ 0.0744,  2.9481,  0.7361,  ...,  0.4953,  1.0592, -1.8740],
         [ 0.0467,  3.7510,  0.0417,  ..., -0.9077, -0.8466, -0.6642]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0744,  2.9481,  0.7361,  ...,  0.4953,  1.0592, -1.8740],
         [ 0.0467,  3.7510,  0.0417,  ..., -0.9077, -0.8466, -0.6642],
         [ 0.0969,  2.7405, -0.1743,  ...,  0.0541,  0.9678, -1.4587]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0467,  3.7510,  0.0417,  ..., -0.9077, -0.8466, -0.6642],
         [ 0.0969,  2.7405, -0.1743,  ...,  0.0541,  0.9678, -1.4587],
         [ 0.0594,  3.7739,  0.2792,  ..., -1.1308, -1.8033, -3.7758]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0969,  2.7405, -0.1743,  ...,  0.0541,  0.9678, -1.4587],
         [ 0.0594,  3.7739,  0.2792,  ..., -1.1308, -1.8033, -3.7758],
         [ 0.0541,  3.5670,  0.6226,  ..., -1.4452, -0.5334, -2.5337]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0594,  3.7739,  0.2792,  ..., -1.1308, -1.8033, -3.7758],
         [ 0.0541,  3.5670,  0.6226,  ..., -1.4452, -0.5334, -2.5337],
         [ 0.0835,  3.4010, -0.0510,  ..., -0.1994,  0.6917, -0.9175]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0541,  3.5670,  0.6226,  ..., -1.4452, -0.5334, -2.5337],
         [ 0.0835,  3.4010, -0.0510,  ..., -0.1994,  0.6917, -0.9175],
         [ 0.1164,  3.5973, -0.0527,  ...,  0.4725, -0.6316, -0.9663]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0835,  3.4010, -0.0510,  ..., -0.1994,  0.6917, -0.9175],
         [ 0.1164,  3.5973, -0.0527,  ...,  0.4725, -0.6316, -0.9663],
         [ 0.0822,  0.9188,  0.4348,  ..., -0.4806,  1.3835,  1.9485]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1164,  3.5973, -0.0527,  ...,  0.4725, -0.6316, -0.9663],
         [ 0.0822,  0.9188,  0.4348,  ..., -0.4806,  1.3835,  1.9485],
         [ 0.0791,  1.2387, -0.0643,  ..., -1.6296,  0.7025,  1.0626]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0822,  0.9188,  0.4348,  ..., -0.4806,  1.3835,  1.9485],
         [ 0.0791,  1.2387, -0.0643,  ..., -1.6296,  0.7025,  1.0626],
         [ 0.0713,  1.9412,  0.2596,  ..., -1.0532,  1.7972,  1.6660]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0791,  1.2387, -0.0643,  ..., -1.6296,  0.7025,  1.0626],
         [ 0.0713,  1.9412,  0.2596,  ..., -1.0532,  1.7972,  1.6660],
         [ 0.0709,  2.0256, -0.5634,  ..., -0.6721,  0.1993, -0.0323]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0713,  1.9412,  0.2596,  ..., -1.0532,  1.7972,  1.6660],
         [ 0.0709,  2.0256, -0.5634,  ..., -0.6721,  0.1993, -0.0323],
         [ 0.0328,  4.1489, -0.1942,  ..., -0.3170,  0.0964,  0.0302]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0709,  2.0256, -0.5634,  ..., -0.6721,  0.1993, -0.0323],
         [ 0.0328,  4.1489, -0.1942,  ..., -0.3170,  0.0964,  0.0302],
         [ 0.1099, 10.4268,  0.3785,  ..., -1.4335,  2.5616, -0.0240]]],
       device='cuda:0')
action =  tensor(787, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0328,  4.1489, -0.1942,  ..., -0.3170,  0.0964,  0.0302],
         [ 0.1099, 10.4268,  0.3785,  ..., -1.4335,  2.5616, -0.0240],
         [ 0.0861,  2.9638, -0.1173,  ..., -0.6027,  2.0819, -2.7697]]],
       device='cuda:0')
action =  tensor(3500, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1099, 10.4268,  0.3785,  ..., -1.4335,  2.5616, -0.0240],
         [ 0.0861,  2.9638, -0.1173,  ..., -0.6027,  2.0819, -2.7697],
         [ 0.0364,  3.2101,  0.5741,  ..., -0.6632,  0.8382, -0.7606]]],
       device='cuda:0')
action =  tensor(7959, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0861,  2.9638, -0.1173,  ..., -0.6027,  2.0819, -2.7697],
         [ 0.0364,  3.2101,  0.5741,  ..., -0.6632,  0.8382, -0.7606],
         [ 0.0645,  1.6156, -0.0434,  ..., -2.3128,  1.3005, -3.5556]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0364,  3.2101,  0.5741,  ..., -0.6632,  0.8382, -0.7606],
         [ 0.0645,  1.6156, -0.0434,  ..., -2.3128,  1.3005, -3.5556],
         [ 0.1026,  0.1002, -0.0366,  ..., -2.5474, -1.3608, -0.6581]]],
       device='cuda:0')
action =  tensor(6155, device='cuda:0')
reward =  9
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0645,  1.6156, -0.0434,  ..., -2.3128,  1.3005, -3.5556],
         [ 0.1026,  0.1002, -0.0366,  ..., -2.5474, -1.3608, -0.6581],
         [ 0.0633,  3.0019,  0.1477,  ..., -2.1545, -1.9051, -0.7630]]],
       device='cuda:0')
action =  tensor(12034, device='cuda:0')
reward =  10
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.1026,  0.1002, -0.0366,  ..., -2.5474, -1.3608, -0.6581],
         [ 0.0633,  3.0019,  0.1477,  ..., -2.1545, -1.9051, -0.7630],
         [ 0.0697,  1.1891, -0.3965,  ..., -1.4103, -0.7564, -0.4892]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  10
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0633,  3.0019,  0.1477,  ..., -2.1545, -1.9051, -0.7630],
         [ 0.0697,  1.1891, -0.3965,  ..., -1.4103, -0.7564, -0.4892],
         [ 0.0618,  2.0255,  0.0472,  ..., -0.4847, -0.3081, -0.0532]]],
       device='cuda:0')
action =  tensor(242, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0697,  1.1891, -0.3965,  ..., -1.4103, -0.7564, -0.4892],
         [ 0.0618,  2.0255,  0.0472,  ..., -0.4847, -0.3081, -0.0532],
         [ 0.0842,  1.9681, -0.1208,  ..., -1.2733,  0.2515, -0.8361]]],
       device='cuda:0')
action =  tensor(127, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0618,  2.0255,  0.0472,  ..., -0.4847, -0.3081, -0.0532],
         [ 0.0842,  1.9681, -0.1208,  ..., -1.2733,  0.2515, -0.8361],
         [ 0.0749,  2.0356,  0.3172,  ..., -0.2614, -1.1520,  1.5925]]],
       device='cuda:0')
action =  tensor(270, device='cuda:0')
reward =  11
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0842,  1.9681, -0.1208,  ..., -1.2733,  0.2515, -0.8361],
         [ 0.0749,  2.0356,  0.3172,  ..., -0.2614, -1.1520,  1.5925],
         [ 0.0669,  4.3417,  0.5808,  ..., -0.2846, -0.7203,  0.1223]]],
       device='cuda:0')
action =  tensor(5340, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0749,  2.0356,  0.3172,  ..., -0.2614, -1.1520,  1.5925],
         [ 0.0669,  4.3417,  0.5808,  ..., -0.2846, -0.7203,  0.1223],
         [ 0.0797,  3.4970, -0.3738,  ..., -0.2003, -0.1130, -0.2712]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  12
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0669,  4.3417,  0.5808,  ..., -0.2846, -0.7203,  0.1223],
         [ 0.0797,  3.4970, -0.3738,  ..., -0.2003, -0.1130, -0.2712],
         [ 0.0322,  4.6388, -0.1981,  ..., -0.1252,  0.0088,  0.0550]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.0028e-01,  2.4692e+00,  6.3102e-01,  ..., -2.8214e+00,
           2.5832e+00, -1.2476e-01],
         [ 4.3727e-02,  2.4666e+00,  3.1503e-01,  ..., -5.5754e-01,
          -3.7936e-01, -9.4848e-01],
         [ 7.3207e-02,  2.8633e+00, -2.4418e-02,  ..., -1.3062e+00,
          -3.4436e-01, -1.9301e+00],
         ...,
         [ 7.9718e-02,  3.4970e+00, -3.7381e-01,  ..., -2.0025e-01,
          -1.1304e-01, -2.7120e-01],
         [ 3.2202e-02,  4.6388e+00, -1.9805e-01,  ..., -1.2524e-01,
           8.7513e-03,  5.5027e-02],
         [ 1.0046e-01,  1.1586e+01,  1.7715e-01,  ..., -1.3740e+00,
           1.9369e+00,  1.3307e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.0028e-01,  2.4692e+00,  6.3102e-01,  ..., -2.8214e+00,
           2.5832e+00, -1.2476e-01],
         [ 4.3727e-02,  2.4666e+00,  3.1503e-01,  ..., -5.5754e-01,
          -3.7936e-01, -9.4848e-01],
         [ 7.3207e-02,  2.8633e+00, -2.4418e-02,  ..., -1.3062e+00,
          -3.4436e-01, -1.9301e+00],
         ...,
         [ 3.2202e-02,  4.6388e+00, -1.9805e-01,  ..., -1.2524e-01,
           8.7513e-03,  5.5027e-02],
         [ 1.0046e-01,  1.1586e+01,  1.7715e-01,  ..., -1.3740e+00,
           1.9369e+00,  1.3307e-01],
         [ 8.4215e-02,  4.9946e+00,  4.5291e-03,  ..., -9.7515e-01,
           2.9063e-01, -1.5042e+00]]], device='cuda:0')
action =  tensor(3522, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.0028e-01,  2.4692e+00,  6.3102e-01,  ..., -2.8214e+00,
           2.5832e+00, -1.2476e-01],
         [ 4.3727e-02,  2.4666e+00,  3.1503e-01,  ..., -5.5754e-01,
          -3.7936e-01, -9.4848e-01],
         [ 7.3207e-02,  2.8633e+00, -2.4418e-02,  ..., -1.3062e+00,
          -3.4436e-01, -1.9301e+00],
         ...,
         [ 1.0046e-01,  1.1586e+01,  1.7715e-01,  ..., -1.3740e+00,
           1.9369e+00,  1.3307e-01],
         [ 8.4215e-02,  4.9946e+00,  4.5291e-03,  ..., -9.7515e-01,
           2.9063e-01, -1.5042e+00],
         [ 5.5515e-02,  3.8284e+00, -7.6210e-02,  ..., -1.7854e+00,
           2.2205e-01, -1.1294e+00]]], device='cuda:0')
action =  tensor(6061, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.0028e-01,  2.4692e+00,  6.3102e-01,  ..., -2.8214e+00,
           2.5832e+00, -1.2476e-01],
         [ 4.3727e-02,  2.4666e+00,  3.1503e-01,  ..., -5.5754e-01,
          -3.7936e-01, -9.4848e-01],
         [ 7.3207e-02,  2.8633e+00, -2.4418e-02,  ..., -1.3062e+00,
          -3.4436e-01, -1.9301e+00],
         ...,
         [ 8.4215e-02,  4.9946e+00,  4.5291e-03,  ..., -9.7515e-01,
           2.9063e-01, -1.5042e+00],
         [ 5.5515e-02,  3.8284e+00, -7.6210e-02,  ..., -1.7854e+00,
           2.2205e-01, -1.1294e+00],
         [ 3.3944e-02,  4.5122e+00,  3.8932e-02,  ..., -1.1025e+00,
           1.4227e+00, -2.0219e-01]]], device='cuda:0')
action =  tensor(32886, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0555,  3.8284, -0.0762,  ..., -1.7854,  0.2220, -1.1294],
         [ 0.0339,  4.5122,  0.0389,  ..., -1.1025,  1.4227, -0.2022],
         [ 0.0552,  4.6047, -0.1591,  ..., -1.9231, -1.0920, -0.6635]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0339,  4.5122,  0.0389,  ..., -1.1025,  1.4227, -0.2022],
         [ 0.0552,  4.6047, -0.1591,  ..., -1.9231, -1.0920, -0.6635],
         [ 0.0974,  2.6082, -0.4940,  ..., -2.2616,  0.4071, -0.8533]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0552,  4.6047, -0.1591,  ..., -1.9231, -1.0920, -0.6635],
         [ 0.0974,  2.6082, -0.4940,  ..., -2.2616,  0.4071, -0.8533],
         [ 0.0563,  3.7687, -0.1663,  ..., -1.1569,  0.5074, -1.2686]]],
       device='cuda:0')
action =  tensor(256, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0974,  2.6082, -0.4940,  ..., -2.2616,  0.4071, -0.8533],
         [ 0.0563,  3.7687, -0.1663,  ..., -1.1569,  0.5074, -1.2686],
         [ 0.0540,  2.1717,  0.1660,  ..., -2.4275, -0.8447, -1.8097]]],
       device='cuda:0')
action =  tensor(248, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0563,  3.7687, -0.1663,  ..., -1.1569,  0.5074, -1.2686],
         [ 0.0540,  2.1717,  0.1660,  ..., -2.4275, -0.8447, -1.8097],
         [ 0.0630,  2.5034,  0.0040,  ..., -2.9219, -2.7041, -0.8493]]],
       device='cuda:0')
action =  tensor(3925, device='cuda:0')
reward =  13
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0540,  2.1717,  0.1660,  ..., -2.4275, -0.8447, -1.8097],
         [ 0.0630,  2.5034,  0.0040,  ..., -2.9219, -2.7041, -0.8494],
         [ 0.0346,  3.4627,  0.2309,  ..., -0.8829, -1.0286, -0.1242]]],
       device='cuda:0')
action =  tensor(539, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0630,  2.5034,  0.0040,  ..., -2.9219, -2.7041, -0.8494],
         [ 0.0346,  3.4627,  0.2309,  ..., -0.8829, -1.0286, -0.1242],
         [ 0.0674,  3.3808, -0.2553,  ..., -0.3330, -1.6303, -0.6125]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0346,  3.4627,  0.2309,  ..., -0.8829, -1.0286, -0.1242],
         [ 0.0674,  3.3808, -0.2553,  ..., -0.3330, -1.6303, -0.6125],
         [ 0.0534,  1.7014,  0.2065,  ...,  0.2581, -1.1506,  0.3703]]],
       device='cuda:0')
action =  tensor(235, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0674,  3.3808, -0.2553,  ..., -0.3330, -1.6303, -0.6125],
         [ 0.0534,  1.7014,  0.2065,  ...,  0.2581, -1.1506,  0.3703],
         [ 0.0795,  2.9914, -0.4882,  ..., -2.4309, -0.3427, -1.6584]]],
       device='cuda:0')
action =  tensor(175, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0534,  1.7014,  0.2065,  ...,  0.2581, -1.1506,  0.3703],
         [ 0.0795,  2.9914, -0.4882,  ..., -2.4309, -0.3427, -1.6584],
         [ 0.0943,  2.3023, -0.4477,  ..., -3.6137,  0.6012, -0.7704]]],
       device='cuda:0')
action =  tensor(327, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0795,  2.9914, -0.4882,  ..., -2.4309, -0.3427, -1.6584],
         [ 0.0943,  2.3023, -0.4477,  ..., -3.6137,  0.6012, -0.7704],
         [ 0.0685,  3.2746, -0.0304,  ...,  0.9022, -2.5127, -2.6738]]],
       device='cuda:0')
action =  tensor(117, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0943,  2.3023, -0.4477,  ..., -3.6137,  0.6012, -0.7704],
         [ 0.0685,  3.2746, -0.0304,  ...,  0.9022, -2.5127, -2.6738],
         [ 0.0765,  4.1095,  0.1824,  ...,  0.8542, -2.4041, -3.5164]]],
       device='cuda:0')
action =  tensor(375, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0685,  3.2746, -0.0304,  ...,  0.9022, -2.5127, -2.6738],
         [ 0.0765,  4.1095,  0.1824,  ...,  0.8542, -2.4041, -3.5164],
         [ 0.0838,  3.5584, -0.3215,  ...,  0.3976, -0.5743, -2.6838]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0765,  4.1095,  0.1824,  ...,  0.8542, -2.4041, -3.5164],
         [ 0.0838,  3.5584, -0.3215,  ...,  0.3976, -0.5743, -2.6838],
         [ 0.0323,  4.8245, -0.2093,  ..., -0.0269,  0.1834, -0.1022]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  14
logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0838,  3.5584, -0.3215,  ...,  0.3976, -0.5743, -2.6838],
         [ 0.0323,  4.8245, -0.2093,  ..., -0.0269,  0.1834, -0.1022],
         [ 0.0928, 12.4520, -0.1714,  ..., -0.9393,  1.7702, -0.3820]]],
       device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  14
Interior Secretary Ken Salazar pledges to keep 'boot on BP's neck' to help victims . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . US Coast Guard says 1,000 barrels a day are being captured . BP chief Tony Hayward says it could take 48 hours to know if system is working .
last_state =  tensor([ 0.0928, 12.4520, -0.1714,  ..., -0.9393,  1.7702, -0.3820],
       device='cuda:0')
final_logits =  tensor([[[ 0.1003,  2.4692,  0.6310,  ..., -2.8214,  2.5832, -0.1248],
         [ 0.0437,  2.4666,  0.3150,  ..., -0.5575, -0.3794, -0.9485],
         [ 0.0732,  2.8633, -0.0244,  ..., -1.3062, -0.3444, -1.9301],
         ...,
         [ 0.0838,  3.5584, -0.3215,  ...,  0.3976, -0.5743, -2.6838],
         [ 0.0323,  4.8245, -0.2093,  ..., -0.0269,  0.1834, -0.1022],
         [ 0.0928, 12.4520, -0.1714,  ..., -0.9393,  1.7702, -0.3820]]],
       device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-2.0060], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1391], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3006], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1416], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0320], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3182], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1279], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7890], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3763], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2450], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4388], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3724], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1963], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1722], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3410], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5265], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7739], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.9547], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9196], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0985], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2534], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6708], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1502], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1885], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2974], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5506], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1031], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0178], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3965], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0679], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7577], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0446], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3050], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0988], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0249], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2554], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3404], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2029], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8040], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5573], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5914], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1002], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.5035], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1766], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0420], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9755], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8469], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1447], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6468], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1013], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6198], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1357], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4942], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3198], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1042], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.0571], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5699], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3024], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2206], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6371], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8530], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4758], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2514], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1711], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0945], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1309], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4133], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2261], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9411], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3299], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0790], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2274], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1070], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8871], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-2.0060, -0.1391, -0.3006, -0.1416, -1.0320, -0.3182, -0.1279, -1.7890,
        -0.3763, -0.2450, -0.4388, -0.3724, -0.1963, -0.1722, -0.3410, -1.5265,
        -0.7739, -1.9547, -0.9196, -0.0985, -1.2534, -0.6708, -0.1502, -0.1885,
        -0.2974, -0.5506, -0.1031, -0.0178, -0.3965, -0.0679, -0.7577, -0.0446,
        -0.3050, -0.0988, -0.0249, -0.2554, -0.3404, -0.2029, -0.8040, -0.5573,
        -0.5914, -0.1002, -2.5035, -0.1766, -0.0420, -0.9755, -0.8469, -0.1447,
        -0.6468, -0.1013, -0.6198, -0.1357, -0.4942, -0.3198, -0.1042, -2.0571,
        -1.5699, -1.3024, -0.2206, -0.6371, -0.8530, -0.4758, -0.2514, -0.1711,
        -0.0945, -0.1309, -0.4133, -0.2261, -0.9411, -0.3299, -0.0790, -0.2274,
        -0.1070, -0.8871], device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,
         1.,  1.,  2.,  3.,  3.,  3.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,
         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  5.,  5.,  6.,  6.,  6.,
         6.,  7.,  8.,  9.,  9., 10., 10., 11., 11., 11., 12., 12., 12., 12.,
        12., 12., 13., 13., 13., 13., 13., 13., 14., 14., 14., 14., 14., 14.,
        14., 14., 14., 14.], device='cuda:0')
log_probs size =  torch.Size([74])
values size =  torch.Size([74])
returns size =  torch.Size([74])
advantages =  tensor([-3.5232e-02, -3.5232e-02, -3.5232e-02, -3.5232e-02,  9.6477e-01,
         9.6477e-01,  9.6477e-01,  9.6477e-01,  9.6477e-01,  9.6477e-01,
         1.9648e+00,  9.6477e-01,  9.6477e-01,  9.6477e-01,  9.6477e-01,
         9.6477e-01,  1.9648e+00,  2.9648e+00,  2.9648e+00,  2.9648e+00,
         3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,
         3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,
         3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,  3.9648e+00,
         3.9648e+00,  3.9648e+00,  4.9648e+00,  4.9648e+00,  5.9648e+00,
         5.9648e+00,  5.9648e+00,  5.9648e+00,  6.9648e+00,  7.9648e+00,
         8.9648e+00,  8.9648e+00,  9.9648e+00,  9.9648e+00,  1.0965e+01,
         1.0965e+01,  1.0965e+01,  1.1965e+01,  1.1965e+01,  1.1965e+01,
         1.1965e+01,  1.1965e+01,  1.1965e+01,  1.2965e+01,  1.2965e+01,
         1.2965e+01,  1.2965e+01,  1.2965e+01,  1.2965e+01,  1.3965e+01,
         1.5368e+02,  1.3965e+01,  1.3965e+01,  1.3965e+01,  1.3965e+01,
         1.3906e+01,  1.3965e+01,  1.3965e+01,  1.3965e+01], device='cuda:0')
actor_loss =  tensor(3.6743, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(28572.6875, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.1242,  2.4685,  0.6564,  ..., -2.8010,  2.5750, -0.1383]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1242,  2.4685,  0.6564,  ..., -2.8010,  2.5750, -0.1383],
         [ 0.0543,  2.5096,  0.3350,  ..., -0.5413, -0.3759, -0.9644]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00]]], device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         [ 4.6065e-02,  4.3215e+00,  1.4221e-01,  ...,  8.0828e-01,
           2.7078e-01, -9.6457e-01]]], device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1101e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         [ 4.6065e-02,  4.3215e+00,  1.4221e-01,  ...,  8.0828e-01,
           2.7078e-01, -9.6457e-01],
         [ 9.5523e-02,  2.3648e+00,  1.0531e-01,  ..., -1.6294e+00,
          -1.8623e+00, -1.6313e+00]]], device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3834e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         [ 4.6065e-02,  4.3215e+00,  1.4221e-01,  ...,  8.0828e-01,
           2.7078e-01, -9.6458e-01],
         [ 9.5523e-02,  2.3648e+00,  1.0531e-01,  ..., -1.6294e+00,
          -1.8623e+00, -1.6313e+00],
         [ 1.2564e-01,  3.1361e+00, -5.9323e-02,  ..., -1.6594e+00,
           1.2202e+00, -9.1757e-01]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3834e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.5523e-02,  2.3648e+00,  1.0531e-01,  ..., -1.6294e+00,
          -1.8623e+00, -1.6313e+00],
         [ 1.2564e-01,  3.1361e+00, -5.9323e-02,  ..., -1.6594e+00,
           1.2202e+00, -9.1757e-01],
         [ 9.8199e-02,  3.1459e+00,  5.5558e-01,  ..., -2.1041e+00,
          -5.5017e-02,  8.4976e-02]]], device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3834e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2564e-01,  3.1361e+00, -5.9323e-02,  ..., -1.6594e+00,
           1.2202e+00, -9.1757e-01],
         [ 9.8199e-02,  3.1459e+00,  5.5558e-01,  ..., -2.1041e+00,
          -5.5017e-02,  8.4976e-02],
         [ 1.0063e-01,  5.2655e-01,  2.1093e-01,  ..., -1.6660e+00,
           6.8428e-01, -2.8449e+00]]], device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.8199e-02,  3.1459e+00,  5.5558e-01,  ..., -2.1041e+00,
          -5.5018e-02,  8.4975e-02],
         [ 1.0063e-01,  5.2655e-01,  2.1093e-01,  ..., -1.6660e+00,
           6.8428e-01, -2.8449e+00],
         [ 3.1756e-02,  3.7219e+00,  2.4177e+00,  ...,  3.7701e+00,
          -4.5011e-01, -3.8718e-01]]], device='cuda:0')
action =  tensor(18457, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0063e-01,  5.2655e-01,  2.1093e-01,  ..., -1.6660e+00,
           6.8428e-01, -2.8449e+00],
         [ 3.1756e-02,  3.7219e+00,  2.4177e+00,  ...,  3.7701e+00,
          -4.5011e-01, -3.8718e-01],
         [ 6.9356e-02,  2.6418e+00,  2.4360e-01,  ..., -3.6706e+00,
          -4.5055e-01, -2.1127e+00]]], device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1100e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 3.1756e-02,  3.7219e+00,  2.4177e+00,  ...,  3.7701e+00,
          -4.5011e-01, -3.8718e-01],
         [ 6.9356e-02,  2.6418e+00,  2.4360e-01,  ..., -3.6706e+00,
          -4.5055e-01, -2.1127e+00],
         [ 7.7801e-02,  1.4906e+00, -7.7438e-02,  ..., -3.8513e+00,
           1.1849e+00, -2.2552e+00]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4129e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1101e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 6.9356e-02,  2.6418e+00,  2.4360e-01,  ..., -3.6706e+00,
          -4.5055e-01, -2.1127e+00],
         [ 7.7801e-02,  1.4906e+00, -7.7438e-02,  ..., -3.8513e+00,
           1.1849e+00, -2.2552e+00],
         [ 7.7097e-02,  2.1694e+00, -1.4799e-01,  ...,  3.6038e-01,
          -9.0509e-01, -1.1499e+00]]], device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4129e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1102e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.7801e-02,  1.4906e+00, -7.7438e-02,  ..., -3.8513e+00,
           1.1849e+00, -2.2552e+00],
         [ 7.7097e-02,  2.1694e+00, -1.4799e-01,  ...,  3.6038e-01,
          -9.0509e-01, -1.1499e+00],
         [ 7.3687e-02,  5.5136e+00, -4.2979e-01,  ..., -2.5959e-02,
          -6.0063e-01, -2.8725e+00]]], device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4129e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1102e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.7097e-02,  2.1694e+00, -1.4799e-01,  ...,  3.6038e-01,
          -9.0509e-01, -1.1499e+00],
         [ 7.3687e-02,  5.5136e+00, -4.2979e-01,  ..., -2.5959e-02,
          -6.0063e-01, -2.8725e+00],
         [ 4.1866e-02,  4.3795e+00,  6.5969e-02,  ..., -3.9166e-01,
          -5.9126e-01, -3.0112e-01]]], device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4129e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1101e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.3687e-02,  5.5136e+00, -4.2979e-01,  ..., -2.5961e-02,
          -6.0063e-01, -2.8725e+00],
         [ 4.1866e-02,  4.3795e+00,  6.5969e-02,  ..., -3.9166e-01,
          -5.9126e-01, -3.0112e-01],
         [ 7.9347e-02,  2.9693e+00, -3.4519e-01,  ..., -2.0555e+00,
           1.4381e+00, -2.7859e+00]]], device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4129e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1101e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 4.1866e-02,  4.3795e+00,  6.5969e-02,  ..., -3.9166e-01,
          -5.9126e-01, -3.0112e-01],
         [ 7.9347e-02,  2.9693e+00, -3.4519e-01,  ..., -2.0555e+00,
           1.4381e+00, -2.7859e+00],
         [ 1.4085e-01,  8.4344e+00, -4.8269e-01,  ..., -1.7288e+00,
           7.1061e-01, -2.7040e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.9347e-02,  2.9693e+00, -3.4519e-01,  ..., -2.0555e+00,
           1.4381e+00, -2.7859e+00],
         [ 1.4085e-01,  8.4344e+00, -4.8269e-01,  ..., -1.7288e+00,
           7.1061e-01, -2.7040e+00],
         [ 1.0654e-01, -3.5572e-01,  5.7366e-01,  ..., -2.8286e+00,
           1.9419e+00,  9.1472e-02]]], device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  2
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.4085e-01,  8.4344e+00, -4.8269e-01,  ..., -1.7288e+00,
           7.1061e-01, -2.7040e+00],
         [ 1.0654e-01, -3.5572e-01,  5.7366e-01,  ..., -2.8286e+00,
           1.9419e+00,  9.1472e-02],
         [ 1.1631e-01,  8.3206e-01,  2.0843e-01,  ..., -3.9970e+00,
           2.4669e+00,  2.7082e-01]]], device='cuda:0')
action =  tensor(4807, device='cuda:0')
reward =  3
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0654e-01, -3.5572e-01,  5.7366e-01,  ..., -2.8286e+00,
           1.9419e+00,  9.1472e-02],
         [ 1.1631e-01,  8.3206e-01,  2.0843e-01,  ..., -3.9970e+00,
           2.4669e+00,  2.7082e-01],
         [ 8.9451e-02,  1.8660e+00,  1.4104e-01,  ..., -2.0370e+00,
           7.8126e-01,  9.7325e-01]]], device='cuda:0')
action =  tensor(113, device='cuda:0')
reward =  3
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1631e-01,  8.3206e-01,  2.0843e-01,  ..., -3.9970e+00,
           2.4669e+00,  2.7082e-01],
         [ 8.9451e-02,  1.8660e+00,  1.4104e-01,  ..., -2.0370e+00,
           7.8126e-01,  9.7325e-01],
         [ 1.0190e-01,  2.4313e+00,  1.2138e-01,  ..., -2.6688e+00,
           1.2647e+00,  1.1410e+00]]], device='cuda:0')
action =  tensor(762, device='cuda:0')
reward =  4
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.9451e-02,  1.8660e+00,  1.4104e-01,  ..., -2.0370e+00,
           7.8126e-01,  9.7325e-01],
         [ 1.0190e-01,  2.4313e+00,  1.2138e-01,  ..., -2.6688e+00,
           1.2647e+00,  1.1410e+00],
         [ 8.9923e-02,  1.6680e+00,  8.1513e-02,  ..., -1.9016e+00,
           1.2005e+00,  7.6233e-01]]], device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0190e-01,  2.4313e+00,  1.2138e-01,  ..., -2.6688e+00,
           1.2647e+00,  1.1410e+00],
         [ 8.9923e-02,  1.6680e+00,  8.1513e-02,  ..., -1.9016e+00,
           1.2005e+00,  7.6233e-01],
         [ 9.3556e-02,  1.1103e+00, -3.2020e-01,  ..., -5.6758e-01,
           5.7100e-01, -1.0678e-01]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.9923e-02,  1.6680e+00,  8.1513e-02,  ..., -1.9016e+00,
           1.2005e+00,  7.6233e-01],
         [ 9.3556e-02,  1.1103e+00, -3.2020e-01,  ..., -5.6758e-01,
           5.7100e-01, -1.0678e-01],
         [ 4.0710e-02,  3.7344e+00, -1.8860e-01,  ..., -3.2024e-01,
           1.4022e-01, -5.9795e-02]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.3556e-02,  1.1103e+00, -3.2020e-01,  ..., -5.6758e-01,
           5.7100e-01, -1.0678e-01],
         [ 4.0710e-02,  3.7344e+00, -1.8860e-01,  ..., -3.2024e-01,
           1.4022e-01, -5.9795e-02],
         [ 1.2633e-01,  9.5288e+00,  5.0202e-01,  ..., -1.5123e+00,
           2.1221e+00, -3.6024e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 4.0710e-02,  3.7344e+00, -1.8860e-01,  ..., -3.2024e-01,
           1.4022e-01, -5.9795e-02],
         [ 1.2633e-01,  9.5288e+00,  5.0202e-01,  ..., -1.5123e+00,
           2.1221e+00, -3.6024e-01],
         [ 1.2376e-01,  2.4674e+00, -1.1049e-01,  ..., -2.1166e+00,
          -3.4147e-01, -1.2106e+00]]], device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2633e-01,  9.5288e+00,  5.0202e-01,  ..., -1.5123e+00,
           2.1221e+00, -3.6024e-01],
         [ 1.2376e-01,  2.4674e+00, -1.1049e-01,  ..., -2.1166e+00,
          -3.4147e-01, -1.2106e+00],
         [ 1.2768e-01,  1.7236e+00,  1.9127e-01,  ..., -1.6706e+00,
           3.4714e+00, -1.8304e+00]]], device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2376e-01,  2.4674e+00, -1.1049e-01,  ..., -2.1166e+00,
          -3.4147e-01, -1.2106e+00],
         [ 1.2768e-01,  1.7236e+00,  1.9127e-01,  ..., -1.6706e+00,
           3.4714e+00, -1.8304e+00],
         [ 9.0242e-02,  4.0985e+00,  5.4690e-01,  ...,  4.4037e-01,
          -6.1557e-01, -2.0053e+00]]], device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2768e-01,  1.7236e+00,  1.9127e-01,  ..., -1.6706e+00,
           3.4714e+00, -1.8304e+00],
         [ 9.0242e-02,  4.0985e+00,  5.4690e-01,  ...,  4.4037e-01,
          -6.1557e-01, -2.0053e+00],
         [ 5.8603e-02,  3.5604e+00,  2.1150e-01,  ..., -6.4759e-02,
          -9.6485e-01, -4.7972e-01]]], device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.0242e-02,  4.0985e+00,  5.4690e-01,  ...,  4.4037e-01,
          -6.1557e-01, -2.0053e+00],
         [ 5.8603e-02,  3.5604e+00,  2.1150e-01,  ..., -6.4759e-02,
          -9.6485e-01, -4.7972e-01],
         [ 1.3004e-01,  1.7466e+00, -1.3883e-01,  ..., -9.9007e-01,
           1.2538e+00, -1.7310e+00]]], device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 5.8603e-02,  3.5604e+00,  2.1150e-01,  ..., -6.4759e-02,
          -9.6485e-01, -4.7972e-01],
         [ 1.3004e-01,  1.7466e+00, -1.3883e-01,  ..., -9.9007e-01,
           1.2538e+00, -1.7310e+00],
         [ 7.1900e-02,  3.5162e+00,  3.9228e-01,  ..., -1.8505e+00,
           1.1521e+00, -2.6157e+00]]], device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3004e-01,  1.7466e+00, -1.3883e-01,  ..., -9.9007e-01,
           1.2538e+00, -1.7310e+00],
         [ 7.1900e-02,  3.5162e+00,  3.9228e-01,  ..., -1.8505e+00,
           1.1521e+00, -2.6157e+00],
         [ 5.2429e-02,  2.6706e+00,  5.1955e-01,  ..., -1.1111e+00,
          -1.1190e+00, -5.4804e-01]]], device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1094e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.1900e-02,  3.5162e+00,  3.9228e-01,  ..., -1.8505e+00,
           1.1521e+00, -2.6157e+00],
         [ 5.2429e-02,  2.6706e+00,  5.1955e-01,  ..., -1.1111e+00,
          -1.1190e+00, -5.4804e-01],
         [ 1.0100e-01,  2.7312e+00, -2.3309e-02,  ..., -2.9518e-01,
           2.0268e+00, -7.3167e-01]]], device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 5.2429e-02,  2.6706e+00,  5.1955e-01,  ..., -1.1111e+00,
          -1.1190e+00, -5.4804e-01],
         [ 1.0100e-01,  2.7312e+00, -2.3309e-02,  ..., -2.9519e-01,
           2.0268e+00, -7.3167e-01],
         [ 9.9819e-02,  2.8413e+00,  6.0714e-01,  ..., -4.0299e-01,
           1.9996e+00, -1.9768e+00]]], device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0100e-01,  2.7312e+00, -2.3309e-02,  ..., -2.9519e-01,
           2.0268e+00, -7.3167e-01],
         [ 9.9819e-02,  2.8413e+00,  6.0714e-01,  ..., -4.0299e-01,
           1.9996e+00, -1.9768e+00],
         [ 9.1363e-02,  3.1112e+00,  7.3894e-01,  ...,  4.4434e-01,
           1.2276e+00, -1.8227e+00]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.9819e-02,  2.8413e+00,  6.0714e-01,  ..., -4.0299e-01,
           1.9996e+00, -1.9768e+00],
         [ 9.1363e-02,  3.1112e+00,  7.3894e-01,  ...,  4.4434e-01,
           1.2276e+00, -1.8227e+00],
         [ 6.3026e-02,  4.2943e+00,  8.9328e-01,  ..., -4.6898e-01,
           3.4288e-01, -8.4711e-01]]], device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.1363e-02,  3.1112e+00,  7.3894e-01,  ...,  4.4434e-01,
           1.2276e+00, -1.8227e+00],
         [ 6.3026e-02,  4.2943e+00,  8.9328e-01,  ..., -4.6898e-01,
           3.4288e-01, -8.4711e-01],
         [ 5.8286e-02,  4.0592e+00,  6.3749e-02,  ..., -8.8925e-01,
          -9.1960e-01, -6.0907e-01]]], device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 6.3026e-02,  4.2943e+00,  8.9328e-01,  ..., -4.6898e-01,
           3.4288e-01, -8.4711e-01],
         [ 5.8286e-02,  4.0592e+00,  6.3749e-02,  ..., -8.8925e-01,
          -9.1960e-01, -6.0907e-01],
         [ 1.2241e-01,  3.0472e+00, -1.7767e-01,  ...,  1.0802e-01,
           7.5121e-01, -1.5232e+00]]], device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 5.8286e-02,  4.0592e+00,  6.3749e-02,  ..., -8.8925e-01,
          -9.1960e-01, -6.0907e-01],
         [ 1.2241e-01,  3.0472e+00, -1.7767e-01,  ...,  1.0802e-01,
           7.5121e-01, -1.5232e+00],
         [ 7.4838e-02,  4.1481e+00,  2.7385e-01,  ..., -1.1949e+00,
          -1.8452e+00, -3.7170e+00]]], device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2241e-01,  3.0472e+00, -1.7767e-01,  ...,  1.0802e-01,
           7.5121e-01, -1.5232e+00],
         [ 7.4838e-02,  4.1481e+00,  2.7385e-01,  ..., -1.1949e+00,
          -1.8452e+00, -3.7170e+00],
         [ 7.1104e-02,  3.6781e+00,  7.4645e-01,  ..., -1.1526e+00,
          -1.5959e-01, -2.7629e+00]]], device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.4838e-02,  4.1481e+00,  2.7385e-01,  ..., -1.1949e+00,
          -1.8452e+00, -3.7170e+00],
         [ 7.1104e-02,  3.6781e+00,  7.4645e-01,  ..., -1.1526e+00,
          -1.5959e-01, -2.7629e+00],
         [ 1.0320e-01,  3.6554e+00, -4.9304e-02,  ..., -3.0052e-01,
           1.1007e+00, -7.0539e-01]]], device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 7.1104e-02,  3.6781e+00,  7.4645e-01,  ..., -1.1526e+00,
          -1.5959e-01, -2.7629e+00],
         [ 1.0320e-01,  3.6554e+00, -4.9304e-02,  ..., -3.0052e-01,
           1.1007e+00, -7.0539e-01],
         [ 1.4865e-01,  4.0427e+00,  1.0535e-01,  ...,  5.2775e-01,
          -6.2721e-01, -2.0771e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0320e-01,  3.6554e+00, -4.9304e-02,  ..., -3.0052e-01,
           1.1007e+00, -7.0539e-01],
         [ 1.4865e-01,  4.0427e+00,  1.0535e-01,  ...,  5.2775e-01,
          -6.2721e-01, -2.0771e+00],
         [ 1.0519e-01,  1.1996e+00,  4.1236e-01,  ..., -3.0044e-01,
           1.4292e+00,  2.0446e+00]]], device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.4865e-01,  4.0427e+00,  1.0535e-01,  ...,  5.2775e-01,
          -6.2721e-01, -2.0771e+00],
         [ 1.0519e-01,  1.1996e+00,  4.1236e-01,  ..., -3.0044e-01,
           1.4292e+00,  2.0446e+00],
         [ 1.0258e-01,  1.3758e+00, -2.8222e-02,  ..., -1.5394e+00,
           6.2414e-01,  1.2754e+00]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0519e-01,  1.1996e+00,  4.1236e-01,  ..., -3.0044e-01,
           1.4292e+00,  2.0446e+00],
         [ 1.0258e-01,  1.3758e+00, -2.8222e-02,  ..., -1.5394e+00,
           6.2414e-01,  1.2754e+00],
         [ 9.2133e-02,  1.9877e+00,  3.0565e-01,  ..., -7.2982e-01,
           1.9018e+00,  1.9866e+00]]], device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.0258e-01,  1.3758e+00, -2.8222e-02,  ..., -1.5394e+00,
           6.2414e-01,  1.2754e+00],
         [ 9.2133e-02,  1.9877e+00,  3.0565e-01,  ..., -7.2982e-01,
           1.9018e+00,  1.9866e+00],
         [ 9.1966e-02,  2.2457e+00, -5.4591e-01,  ..., -4.6065e-01,
           2.7899e-01,  4.1474e-03]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.2133e-02,  1.9877e+00,  3.0565e-01,  ..., -7.2982e-01,
           1.9018e+00,  1.9866e+00],
         [ 9.1966e-02,  2.2457e+00, -5.4591e-01,  ..., -4.6065e-01,
           2.7899e-01,  4.1474e-03],
         [ 4.1288e-02,  4.0937e+00, -1.5183e-01,  ..., -3.1836e-01,
           1.6962e-01,  1.8975e-02]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.1966e-02,  2.2457e+00, -5.4591e-01,  ..., -4.6065e-01,
           2.7899e-01,  4.1474e-03],
         [ 4.1288e-02,  4.0937e+00, -1.5183e-01,  ..., -3.1836e-01,
           1.6962e-01,  1.8975e-02],
         [ 1.3820e-01,  1.1252e+01,  1.6467e-01,  ..., -1.2855e+00,
           2.6373e+00, -3.6610e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 4.1288e-02,  4.0937e+00, -1.5183e-01,  ..., -3.1836e-01,
           1.6962e-01,  1.8975e-02],
         [ 1.3820e-01,  1.1252e+01,  1.6467e-01,  ..., -1.2855e+00,
           2.6373e+00, -3.6610e-01],
         [ 1.1997e-01,  4.0160e+00, -6.5791e-02,  ..., -1.0291e+00,
          -1.5717e-01, -1.5417e+00]]], device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3820e-01,  1.1252e+01,  1.6467e-01,  ..., -1.2855e+00,
           2.6373e+00, -3.6610e-01],
         [ 1.1997e-01,  4.0160e+00, -6.5791e-02,  ..., -1.0291e+00,
          -1.5717e-01, -1.5417e+00],
         [ 1.3865e-01,  1.5299e+00, -3.6542e-01,  ..., -2.5318e+00,
           1.4239e+00, -3.5181e-02]]], device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1997e-01,  4.0160e+00, -6.5791e-02,  ..., -1.0291e+00,
          -1.5717e-01, -1.5417e+00],
         [ 1.3865e-01,  1.5299e+00, -3.6542e-01,  ..., -2.5318e+00,
           1.4239e+00, -3.5181e-02],
         [ 8.6200e-02,  3.2055e+00, -1.3023e-01,  ..., -1.7120e-01,
           1.1018e+00, -2.2460e-01]]], device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3865e-01,  1.5299e+00, -3.6542e-01,  ..., -2.5318e+00,
           1.4239e+00, -3.5181e-02],
         [ 8.6200e-02,  3.2055e+00, -1.3023e-01,  ..., -1.7120e-01,
           1.1018e+00, -2.2460e-01],
         [ 1.1886e-01,  1.6154e+00,  2.1531e-01,  ..., -8.5036e-01,
           9.2970e-01, -1.3691e-01]]], device='cuda:0')
action =  tensor(129, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.6200e-02,  3.2055e+00, -1.3023e-01,  ..., -1.7120e-01,
           1.1018e+00, -2.2460e-01],
         [ 1.1886e-01,  1.6154e+00,  2.1531e-01,  ..., -8.5036e-01,
           9.2970e-01, -1.3691e-01],
         [ 1.3101e-01,  1.9542e+00,  2.4208e-01,  ..., -2.7477e+00,
           8.4398e-01, -2.3008e+00]]], device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1886e-01,  1.6154e+00,  2.1531e-01,  ..., -8.5036e-01,
           9.2970e-01, -1.3691e-01],
         [ 1.3101e-01,  1.9542e+00,  2.4208e-01,  ..., -2.7477e+00,
           8.4398e-01, -2.3008e+00],
         [ 1.2551e-01,  1.1226e+00,  1.8839e-01,  ..., -4.6528e-01,
           7.0894e-01, -1.6232e-01]]], device='cuda:0')
action =  tensor(1900, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3101e-01,  1.9542e+00,  2.4208e-01,  ..., -2.7477e+00,
           8.4398e-01, -2.3008e+00],
         [ 1.2551e-01,  1.1226e+00,  1.8839e-01,  ..., -4.6528e-01,
           7.0894e-01, -1.6232e-01],
         [ 1.2023e-01,  1.4931e+00, -2.6915e-01,  ...,  8.9879e-01,
          -1.5547e-01, -6.6414e-01]]], device='cuda:0')
action =  tensor(269, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2551e-01,  1.1226e+00,  1.8839e-01,  ..., -4.6528e-01,
           7.0894e-01, -1.6232e-01],
         [ 1.2023e-01,  1.4931e+00, -2.6915e-01,  ...,  8.9879e-01,
          -1.5547e-01, -6.6414e-01],
         [ 1.3490e-01,  2.7395e+00,  2.0433e-01,  ..., -1.4449e+00,
           1.2804e+00, -3.0867e+00]]], device='cuda:0')
action =  tensor(847, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2023e-01,  1.4931e+00, -2.6915e-01,  ...,  8.9879e-01,
          -1.5547e-01, -6.6414e-01],
         [ 1.3490e-01,  2.7395e+00,  2.0433e-01,  ..., -1.4449e+00,
           1.2804e+00, -3.0867e+00],
         [ 1.3905e-01,  2.9474e+00, -2.0195e-03,  ..., -1.2290e-01,
           2.9966e-01, -1.6318e+00]]], device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3490e-01,  2.7395e+00,  2.0433e-01,  ..., -1.4449e+00,
           1.2804e+00, -3.0867e+00],
         [ 1.3905e-01,  2.9474e+00, -2.0195e-03,  ..., -1.2290e-01,
           2.9966e-01, -1.6318e+00],
         [ 1.2516e-01,  2.4191e+00,  2.9022e-01,  ...,  6.6797e-01,
           1.1510e+00, -7.7417e-01]]], device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.3905e-01,  2.9474e+00, -2.0195e-03,  ..., -1.2290e-01,
           2.9966e-01, -1.6318e+00],
         [ 1.2516e-01,  2.4191e+00,  2.9022e-01,  ...,  6.6797e-01,
           1.1510e+00, -7.7417e-01],
         [ 6.0648e-02,  2.5862e+00,  1.9447e+00,  ...,  2.4441e+00,
           1.3122e+00,  4.6194e-01]]], device='cuda:0')
action =  tensor(5891, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2516e-01,  2.4191e+00,  2.9022e-01,  ...,  6.6797e-01,
           1.1510e+00, -7.7417e-01],
         [ 6.0648e-02,  2.5862e+00,  1.9447e+00,  ...,  2.4441e+00,
           1.3122e+00,  4.6194e-01],
         [ 8.2066e-02,  4.1694e+00,  4.4822e-01,  ..., -1.4355e+00,
           2.8678e-01, -1.1622e+00]]], device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  9
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 6.0648e-02,  2.5862e+00,  1.9447e+00,  ...,  2.4441e+00,
           1.3122e+00,  4.6194e-01],
         [ 8.2066e-02,  4.1694e+00,  4.4822e-01,  ..., -1.4355e+00,
           2.8678e-01, -1.1622e+00],
         [ 8.3616e-02,  2.7268e+00,  6.8281e-03,  ..., -2.5804e-01,
           1.9990e+00, -1.0443e+00]]], device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  8
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.2066e-02,  4.1694e+00,  4.4822e-01,  ..., -1.4355e+00,
           2.8678e-01, -1.1622e+00],
         [ 8.3616e-02,  2.7268e+00,  6.8281e-03,  ..., -2.5804e-01,
           1.9990e+00, -1.0443e+00],
         [ 1.1945e-01,  6.2209e+00,  3.2908e-02,  ...,  1.0170e+00,
           2.1622e+00, -3.1360e+00]]], device='cuda:0')
action =  tensor(5469, device='cuda:0')
reward =  9
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.3616e-02,  2.7268e+00,  6.8281e-03,  ..., -2.5804e-01,
           1.9990e+00, -1.0443e+00],
         [ 1.1945e-01,  6.2209e+00,  3.2908e-02,  ...,  1.0170e+00,
           2.1622e+00, -3.1360e+00],
         [ 1.2401e-01,  4.1407e+00, -4.3444e-01,  ..., -3.8177e-01,
           5.9537e-01, -1.9302e+00]]], device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  9
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1945e-01,  6.2209e+00,  3.2908e-02,  ...,  1.0170e+00,
           2.1622e+00, -3.1360e+00],
         [ 1.2401e-01,  4.1407e+00, -4.3444e-01,  ..., -3.8177e-01,
           5.9537e-01, -1.9302e+00],
         [ 8.9647e-02,  3.1356e+00,  4.8306e-01,  ..., -5.0247e-02,
           8.4676e-01, -8.9670e-01]]], device='cuda:0')
action =  tensor(4800, device='cuda:0')
reward =  10
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.2401e-01,  4.1407e+00, -4.3444e-01,  ..., -3.8177e-01,
           5.9537e-01, -1.9302e+00],
         [ 8.9647e-02,  3.1356e+00,  4.8306e-01,  ..., -5.0247e-02,
           8.4676e-01, -8.9670e-01],
         [ 9.8850e-02,  3.9239e+00, -2.9245e-01,  ..., -4.5901e-01,
           2.3411e-01,  8.7626e-01]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  10
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.9647e-02,  3.1356e+00,  4.8306e-01,  ..., -5.0247e-02,
           8.4676e-01, -8.9670e-01],
         [ 9.8850e-02,  3.9239e+00, -2.9245e-01,  ..., -4.5901e-01,
           2.3411e-01,  8.7626e-01],
         [ 9.6035e-02,  2.7535e+00,  3.5352e-01,  ..., -6.6413e-01,
           1.3543e+00,  1.7789e+00]]], device='cuda:0')
action =  tensor(8186, device='cuda:0')
reward =  11
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.8850e-02,  3.9239e+00, -2.9245e-01,  ..., -4.5901e-01,
           2.3411e-01,  8.7626e-01],
         [ 9.6035e-02,  2.7535e+00,  3.5352e-01,  ..., -6.6413e-01,
           1.3543e+00,  1.7789e+00],
         [ 1.1055e-01,  3.5020e+00, -4.9303e-01,  ...,  4.1566e-01,
           3.4354e-01, -1.0704e+00]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  11
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 9.6035e-02,  2.7535e+00,  3.5352e-01,  ..., -6.6413e-01,
           1.3543e+00,  1.7789e+00],
         [ 1.1055e-01,  3.5020e+00, -4.9303e-01,  ...,  4.1566e-01,
           3.4354e-01, -1.0704e+00],
         [ 4.6585e-02,  4.2673e+00, -1.6851e-01,  ..., -3.1575e-01,
           8.8232e-03, -2.7528e-01]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  11
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1055e-01,  3.5020e+00, -4.9303e-01,  ...,  4.1566e-01,
           3.4354e-01, -1.0704e+00],
         [ 4.6585e-02,  4.2673e+00, -1.6851e-01,  ..., -3.1575e-01,
           8.8232e-03, -2.7528e-01],
         [ 1.4217e-01,  1.0318e+01,  5.0859e-02,  ..., -6.9252e-01,
           1.2370e+00, -1.8633e+00]]], device='cuda:0')
action =  tensor(2218, device='cuda:0')
reward =  11
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 4.6585e-02,  4.2673e+00, -1.6851e-01,  ..., -3.1575e-01,
           8.8232e-03, -2.7528e-01],
         [ 1.4217e-01,  1.0318e+01,  5.0859e-02,  ..., -6.9252e-01,
           1.2370e+00, -1.8633e+00],
         [ 8.3836e-02,  4.6064e+00,  5.2819e-01,  ..., -1.3266e+00,
           1.6092e-01, -8.2352e-01]]], device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.4217e-01,  1.0318e+01,  5.0859e-02,  ..., -6.9252e-01,
           1.2370e+00, -1.8633e+00],
         [ 8.3836e-02,  4.6064e+00,  5.2819e-01,  ..., -1.3266e+00,
           1.6092e-01, -8.2352e-01],
         [ 1.1751e-01,  4.4815e+00, -6.6317e-02,  ..., -5.2225e-01,
           2.6830e+00, -1.5155e+00]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 8.3836e-02,  4.6064e+00,  5.2819e-01,  ..., -1.3266e+00,
           1.6092e-01, -8.2352e-01],
         [ 1.1751e-01,  4.4815e+00, -6.6317e-02,  ..., -5.2225e-01,
           2.6830e+00, -1.5155e+00],
         [ 6.6149e-02,  5.0653e+00,  1.5643e-01,  ..., -1.3985e+00,
           5.9270e-01,  1.0138e-02]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  12
logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1751e-01,  4.4815e+00, -6.6317e-02,  ..., -5.2225e-01,
           2.6830e+00, -1.5155e+00],
         [ 6.6149e-02,  5.0653e+00,  1.5643e-01,  ..., -1.3985e+00,
           5.9270e-01,  1.0138e-02],
         [ 1.3938e-01,  1.0191e+01, -4.5782e-02,  ..., -5.7625e-01,
           1.3132e+00, -1.4356e+00]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  12
Interior Secretary Ken Salazar pledges to keep 'boot on BP's neck' to help victims of oil spill . BP pledges $ 500m -LRB- # 346m -RRB- to study the spill . BP says it will be on Wednesday before trying a 'top kill' bid to plug the leak . Top kill .
last_state =  tensor([ 0.1394, 10.1915, -0.0458,  ..., -0.5762,  1.3132, -1.4356],
       device='cuda:0')
final_logits =  tensor([[[ 1.2416e-01,  2.4685e+00,  6.5635e-01,  ..., -2.8010e+00,
           2.5750e+00, -1.3835e-01],
         [ 5.4263e-02,  2.5096e+00,  3.3503e-01,  ..., -5.4130e-01,
          -3.7592e-01, -9.6443e-01],
         [ 9.0780e-02,  2.8961e+00, -2.1099e-03,  ..., -1.3099e+00,
          -3.5468e-01, -1.8845e+00],
         ...,
         [ 1.1751e-01,  4.4815e+00, -6.6317e-02,  ..., -5.2225e-01,
           2.6830e+00, -1.5155e+00],
         [ 6.6149e-02,  5.0653e+00,  1.5643e-01,  ..., -1.3985e+00,
           5.9270e-01,  1.0138e-02],
         [ 1.3938e-01,  1.0191e+01, -4.5782e-02,  ..., -5.7625e-01,
           1.3132e+00, -1.4356e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-2.0819], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1409], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2965], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1421], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0772], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3252], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1202], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7168], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3225], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2619], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3992], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3896], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2221], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1791], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3426], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4417], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7736], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.9929], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9657], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4677], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9832], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1796], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1012], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2117], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8655], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1709], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1898], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3107], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5534], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1546], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0199], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4955], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0804], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8002], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0205], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0491], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2835], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1051], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0392], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4228], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5593], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2106], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8852], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5135], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5483], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1008], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.1964], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5553], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5007], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5613], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2777], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.8840], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4192], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2513], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4678], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7792], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.0873], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0935], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2839], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2809], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1056], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4087], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2669], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4728], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4039], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6281], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1045], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4956], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4408], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7673], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1038], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.5200], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-2.0819, -0.1409, -0.2965, -0.1421, -1.0772, -0.3252, -0.1202, -1.7168,
        -0.3225, -0.2619, -0.3992, -0.3896, -0.2221, -0.1791, -0.3426, -1.4417,
        -0.7736, -1.9929, -0.9657, -1.4677, -0.9832, -0.1796, -0.1012, -1.2117,
        -0.8655, -0.1709, -0.1898, -0.3107, -0.5534, -0.1546, -0.0199, -0.4955,
        -0.0804, -0.8002, -0.0205, -0.0491, -0.2835, -0.1051, -0.0392, -0.4228,
        -0.5593, -0.2106, -0.8852, -0.5135, -0.5483, -0.1008, -2.1964, -1.5553,
        -0.5007, -0.5613, -1.2777, -2.8840, -0.4192, -0.2513, -1.4678, -0.7792,
        -1.0873, -0.0935, -0.2839, -0.2809, -1.1056, -0.4087, -0.2669, -0.4728,
        -0.4039, -0.6281, -0.1045, -1.4956, -0.4408, -1.7673, -0.1038, -2.5200],
       device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([ 0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,
         1.,  1.,  2.,  3.,  3.,  4.,  5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,
         6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,
         7.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  9.,  8.,  9.,  9., 10., 10., 11., 11., 11., 11., 12., 12.,
        12., 12.], device='cuda:0')
log_probs size =  torch.Size([72])
values size =  torch.Size([72])
returns size =  torch.Size([72])
advantages =  tensor([-3.4856e-02, -3.4856e-02, -3.4856e-02, -3.4856e-02,  9.6514e-01,
         9.6514e-01,  9.6514e-01,  9.6514e-01,  9.6514e-01,  9.6514e-01,
         1.9651e+00,  9.6514e-01,  9.6514e-01,  9.6514e-01,  7.7129e+00,
         9.6514e-01,  1.9651e+00,  2.9651e+00,  2.9651e+00,  3.9651e+00,
         4.9651e+00,  4.9651e+00,  4.9651e+00,  5.9651e+00,  5.9651e+00,
         5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,
         5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,
         5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,  5.9651e+00,
         5.9651e+00,  6.9651e+00,  6.9651e+00,  6.9651e+00,  6.9651e+00,
         6.9651e+00,  6.9651e+00,  7.9651e+00,  7.9651e+00,  7.9651e+00,
         7.9651e+00,  7.9651e+00,  7.9651e+00,  7.9651e+00,  7.9651e+00,
         7.9651e+00,  7.9651e+00,  7.9651e+00,  8.9651e+00,  7.9651e+00,
         8.9651e+00,  8.9651e+00,  9.9651e+00, -3.6227e+01,  1.0965e+01,
         1.0965e+01,  1.0965e+01,  1.0965e+01,  1.1965e+01,  1.1965e+01,
         1.1965e+01,  1.1965e+01], device='cuda:0')
actor_loss =  tensor(3.8552, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(4583.0742, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739]]],
       device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417]]],
       device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         [ 0.0543,  4.3462,  0.1602,  ...,  0.8303,  0.2627, -0.9442]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         [ 0.0543,  4.3462,  0.1602,  ...,  0.8303,  0.2627, -0.9442],
         [ 0.1113,  2.3869,  0.1230,  ..., -1.5707, -1.8658, -1.5789]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         [ 0.0543,  4.3462,  0.1602,  ...,  0.8303,  0.2627, -0.9442],
         [ 0.1113,  2.3869,  0.1230,  ..., -1.5707, -1.8658, -1.5789],
         [ 0.1470,  3.1606, -0.0298,  ..., -1.6064,  1.2937, -0.8598]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1113,  2.3869,  0.1230,  ..., -1.5707, -1.8658, -1.5789],
         [ 0.1470,  3.1606, -0.0298,  ..., -1.6064,  1.2937, -0.8598],
         [ 0.1143,  3.1839,  0.5678,  ..., -2.0419, -0.0339,  0.1107]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1470,  3.1606, -0.0298,  ..., -1.6064,  1.2937, -0.8598],
         [ 0.1143,  3.1839,  0.5678,  ..., -2.0419, -0.0339,  0.1107],
         [ 0.1198,  0.5395,  0.2525,  ..., -1.6397,  0.6933, -2.7433]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1143,  3.1839,  0.5678,  ..., -2.0419, -0.0339,  0.1107],
         [ 0.1198,  0.5395,  0.2525,  ..., -1.6397,  0.6933, -2.7433],
         [ 0.0369,  3.7128,  2.4771,  ...,  3.9242, -0.4342, -0.2270]]],
       device='cuda:0')
action =  tensor(18457, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1198,  0.5395,  0.2525,  ..., -1.6397,  0.6933, -2.7433],
         [ 0.0369,  3.7128,  2.4771,  ...,  3.9242, -0.4342, -0.2270],
         [ 0.0806,  2.7367,  0.2552,  ..., -3.6808, -0.5155, -2.1953]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0369,  3.7128,  2.4771,  ...,  3.9242, -0.4342, -0.2270],
         [ 0.0806,  2.7367,  0.2552,  ..., -3.6808, -0.5155, -2.1953],
         [ 0.0932,  1.5442, -0.0564,  ..., -3.8183,  1.1768, -2.2984]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0806,  2.7367,  0.2552,  ..., -3.6808, -0.5155, -2.1953],
         [ 0.0932,  1.5442, -0.0564,  ..., -3.8183,  1.1768, -2.2984],
         [ 0.0913,  2.2347, -0.1365,  ...,  0.3272, -0.9483, -1.1614]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0932,  1.5442, -0.0564,  ..., -3.8183,  1.1768, -2.2984],
         [ 0.0913,  2.2347, -0.1365,  ...,  0.3272, -0.9483, -1.1614],
         [ 0.0907,  5.5086, -0.4472,  ..., -0.2469, -0.8245, -3.2480]]],
       device='cuda:0')
action =  tensor(116, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0913,  2.2347, -0.1365,  ...,  0.3272, -0.9483, -1.1614],
         [ 0.0907,  5.5086, -0.4472,  ..., -0.2469, -0.8245, -3.2480],
         [ 0.0498,  4.4278,  0.0816,  ..., -0.4309, -0.6153, -0.3328]]],
       device='cuda:0')
action =  tensor(3464, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0907,  5.5086, -0.4472,  ..., -0.2469, -0.8245, -3.2480],
         [ 0.0498,  4.4278,  0.0816,  ..., -0.4309, -0.6153, -0.3328],
         [ 0.0932,  2.9896, -0.3343,  ..., -2.0371,  1.4592, -2.7899]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0498,  4.4278,  0.0816,  ..., -0.4309, -0.6153, -0.3328],
         [ 0.0932,  2.9896, -0.3343,  ..., -2.0371,  1.4592, -2.7899],
         [ 0.1605,  8.1238, -0.4945,  ..., -1.4391,  0.5874, -2.9558]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0932,  2.9896, -0.3343,  ..., -2.0371,  1.4592, -2.7899],
         [ 0.1605,  8.1238, -0.4945,  ..., -1.4391,  0.5874, -2.9558],
         [ 0.1270, -0.2211,  0.5804,  ..., -2.7064,  1.9455,  0.1311]]],
       device='cuda:0')
action =  tensor(225, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1605,  8.1238, -0.4945,  ..., -1.4391,  0.5874, -2.9558],
         [ 0.1270, -0.2211,  0.5804,  ..., -2.7064,  1.9455,  0.1311],
         [ 0.1386,  0.9088,  0.2224,  ..., -3.9318,  2.5664,  0.3206]]],
       device='cuda:0')
action =  tensor(4807, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1270, -0.2211,  0.5804,  ..., -2.7064,  1.9455,  0.1311],
         [ 0.1386,  0.9088,  0.2224,  ..., -3.9318,  2.5664,  0.3206],
         [ 0.1073,  1.9629,  0.1578,  ..., -1.9953,  0.7461,  1.0551]]],
       device='cuda:0')
action =  tensor(113, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1386,  0.9088,  0.2224,  ..., -3.9318,  2.5664,  0.3206],
         [ 0.1073,  1.9629,  0.1578,  ..., -1.9953,  0.7461,  1.0551],
         [ 0.1230,  2.5578,  0.1375,  ..., -2.6605,  1.3209,  1.1654]]],
       device='cuda:0')
action =  tensor(762, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1073,  1.9629,  0.1578,  ..., -1.9953,  0.7461,  1.0551],
         [ 0.1230,  2.5578,  0.1375,  ..., -2.6605,  1.3209,  1.1654],
         [ 0.1067,  1.7824,  0.0997,  ..., -1.8257,  1.1983,  0.8198]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1230,  2.5578,  0.1375,  ..., -2.6605,  1.3209,  1.1654],
         [ 0.1067,  1.7824,  0.0997,  ..., -1.8257,  1.1983,  0.8198],
         [ 0.1099,  1.2535, -0.2944,  ..., -0.4533,  0.5336, -0.1446]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1067,  1.7824,  0.0997,  ..., -1.8257,  1.1983,  0.8198],
         [ 0.1099,  1.2535, -0.2944,  ..., -0.4533,  0.5336, -0.1446],
         [ 0.0473,  3.7631, -0.1780,  ..., -0.3281,  0.1382, -0.0533]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1099,  1.2535, -0.2944,  ..., -0.4533,  0.5336, -0.1446],
         [ 0.0473,  3.7631, -0.1780,  ..., -0.3281,  0.1382, -0.0533],
         [ 0.1476,  9.6777,  0.5088,  ..., -1.6274,  2.1097, -0.3855]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0473,  3.7631, -0.1780,  ..., -0.3281,  0.1382, -0.0533],
         [ 0.1476,  9.6777,  0.5088,  ..., -1.6274,  2.1097, -0.3855],
         [ 0.1447,  2.5589, -0.0967,  ..., -2.0744, -0.2779, -1.2272]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1476,  9.6777,  0.5088,  ..., -1.6274,  2.1097, -0.3855],
         [ 0.1447,  2.5589, -0.0967,  ..., -2.0744, -0.2779, -1.2272],
         [ 0.1501,  1.8184,  0.2131,  ..., -1.6086,  3.5159, -1.7779]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1447,  2.5589, -0.0967,  ..., -2.0744, -0.2779, -1.2272],
         [ 0.1501,  1.8184,  0.2131,  ..., -1.6086,  3.5159, -1.7779],
         [ 0.1050,  4.1523,  0.5684,  ...,  0.4655, -0.5935, -1.9912]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1501,  1.8184,  0.2131,  ..., -1.6086,  3.5159, -1.7779],
         [ 0.1050,  4.1523,  0.5684,  ...,  0.4655, -0.5935, -1.9912],
         [ 0.0684,  3.6071,  0.2128,  ..., -0.0447, -0.9737, -0.4898]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1050,  4.1523,  0.5684,  ...,  0.4655, -0.5935, -1.9912],
         [ 0.0684,  3.6071,  0.2128,  ..., -0.0447, -0.9737, -0.4898],
         [ 0.1508,  1.8782, -0.1382,  ..., -0.9441,  1.2532, -1.6720]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0684,  3.6071,  0.2128,  ..., -0.0447, -0.9737, -0.4898],
         [ 0.1508,  1.8782, -0.1382,  ..., -0.9441,  1.2532, -1.6720],
         [ 0.0854,  3.4658,  0.3848,  ..., -1.7402,  1.2119, -2.7217]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1508,  1.8782, -0.1382,  ..., -0.9441,  1.2532, -1.6720],
         [ 0.0854,  3.4658,  0.3848,  ..., -1.7402,  1.2119, -2.7217],
         [ 0.0604,  2.7664,  0.5212,  ..., -1.1258, -1.1227, -0.5644]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0854,  3.4658,  0.3848,  ..., -1.7402,  1.2119, -2.7217],
         [ 0.0604,  2.7664,  0.5212,  ..., -1.1258, -1.1227, -0.5644],
         [ 0.1185,  2.7803, -0.0405,  ..., -0.3494,  2.0367, -0.6968]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0604,  2.7664,  0.5212,  ..., -1.1258, -1.1227, -0.5644],
         [ 0.1185,  2.7803, -0.0405,  ..., -0.3494,  2.0367, -0.6968],
         [ 0.1149,  2.9378,  0.6427,  ..., -0.3236,  1.9716, -2.0575]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1185,  2.7803, -0.0405,  ..., -0.3494,  2.0367, -0.6968],
         [ 0.1149,  2.9378,  0.6427,  ..., -0.3236,  1.9716, -2.0575],
         [ 0.1066,  3.1583,  0.7406,  ...,  0.4178,  1.2484, -1.8385]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1149,  2.9378,  0.6427,  ..., -0.3236,  1.9716, -2.0575],
         [ 0.1066,  3.1583,  0.7406,  ...,  0.4178,  1.2484, -1.8385],
         [ 0.0729,  4.3381,  0.8774,  ..., -0.4995,  0.3983, -0.7557]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1066,  3.1583,  0.7406,  ...,  0.4178,  1.2484, -1.8385],
         [ 0.0729,  4.3381,  0.8774,  ..., -0.4995,  0.3983, -0.7557],
         [ 0.0681,  4.0698,  0.0730,  ..., -0.8426, -0.9254, -0.6634]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0729,  4.3381,  0.8774,  ..., -0.4995,  0.3983, -0.7557],
         [ 0.0681,  4.0698,  0.0730,  ..., -0.8426, -0.9254, -0.6634],
         [ 0.1430,  3.0998, -0.1754,  ...,  0.1357,  0.7825, -1.4978]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0681,  4.0698,  0.0730,  ..., -0.8426, -0.9254, -0.6634],
         [ 0.1430,  3.0998, -0.1754,  ...,  0.1357,  0.7825, -1.4978],
         [ 0.0906,  4.0341,  0.2907,  ..., -1.1297, -1.7506, -3.8621]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1430,  3.0998, -0.1754,  ...,  0.1357,  0.7825, -1.4978],
         [ 0.0906,  4.0341,  0.2907,  ..., -1.1297, -1.7506, -3.8621],
         [ 0.0847,  3.6632,  0.7981,  ..., -0.9709,  0.0877, -2.8250]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0906,  4.0341,  0.2907,  ..., -1.1297, -1.7506, -3.8621],
         [ 0.0847,  3.6632,  0.7981,  ..., -0.9709,  0.0877, -2.8250],
         [ 0.1212,  3.7388, -0.0552,  ..., -0.3399,  1.2119, -0.6742]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.0847,  3.6632,  0.7981,  ..., -0.9709,  0.0877, -2.8250],
         [ 0.1212,  3.7388, -0.0552,  ..., -0.3399,  1.2119, -0.6742],
         [ 0.1703,  4.0908,  0.1452,  ...,  0.6134, -0.4863, -2.1793]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1212,  3.7388, -0.0552,  ..., -0.3399,  1.2119, -0.6742],
         [ 0.1703,  4.0908,  0.1452,  ...,  0.6134, -0.4863, -2.1793],
         [ 0.1240,  1.1870,  0.4221,  ..., -0.1984,  1.5275,  2.1122]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1703,  4.0908,  0.1452,  ...,  0.6134, -0.4863, -2.1793],
         [ 0.1240,  1.1870,  0.4221,  ..., -0.1984,  1.5275,  2.1122],
         [ 0.1229,  1.4271, -0.0095,  ..., -1.4981,  0.6829,  1.3383]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1240,  1.1870,  0.4221,  ..., -0.1984,  1.5275,  2.1122],
         [ 0.1229,  1.4271, -0.0095,  ..., -1.4981,  0.6829,  1.3383],
         [ 0.1093,  2.0270,  0.3401,  ..., -0.5702,  1.8960,  2.0026]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1229,  1.4271, -0.0095,  ..., -1.4981,  0.6829,  1.3383],
         [ 0.1093,  2.0270,  0.3401,  ..., -0.5702,  1.8960,  2.0026],
         [ 0.1092,  2.2266, -0.5301,  ..., -0.3963,  0.3517,  0.0491]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1093,  2.0270,  0.3401,  ..., -0.5702,  1.8960,  2.0026],
         [ 0.1092,  2.2266, -0.5301,  ..., -0.3963,  0.3517,  0.0491],
         [ 0.0487,  3.9628, -0.1032,  ..., -0.2462,  0.2523, -0.0094]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.4397e-01,  2.4389e+00,  6.7658e-01,  ..., -2.7710e+00,
           2.5429e+00, -1.5494e-01],
         [ 6.3132e-02,  2.5315e+00,  3.5219e-01,  ..., -5.1777e-01,
          -3.8187e-01, -9.7394e-01],
         [ 1.0573e-01,  2.9039e+00,  1.8984e-02,  ..., -1.3028e+00,
          -3.6607e-01, -1.8417e+00],
         ...,
         [ 1.0916e-01,  2.2266e+00, -5.3010e-01,  ..., -3.9634e-01,
           3.5172e-01,  4.9080e-02],
         [ 4.8744e-02,  3.9628e+00, -1.0323e-01,  ..., -2.4616e-01,
           2.5233e-01, -9.4121e-03],
         [ 1.6088e-01,  1.1292e+01,  1.3775e-01,  ..., -1.2617e+00,
           2.9048e+00, -7.9460e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  7
logits =  tensor([[[ 1.4397e-01,  2.4389e+00,  6.7658e-01,  ..., -2.7710e+00,
           2.5429e+00, -1.5494e-01],
         [ 6.3132e-02,  2.5315e+00,  3.5219e-01,  ..., -5.1777e-01,
          -3.8187e-01, -9.7394e-01],
         [ 1.0573e-01,  2.9039e+00,  1.8984e-02,  ..., -1.3028e+00,
          -3.6607e-01, -1.8417e+00],
         ...,
         [ 4.8744e-02,  3.9628e+00, -1.0323e-01,  ..., -2.4616e-01,
           2.5233e-01, -9.4121e-03],
         [ 1.6088e-01,  1.1292e+01,  1.3775e-01,  ..., -1.2617e+00,
           2.9048e+00, -7.9460e-01],
         [ 1.4279e-01,  4.3353e+00, -8.1611e-02,  ..., -8.8855e-01,
          -1.5796e-01, -1.4288e+00]]], device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1609, 11.2923,  0.1378,  ..., -1.2617,  2.9048, -0.7946],
         [ 0.1428,  4.3353, -0.0816,  ..., -0.8886, -0.1580, -1.4288],
         [ 0.1631,  1.8368, -0.3890,  ..., -2.4193,  1.6248,  0.0510]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1428,  4.3353, -0.0816,  ..., -0.8886, -0.1580, -1.4288],
         [ 0.1631,  1.8368, -0.3890,  ..., -2.4193,  1.6248,  0.0510],
         [ 0.1047,  3.3105, -0.1228,  ...,  0.0230,  1.0686, -0.1429]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1631,  1.8368, -0.3890,  ..., -2.4193,  1.6248,  0.0510],
         [ 0.1047,  3.3105, -0.1228,  ...,  0.0230,  1.0686, -0.1429],
         [ 0.1391,  1.6077,  0.2523,  ..., -0.6387,  0.8117,  0.1086]]],
       device='cuda:0')
action =  tensor(129, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1047,  3.3105, -0.1228,  ...,  0.0230,  1.0686, -0.1429],
         [ 0.1391,  1.6077,  0.2523,  ..., -0.6387,  0.8117,  0.1086],
         [ 0.1575,  1.8034,  0.2499,  ..., -2.6593,  1.1191, -1.7751]]],
       device='cuda:0')
action =  tensor(479, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1391,  1.6077,  0.2523,  ..., -0.6387,  0.8117,  0.1086],
         [ 0.1575,  1.8034,  0.2499,  ..., -2.6593,  1.1191, -1.7751],
         [ 0.1489,  3.8491, -0.3972,  ..., -0.3574,  0.2971, -1.1159]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1575,  1.8034,  0.2499,  ..., -2.6593,  1.1191, -1.7751],
         [ 0.1489,  3.8491, -0.3972,  ..., -0.3574,  0.2971, -1.1159],
         [ 0.1294,  0.9284,  0.3755,  ..., -1.3888,  1.4257,  1.3626]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1489,  3.8491, -0.3972,  ..., -0.3574,  0.2971, -1.1159],
         [ 0.1294,  0.9284,  0.3755,  ..., -1.3888,  1.4257,  1.3626],
         [ 0.1232,  1.7575, -0.1830,  ..., -1.7177,  0.0690,  1.0115]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1294,  0.9284,  0.3755,  ..., -1.3888,  1.4257,  1.3626],
         [ 0.1232,  1.7575, -0.1830,  ..., -1.7177,  0.0690,  1.0115],
         [ 0.1084,  2.0569,  0.3092,  ..., -0.7195,  1.7114,  2.0466]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1232,  1.7575, -0.1830,  ..., -1.7177,  0.0690,  1.0115],
         [ 0.1084,  2.0569,  0.3092,  ..., -0.7195,  1.7114,  2.0466],
         [ 0.1115,  3.5068, -0.6663,  ..., -0.9275,  0.1480, -0.1990]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1084,  2.0569,  0.3092,  ..., -0.7195,  1.7114,  2.0466],
         [ 0.1115,  3.5068, -0.6663,  ..., -0.9275,  0.1480, -0.1990],
         [ 0.0495,  4.4627, -0.1650,  ..., -0.4363,  0.1394, -0.1806]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  8
logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1115,  3.5068, -0.6663,  ..., -0.9275,  0.1480, -0.1990],
         [ 0.0495,  4.4627, -0.1650,  ..., -0.4363,  0.1394, -0.1806],
         [ 0.1638, 11.4333, -0.1784,  ..., -1.0551,  1.7953, -1.0704]]],
       device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  8
Interior Secretary Ken Salazar pledges to keep 'boot on BP's neck' to help victims of oil spill . BP pledges $ 500m -LRB- # 346m -RRB- to study the spill . BP says it will be done to study the spill .
last_state =  tensor([ 0.1638, 11.4333, -0.1784,  ..., -1.0551,  1.7953, -1.0704],
       device='cuda:0')
final_logits =  tensor([[[ 0.1440,  2.4389,  0.6766,  ..., -2.7710,  2.5429, -0.1549],
         [ 0.0631,  2.5315,  0.3522,  ..., -0.5178, -0.3819, -0.9739],
         [ 0.1057,  2.9039,  0.0190,  ..., -1.3028, -0.3661, -1.8417],
         ...,
         [ 0.1115,  3.5068, -0.6663,  ..., -0.9275,  0.1480, -0.1990],
         [ 0.0495,  4.4627, -0.1650,  ..., -0.4363,  0.1394, -0.1806],
         [ 0.1638, 11.4333, -0.1784,  ..., -1.0551,  1.7953, -1.0704]]],
       device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-2.1766], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1424], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2940], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1417], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1179], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3279], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1167], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6616], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2789], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2688], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3858], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4029], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2561], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1878], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3719], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4434], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7870], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.0360], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8961], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4610], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9165], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1839], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1025], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2749], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9547], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1839], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2016], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3187], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5956], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2002], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0208], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5396], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1009], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7394], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0247], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0501], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2970], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1115], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0593], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5295], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5519], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2074], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9586], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5465], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5012], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1026], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7533], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5174], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4824], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4755], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.2971], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.9697], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.2962], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4245], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5321], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6778], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8091], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1035], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6948], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-2.1766, -0.1424, -0.2940, -0.1417, -1.1179, -0.3279, -0.1167, -1.6616,
        -0.2789, -0.2688, -0.3858, -0.4029, -0.2561, -0.1878, -0.3719, -1.4434,
        -0.7870, -2.0360, -0.8961, -1.4610, -0.9165, -0.1839, -0.1025, -1.2749,
        -0.9547, -0.1839, -0.2016, -0.3187, -0.5956, -0.2002, -0.0208, -0.5396,
        -0.1009, -0.7394, -0.0247, -0.0501, -0.2970, -0.1115, -0.0593, -0.5295,
        -0.5519, -0.2074, -0.9586, -0.5465, -0.5012, -0.1026, -1.7533, -1.5174,
        -0.4824, -0.4755, -1.2971, -2.9697, -2.2962, -0.4245, -0.5321, -0.6778,
        -0.8091, -0.1035, -1.6948], device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 2., 3.,
        3., 4., 5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,
        6., 6., 6., 6., 6., 7., 7., 7., 7., 7., 7., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8.], device='cuda:0')
log_probs size =  torch.Size([59])
values size =  torch.Size([59])
returns size =  torch.Size([59])
advantages =  tensor([-3.4536e-02, -3.4536e-02, -3.4536e-02, -3.4536e-02,  9.6546e-01,
         9.6546e-01,  9.6546e-01,  9.6546e-01,  9.6546e-01,  9.6546e-01,
         1.9655e+00,  9.6546e-01,  9.6546e-01,  9.6546e-01,  9.6546e-01,
         9.6546e-01,  1.9655e+00,  2.9655e+00,  2.9655e+00,  3.9655e+00,
         4.9655e+00,  4.9655e+00,  4.9655e+00,  5.9655e+00,  5.9655e+00,
         5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,
         5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,
         5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,  5.9655e+00,
         5.9655e+00,  6.9655e+00,  6.9655e+00,  6.9655e+00,  6.9655e+00,
         6.9655e+00,  6.9655e+00,  7.9655e+00,  7.9655e+00,  7.9655e+00,
        -1.5057e+02,  7.9655e+00,  7.9655e+00,  7.9655e+00,  7.9655e+00,
         7.9655e+00,  7.9655e+00,  7.9655e+00,  7.9655e+00], device='cuda:0')
actor_loss =  tensor(-0.0395, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(24425.2949, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704]]],
       device='cuda:0')
action =  tensor(2508, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551]]],
       device='cuda:0')
action =  tensor(56337, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207]]],
       device='cuda:0')
action =  tensor(50669, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         [ 0.0953,  3.6283, -0.1014,  ..., -3.0333, -0.7537,  0.8201]]],
       device='cuda:0')
action =  tensor(65353, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         [ 0.0953,  3.6283, -0.1014,  ..., -3.0333, -0.7537,  0.8201],
         [ 0.0783,  2.4769,  0.3998,  ..., -0.6425,  0.6389, -0.0810]]],
       device='cuda:0')
action =  tensor(316, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         [ 0.0953,  3.6283, -0.1014,  ..., -3.0333, -0.7537,  0.8201],
         [ 0.0783,  2.4769,  0.3998,  ..., -0.6425,  0.6389, -0.0810],
         [ 0.0977,  2.6527,  0.3521,  ..., -0.0040,  1.1973, -0.5128]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0783,  2.4769,  0.3998,  ..., -0.6425,  0.6389, -0.0810],
         [ 0.0977,  2.6527,  0.3521,  ..., -0.0040,  1.1973, -0.5128],
         [ 0.1037,  3.0504,  0.7098,  ...,  0.4866,  1.4451, -0.3528]]],
       device='cuda:0')
action =  tensor(5212, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0977,  2.6527,  0.3521,  ..., -0.0040,  1.1973, -0.5128],
         [ 0.1037,  3.0504,  0.7098,  ...,  0.4866,  1.4451, -0.3528],
         [ 0.0971,  2.8350,  0.0315,  ..., -2.8744,  0.7719,  0.6326]]],
       device='cuda:0')
action =  tensor(1986, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1037,  3.0504,  0.7098,  ...,  0.4866,  1.4451, -0.3528],
         [ 0.0971,  2.8350,  0.0315,  ..., -2.8744,  0.7719,  0.6326],
         [ 0.1208,  2.4153, -0.0929,  ..., -2.6149,  0.1536, -1.2145]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0971,  2.8350,  0.0315,  ..., -2.8744,  0.7719,  0.6326],
         [ 0.1208,  2.4153, -0.0929,  ..., -2.6149,  0.1536, -1.2145],
         [ 0.1072,  2.8739,  0.0104,  ..., -1.6273,  0.2810, -0.7435]]],
       device='cuda:0')
action =  tensor(2903, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1208,  2.4153, -0.0929,  ..., -2.6149,  0.1536, -1.2145],
         [ 0.1072,  2.8739,  0.0104,  ..., -1.6273,  0.2810, -0.7435],
         [ 0.0961,  4.1745,  0.3339,  ..., -2.5580,  0.8035, -0.6049]]],
       device='cuda:0')
action =  tensor(35178, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1072,  2.8739,  0.0104,  ..., -1.6273,  0.2810, -0.7435],
         [ 0.0961,  4.1745,  0.3339,  ..., -2.5580,  0.8035, -0.6049],
         [ 0.0345,  2.8612,  0.1108,  ...,  0.4477, -0.8422, -2.1222]]],
       device='cuda:0')
action =  tensor(252, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0961,  4.1745,  0.3339,  ..., -2.5580,  0.8035, -0.6049],
         [ 0.0345,  2.8612,  0.1108,  ...,  0.4477, -0.8422, -2.1222],
         [ 0.0906,  2.5806, -0.0221,  ..., -0.4145,  1.3982,  0.4430]]],
       device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0345,  2.8612,  0.1108,  ...,  0.4477, -0.8422, -2.1222],
         [ 0.0906,  2.5806, -0.0221,  ..., -0.4145,  1.3982,  0.4430],
         [ 0.0975,  2.9911,  0.0316,  ..., -2.7730, -0.9182,  1.5612]]],
       device='cuda:0')
action =  tensor(762, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0906,  2.5806, -0.0221,  ..., -0.4145,  1.3982,  0.4430],
         [ 0.0975,  2.9911,  0.0316,  ..., -2.7730, -0.9182,  1.5612],
         [ 0.1122,  2.5833, -0.4597,  ..., -2.1767,  0.1310, -2.0262]]],
       device='cuda:0')
action =  tensor(111, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0975,  2.9911,  0.0316,  ..., -2.7730, -0.9182,  1.5612],
         [ 0.1122,  2.5833, -0.4597,  ..., -2.1767,  0.1310, -2.0262],
         [ 0.1071,  1.8551,  0.1286,  ..., -2.9579,  0.3959, -2.0981]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1122,  2.5833, -0.4597,  ..., -2.1767,  0.1310, -2.0262],
         [ 0.1071,  1.8551,  0.1286,  ..., -2.9579,  0.3959, -2.0981],
         [ 0.0981,  2.2685,  0.2982,  ..., -2.1496, -0.2750, -2.6955]]],
       device='cuda:0')
action =  tensor(989, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1071,  1.8551,  0.1286,  ..., -2.9579,  0.3959, -2.0981],
         [ 0.0981,  2.2685,  0.2982,  ..., -2.1496, -0.2750, -2.6955],
         [ 0.1244,  3.7357,  0.0081,  ..., -2.0831, -0.0425, -1.4165]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0981,  2.2685,  0.2982,  ..., -2.1496, -0.2750, -2.6955],
         [ 0.1244,  3.7357,  0.0081,  ..., -2.0831, -0.0425, -1.4165],
         [ 0.0696,  5.2498,  0.4631,  ..., -0.3806,  0.0146, -1.2145]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  2
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.2442e-01,  3.7357e+00,  8.1181e-03,  ..., -2.0831e+00,
          -4.2502e-02, -1.4165e+00],
         [ 6.9634e-02,  5.2498e+00,  4.6308e-01,  ..., -3.8056e-01,
           1.4643e-02, -1.2145e+00],
         [ 1.4639e-01,  8.7410e+00,  3.7502e-01,  ..., -2.7487e+00,
           2.5787e+00, -8.6590e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0696,  5.2498,  0.4631,  ..., -0.3806,  0.0146, -1.2145],
         [ 0.1464,  8.7410,  0.3750,  ..., -2.7487,  2.5787, -0.8659],
         [ 0.1528,  2.8166,  0.0360,  ..., -1.0220, -0.7693, -1.0346]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1464,  8.7410,  0.3750,  ..., -2.7487,  2.5787, -0.8659],
         [ 0.1528,  2.8166,  0.0360,  ..., -1.0220, -0.7693, -1.0346],
         [ 0.1694,  1.5399,  0.2686,  ..., -1.4630,  3.4454, -1.6345]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1528,  2.8166,  0.0360,  ..., -1.0220, -0.7693, -1.0346],
         [ 0.1694,  1.5399,  0.2686,  ..., -1.4630,  3.4454, -1.6345],
         [ 0.1166,  3.6931,  0.5499,  ...,  0.3953, -0.8044, -2.4071]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1694,  1.5399,  0.2686,  ..., -1.4630,  3.4454, -1.6345],
         [ 0.1166,  3.6931,  0.5499,  ...,  0.3953, -0.8044, -2.4071],
         [ 0.0770,  3.5002,  0.1741,  ..., -0.0812, -1.1949, -0.5492]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1166,  3.6931,  0.5499,  ...,  0.3953, -0.8044, -2.4071],
         [ 0.0770,  3.5002,  0.1741,  ..., -0.0812, -1.1949, -0.5492],
         [ 0.1693,  1.4697, -0.1283,  ..., -0.8275,  0.8653, -1.5386]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0770,  3.5002,  0.1741,  ..., -0.0812, -1.1949, -0.5492],
         [ 0.1693,  1.4697, -0.1283,  ..., -0.8275,  0.8653, -1.5386],
         [ 0.0943,  2.9859,  0.4092,  ..., -1.5098,  1.5727, -2.5916]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1693,  1.4697, -0.1283,  ..., -0.8275,  0.8653, -1.5386],
         [ 0.0943,  2.9859,  0.4092,  ..., -1.5098,  1.5727, -2.5916],
         [ 0.0678,  2.5632,  0.5387,  ..., -1.1714, -1.0555, -0.6275]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 9.4320e-02,  2.9859e+00,  4.0921e-01,  ..., -1.5098e+00,
           1.5727e+00, -2.5916e+00],
         [ 6.7787e-02,  2.5632e+00,  5.3871e-01,  ..., -1.1714e+00,
          -1.0555e+00, -6.2746e-01],
         [ 1.2889e-01,  2.2356e+00,  2.7942e-03,  ..., -1.7750e-01,
           2.0628e+00, -8.7975e-01]]], device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 6.7787e-02,  2.5632e+00,  5.3871e-01,  ..., -1.1714e+00,
          -1.0555e+00, -6.2746e-01],
         [ 1.2889e-01,  2.2356e+00,  2.7942e-03,  ..., -1.7750e-01,
           2.0628e+00, -8.7975e-01],
         [ 1.1919e-01,  2.5083e+00,  7.5369e-01,  ..., -1.1905e-01,
           2.6517e+00, -1.8543e+00]]], device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.2889e-01,  2.2356e+00,  2.7942e-03,  ..., -1.7750e-01,
           2.0628e+00, -8.7975e-01],
         [ 1.1919e-01,  2.5083e+00,  7.5369e-01,  ..., -1.1905e-01,
           2.6517e+00, -1.8543e+00],
         [ 1.2078e-01,  3.0539e+00,  7.6793e-01,  ...,  5.5361e-01,
           1.0546e+00, -2.0174e+00]]], device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1192,  2.5083,  0.7537,  ..., -0.1191,  2.6517, -1.8543],
         [ 0.1208,  3.0539,  0.7679,  ...,  0.5536,  1.0546, -2.0174],
         [ 0.0716,  3.5336,  0.0874,  ..., -0.8698, -1.0512, -0.7574]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1208,  3.0539,  0.7679,  ...,  0.5536,  1.0546, -2.0174],
         [ 0.0716,  3.5336,  0.0874,  ..., -0.8698, -1.0512, -0.7574],
         [ 0.1521,  2.5239, -0.0850,  ...,  0.2743,  0.7552, -1.2217]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0716,  3.5336,  0.0874,  ..., -0.8698, -1.0512, -0.7574],
         [ 0.1521,  2.5239, -0.0850,  ...,  0.2743,  0.7552, -1.2217],
         [ 0.0996,  3.6473,  0.3094,  ..., -0.7114, -2.0396, -4.1346]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1521,  2.5239, -0.0850,  ...,  0.2743,  0.7552, -1.2217],
         [ 0.0996,  3.6473,  0.3094,  ..., -0.7114, -2.0396, -4.1346],
         [ 0.0936,  3.2232,  0.7869,  ..., -1.3459,  0.2833, -2.8474]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0996,  3.6473,  0.3094,  ..., -0.7114, -2.0396, -4.1346],
         [ 0.0936,  3.2232,  0.7869,  ..., -1.3459,  0.2833, -2.8474],
         [ 0.1376,  2.9156,  0.0200,  ..., -0.1005,  0.6294, -0.8685]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0936,  3.2232,  0.7869,  ..., -1.3459,  0.2833, -2.8474],
         [ 0.1376,  2.9156,  0.0200,  ..., -0.1005,  0.6294, -0.8685],
         [ 0.1870,  3.0326,  0.2406,  ...,  0.7680, -0.0771, -2.4462]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1376,  2.9156,  0.0200,  ..., -0.1005,  0.6294, -0.8685],
         [ 0.1870,  3.0326,  0.2406,  ...,  0.7680, -0.0771, -2.4462],
         [ 0.1398,  0.5351,  0.5134,  ...,  0.0383,  1.9602,  2.4458]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.8696e-01,  3.0326e+00,  2.4061e-01,  ...,  7.6797e-01,
          -7.7128e-02, -2.4462e+00],
         [ 1.3984e-01,  5.3511e-01,  5.1339e-01,  ...,  3.8285e-02,
           1.9602e+00,  2.4458e+00],
         [ 1.3937e-01,  1.2796e+00, -9.9941e-04,  ..., -1.3867e+00,
           6.5820e-01,  1.1545e+00]]], device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.3984e-01,  5.3511e-01,  5.1339e-01,  ...,  3.8285e-02,
           1.9602e+00,  2.4458e+00],
         [ 1.3937e-01,  1.2796e+00, -9.9941e-04,  ..., -1.3867e+00,
           6.5820e-01,  1.1545e+00],
         [ 1.2443e-01,  1.7095e+00,  3.5957e-01,  ..., -4.6065e-01,
           1.6909e+00,  1.7809e+00]]], device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.3937e-01,  1.2796e+00, -9.9941e-04,  ..., -1.3867e+00,
           6.5820e-01,  1.1545e+00],
         [ 1.2443e-01,  1.7095e+00,  3.5957e-01,  ..., -4.6065e-01,
           1.6909e+00,  1.7809e+00],
         [ 1.2231e-01,  1.9314e+00, -5.1872e-01,  ..., -4.7290e-01,
           2.2568e-01, -1.0903e-01]]], device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1244,  1.7095,  0.3596,  ..., -0.4607,  1.6909,  1.7809],
         [ 0.1223,  1.9314, -0.5187,  ..., -0.4729,  0.2257, -0.1090],
         [ 0.0545,  4.0980, -0.0854,  ..., -0.2029,  0.1049,  0.0176]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1223,  1.9314, -0.5187,  ..., -0.4729,  0.2257, -0.1090],
         [ 0.0545,  4.0980, -0.0854,  ..., -0.2029,  0.1049,  0.0176],
         [ 0.1842, 10.5321,  0.2048,  ..., -1.5107,  3.2934, -1.5170]]],
       device='cuda:0')
action =  tensor(5634, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 5.4457e-02,  4.0980e+00, -8.5378e-02,  ..., -2.0289e-01,
           1.0492e-01,  1.7553e-02],
         [ 1.8420e-01,  1.0532e+01,  2.0478e-01,  ..., -1.5107e+00,
           3.2934e+00, -1.5170e+00],
         [ 7.5100e-02,  2.7258e+00,  3.0043e-01,  ..., -3.6315e-01,
          -5.6210e-03, -1.2675e+00]]], device='cuda:0')
action =  tensor(4754, device='cuda:0')
reward =  5
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.8420e-01,  1.0532e+01,  2.0478e-01,  ..., -1.5107e+00,
           3.2934e+00, -1.5170e+00],
         [ 7.5100e-02,  2.7258e+00,  3.0043e-01,  ..., -3.6315e-01,
          -5.6210e-03, -1.2675e+00],
         [ 1.2604e-01,  3.7320e+00, -9.5881e-02,  ..., -1.0983e+00,
           2.0199e-01, -2.0527e+00]]], device='cuda:0')
action =  tensor(6755, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0751,  2.7258,  0.3004,  ..., -0.3631, -0.0056, -1.2675],
         [ 0.1260,  3.7320, -0.0959,  ..., -1.0983,  0.2020, -2.0527],
         [ 0.0629,  4.5555,  0.1419,  ...,  1.0454,  0.3517, -0.7997]]],
       device='cuda:0')
action =  tensor(50764, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1260,  3.7320, -0.0959,  ..., -1.0983,  0.2020, -2.0527],
         [ 0.0629,  4.5555,  0.1419,  ...,  1.0454,  0.3517, -0.7997],
         [ 0.1330,  4.4012,  0.0231,  ..., -1.2474, -1.5940, -0.9686]]],
       device='cuda:0')
action =  tensor(24075, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0629,  4.5555,  0.1419,  ...,  1.0454,  0.3517, -0.7997],
         [ 0.1330,  4.4012,  0.0231,  ..., -1.2474, -1.5940, -0.9686],
         [ 0.1514,  3.4414, -0.2165,  ..., -0.7988,  0.3314, -0.1237]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1330,  4.4012,  0.0231,  ..., -1.2474, -1.5940, -0.9686],
         [ 0.1514,  3.4414, -0.2165,  ..., -0.7988,  0.3314, -0.1237],
         [ 0.1286,  3.1022,  0.5334,  ..., -0.8158,  0.0609,  0.6501]]],
       device='cuda:0')
action =  tensor(376, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1514,  3.4414, -0.2165,  ..., -0.7988,  0.3314, -0.1237],
         [ 0.1286,  3.1022,  0.5334,  ..., -0.8158,  0.0609,  0.6501],
         [ 0.1431, -0.2312,  0.0412,  ..., -1.8827,  1.2944, -2.1462]]],
       device='cuda:0')
action =  tensor(150, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1286,  3.1022,  0.5334,  ..., -0.8158,  0.0609,  0.6501],
         [ 0.1431, -0.2312,  0.0412,  ..., -1.8827,  1.2944, -2.1462],
         [ 0.0913,  3.0625,  0.3501,  ..., -0.8989, -0.8750, -1.5999]]],
       device='cuda:0')
action =  tensor(5407, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1431, -0.2312,  0.0412,  ..., -1.8827,  1.2944, -2.1462],
         [ 0.0913,  3.0625,  0.3501,  ..., -0.8989, -0.8750, -1.5999],
         [ 0.1199,  2.7449, -0.2048,  ..., -2.1091,  0.0906, -1.4156]]],
       device='cuda:0')
action =  tensor(124, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0913,  3.0625,  0.3501,  ..., -0.8989, -0.8750, -1.5999],
         [ 0.1199,  2.7449, -0.2048,  ..., -2.1091,  0.0906, -1.4156],
         [ 0.1478,  0.7768, -0.0460,  ..., -2.5670,  1.4911, -0.8164]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1199,  2.7449, -0.2048,  ..., -2.1091,  0.0906, -1.4156],
         [ 0.1478,  0.7768, -0.0460,  ..., -2.5670,  1.4911, -0.8164],
         [ 0.1337,  4.6063, -0.1405,  ...,  0.1545, -1.8555, -2.2163]]],
       device='cuda:0')
action =  tensor(1034, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1478,  0.7768, -0.0460,  ..., -2.5670,  1.4911, -0.8164],
         [ 0.1337,  4.6063, -0.1405,  ...,  0.1545, -1.8555, -2.2163],
         [ 0.0509,  1.3683,  1.7998,  ...,  4.6249,  1.5331, -0.1122]]],
       device='cuda:0')
action =  tensor(386, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1337,  4.6063, -0.1405,  ...,  0.1545, -1.8555, -2.2163],
         [ 0.0509,  1.3683,  1.7998,  ...,  4.6249,  1.5331, -0.1122],
         [ 0.0670,  0.9589,  0.4678,  ...,  0.9230, -3.1332,  2.6906]]],
       device='cuda:0')
action =  tensor(2076, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0509,  1.3683,  1.7998,  ...,  4.6249,  1.5331, -0.1122],
         [ 0.0670,  0.9589,  0.4678,  ...,  0.9230, -3.1332,  2.6906],
         [ 0.0911,  3.4050, -0.2300,  ..., -2.0698,  0.2665,  0.9375]]],
       device='cuda:0')
action =  tensor(230, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0670,  0.9589,  0.4678,  ...,  0.9230, -3.1332,  2.6906],
         [ 0.0911,  3.4050, -0.2300,  ..., -2.0698,  0.2665,  0.9375],
         [ 0.1385,  3.4328, -0.0549,  ...,  0.4486,  0.6213, -3.0162]]],
       device='cuda:0')
action =  tensor(117, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.0911,  3.4050, -0.2300,  ..., -2.0698,  0.2665,  0.9375],
         [ 0.1385,  3.4328, -0.0549,  ...,  0.4486,  0.6213, -3.0162],
         [ 0.1288,  4.4408,  0.0886,  ...,  0.7909, -0.4762, -1.5545]]],
       device='cuda:0')
action =  tensor(993, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1385,  3.4328, -0.0549,  ...,  0.4486,  0.6213, -3.0162],
         [ 0.1288,  4.4408,  0.0886,  ...,  0.7909, -0.4762, -1.5545],
         [ 0.1121,  5.2320, -0.2916,  ..., -0.5791,  0.4096, -2.6342]]],
       device='cuda:0')
action =  tensor(131, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1288,  4.4408,  0.0886,  ...,  0.7909, -0.4762, -1.5545],
         [ 0.1121,  5.2320, -0.2916,  ..., -0.5791,  0.4096, -2.6342],
         [ 0.1702,  8.9001, -0.4271,  ..., -1.0006,  0.3914, -2.1801]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1121,  5.2320, -0.2916,  ..., -0.5791,  0.4096, -2.6342],
         [ 0.1702,  8.9001, -0.4271,  ..., -1.0006,  0.3914, -2.1801],
         [ 0.1416,  3.4772, -0.3999,  ..., -0.1685,  0.0853, -1.5936]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1604,  2.4095,  0.6946,  ..., -2.7472,  2.5198, -0.1704],
         [ 0.0956,  2.9759,  0.5431,  ..., -1.5900,  0.6936, -0.2551],
         [ 0.0842,  1.0896,  0.3915,  ..., -2.2143,  0.2828, -1.0207],
         ...,
         [ 0.1702,  8.9001, -0.4271,  ..., -1.0006,  0.3914, -2.1801],
         [ 0.1416,  3.4772, -0.3999,  ..., -0.1685,  0.0853, -1.5936],
         [ 0.0641,  4.9972, -0.0917,  ..., -0.8266,  0.1404, -0.4447]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  6
logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.4158e-01,  3.4772e+00, -3.9986e-01,  ..., -1.6854e-01,
           8.5298e-02, -1.5936e+00],
         [ 6.4110e-02,  4.9972e+00, -9.1658e-02,  ..., -8.2664e-01,
           1.4036e-01, -4.4467e-01],
         [ 1.7141e-01,  1.1833e+01, -6.5204e-03,  ..., -1.2219e+00,
           2.0441e+00, -1.0656e+00]]], device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  6
Two Greenpeace campaigners unfurled a flag showing BP logo smudged in oil and the words . BP pledges $ 500m -LRB- #346m -RRB- to study the spill . Interior Secretary Ken Salazar vows to keep our boot on BP 'in whatever way is necessary' spill .
last_state =  tensor([ 1.7141e-01,  1.1833e+01, -6.5204e-03,  ..., -1.2219e+00,
         2.0441e+00, -1.0656e+00], device='cuda:0')
final_logits =  tensor([[[ 1.6036e-01,  2.4095e+00,  6.9464e-01,  ..., -2.7472e+00,
           2.5198e+00, -1.7039e-01],
         [ 9.5581e-02,  2.9759e+00,  5.4314e-01,  ..., -1.5900e+00,
           6.9359e-01, -2.5509e-01],
         [ 8.4239e-02,  1.0896e+00,  3.9148e-01,  ..., -2.2143e+00,
           2.8281e-01, -1.0207e+00],
         ...,
         [ 1.4158e-01,  3.4772e+00, -3.9986e-01,  ..., -1.6854e-01,
           8.5298e-02, -1.5936e+00],
         [ 6.4110e-02,  4.9972e+00, -9.1658e-02,  ..., -8.2664e-01,
           1.4036e-01, -4.4467e-01],
         [ 1.7141e-01,  1.1833e+01, -6.5204e-03,  ..., -1.2219e+00,
           2.0441e+00, -1.0656e+00]]], device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-2.2063], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0555], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6110], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5993], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3312], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3422], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1886], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9278], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6623], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3457], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6447], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0734], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1283], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0818], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9343], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1560], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1407], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8963], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1609], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5623], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4844], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1754], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2118], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2935], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4950], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2022], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0185], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4926], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0898], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8043], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0379], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2524], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0819], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0690], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3846], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6351], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1597], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6014], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6375], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8868], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0968], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.1087], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1064], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2802], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1719], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.4774], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2742], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1437], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5617], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1551], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0903], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3379], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.7456], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.8643], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2190], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4105], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9563], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0440], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4958], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.8336], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6272], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1070], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.7896], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-2.2063, -0.0555, -0.6110, -0.5993, -0.3312, -0.3422, -0.1886, -0.9278,
        -0.6623, -0.3457, -0.6447, -0.0734, -0.1283, -0.0818, -0.9343, -0.1560,
        -0.1407, -0.8963, -0.1609, -1.5623, -0.4844, -0.1754, -0.2118, -0.2935,
        -0.4950, -0.2022, -0.0185, -0.4926, -0.0898, -0.8043, -0.0379, -0.2524,
        -0.0819, -0.0690, -0.3846, -0.6351, -0.1597, -0.6014, -0.6375, -0.8868,
        -0.0968, -1.1087, -0.1064, -0.2802, -0.1719, -1.4774, -0.2742, -0.1437,
        -1.5617, -0.1551, -0.0903, -0.3379, -0.7456, -1.8643, -0.2190, -0.4105,
        -0.9563, -0.0440, -0.4958, -1.8336, -0.6272, -0.1070, -1.7896],
       device='cuda:0', grad_fn=<CatBackward>)
rewards =  tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,
        2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        4., 4., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,
        5., 6., 6., 6., 6., 6., 6., 6., 6.], device='cuda:0')
log_probs size =  torch.Size([63])
values size =  torch.Size([63])
returns size =  torch.Size([63])
advantages =  tensor([-3.4258e-02, -3.4258e-02, -3.4258e-02, -3.4258e-02, -3.4258e-02,
        -3.4258e-02, -3.4258e-02, -3.4258e-02,  9.6574e-01, -8.3544e+01,
         9.6574e-01,  9.6574e-01,  9.6574e-01,  1.9657e+00,  1.9657e+00,
         1.9657e+00,  1.9657e+00,  1.9657e+00,  1.9657e+00,  1.9657e+00,
         2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,
         2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,
         2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,  2.9657e+00,
         2.9657e+00,  3.9657e+00,  3.9657e+00,  4.9657e+00,  4.9657e+00,
         4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,
         4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,
         4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,  4.9657e+00,
         5.9657e+00,  5.9657e+00,  5.9657e+00,  5.9657e+00,  5.9657e+00,
         5.9657e+00,  5.9657e+00,  5.9657e+00], device='cuda:0')
actor_loss =  tensor(1.3489, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(7886.5059, device='cuda:0', grad_fn=<MseLossBackward>)
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840]]],
       device='cuda:0')
action =  tensor(2508, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368]]],
       device='cuda:0')
action =  tensor(56337, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296]]],
       device='cuda:0')
action =  tensor(50669, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         [ 0.1053,  3.6004, -0.0875,  ..., -3.0352, -0.8407,  0.7903]]],
       device='cuda:0')
action =  tensor(65353, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         [ 0.1053,  3.6003, -0.0875,  ..., -3.0352, -0.8407,  0.7903],
         [ 0.0870,  2.5316,  0.4190,  ..., -0.5272,  0.7381, -0.0691]]],
       device='cuda:0')
action =  tensor(316, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         [ 0.1053,  3.6003, -0.0875,  ..., -3.0352, -0.8407,  0.7903],
         [ 0.0870,  2.5316,  0.4191,  ..., -0.5272,  0.7381, -0.0691],
         [ 0.1074,  2.6673,  0.3671,  ...,  0.0296,  1.1903, -0.5583]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0870,  2.5316,  0.4191,  ..., -0.5272,  0.7381, -0.0691],
         [ 0.1074,  2.6673,  0.3671,  ...,  0.0296,  1.1903, -0.5583],
         [ 0.1146,  3.0292,  0.7296,  ...,  0.4810,  1.4773, -0.3618]]],
       device='cuda:0')
action =  tensor(5212, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1074,  2.6673,  0.3671,  ...,  0.0296,  1.1903, -0.5583],
         [ 0.1146,  3.0292,  0.7296,  ...,  0.4810,  1.4773, -0.3618],
         [ 0.1075,  2.8405,  0.0371,  ..., -2.8185,  0.7008,  0.6195]]],
       device='cuda:0')
action =  tensor(1986, device='cuda:0')
reward =  0
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1146,  3.0292,  0.7296,  ...,  0.4810,  1.4773, -0.3618],
         [ 0.1075,  2.8405,  0.0371,  ..., -2.8185,  0.7008,  0.6195],
         [ 0.1330,  2.4125, -0.0676,  ..., -2.5675,  0.2033, -1.2020]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1075,  2.8405,  0.0371,  ..., -2.8185,  0.7008,  0.6195],
         [ 0.1330,  2.4125, -0.0676,  ..., -2.5675,  0.2033, -1.2020],
         [ 0.1178,  2.9026,  0.0115,  ..., -1.5795,  0.2818, -0.7496]]],
       device='cuda:0')
action =  tensor(2903, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1330,  2.4125, -0.0676,  ..., -2.5675,  0.2033, -1.2020],
         [ 0.1178,  2.9026,  0.0115,  ..., -1.5795,  0.2818, -0.7496],
         [ 0.1064,  4.2038,  0.3403,  ..., -2.5253,  0.7856, -0.5916]]],
       device='cuda:0')
action =  tensor(35178, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1178,  2.9026,  0.0115,  ..., -1.5795,  0.2818, -0.7496],
         [ 0.1064,  4.2038,  0.3403,  ..., -2.5253,  0.7856, -0.5916],
         [ 0.0375,  2.9004,  0.1167,  ...,  0.4724, -0.8916, -2.1144]]],
       device='cuda:0')
action =  tensor(252, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1064,  4.2038,  0.3403,  ..., -2.5253,  0.7856, -0.5916],
         [ 0.0375,  2.9004,  0.1167,  ...,  0.4724, -0.8916, -2.1144],
         [ 0.1004,  2.6057, -0.0129,  ..., -0.3746,  1.4074,  0.4221]]],
       device='cuda:0')
action =  tensor(115, device='cuda:0')
reward =  1
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0375,  2.9004,  0.1167,  ...,  0.4724, -0.8916, -2.1144],
         [ 0.1004,  2.6057, -0.0129,  ..., -0.3746,  1.4074,  0.4221],
         [ 0.1077,  3.0050,  0.0397,  ..., -2.7175, -0.8787,  1.5705]]],
       device='cuda:0')
action =  tensor(762, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1004,  2.6057, -0.0129,  ..., -0.3746,  1.4074,  0.4221],
         [ 0.1077,  3.0050,  0.0397,  ..., -2.7175, -0.8787,  1.5705],
         [ 0.1244,  2.6414, -0.4451,  ..., -2.2085,  0.1635, -2.0393]]],
       device='cuda:0')
action =  tensor(111, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1077,  3.0050,  0.0397,  ..., -2.7175, -0.8787,  1.5705],
         [ 0.1244,  2.6414, -0.4451,  ..., -2.2085,  0.1635, -2.0393],
         [ 0.1190,  1.9207,  0.1426,  ..., -2.9914,  0.4430, -2.2327]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1244,  2.6414, -0.4451,  ..., -2.2085,  0.1635, -2.0393],
         [ 0.1190,  1.9207,  0.1426,  ..., -2.9914,  0.4430, -2.2327],
         [ 0.1074,  2.2722,  0.3136,  ..., -2.1266, -0.2596, -2.6758]]],
       device='cuda:0')
action =  tensor(989, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1190,  1.9207,  0.1426,  ..., -2.9914,  0.4430, -2.2327],
         [ 0.1074,  2.2722,  0.3136,  ..., -2.1266, -0.2596, -2.6758],
         [ 0.1368,  3.8326,  0.0220,  ..., -2.0489, -0.0050, -1.3987]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  2
logits =  tensor([[[ 1.7426e-01,  2.3939e+00,  7.0914e-01,  ..., -2.7250e+00,
           2.4976e+00, -1.8404e-01],
         [ 1.0537e-01,  3.0164e+00,  5.5756e-01,  ..., -1.6107e+00,
           6.8961e-01, -2.3680e-01],
         [ 9.2635e-02,  1.0857e+00,  3.9996e-01,  ..., -2.2071e+00,
           2.7688e-01, -1.0296e+00],
         ...,
         [ 1.0744e-01,  2.2722e+00,  3.1360e-01,  ..., -2.1266e+00,
          -2.5960e-01, -2.6758e+00],
         [ 1.3676e-01,  3.8326e+00,  2.1992e-02,  ..., -2.0489e+00,
          -4.9750e-03, -1.3987e+00],
         [ 7.5222e-02,  5.2633e+00,  4.4908e-01,  ..., -3.6859e-01,
           1.1842e-02, -1.1987e+00]]], device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  2
logits =  tensor([[[ 1.7426e-01,  2.3939e+00,  7.0914e-01,  ..., -2.7250e+00,
           2.4976e+00, -1.8404e-01],
         [ 1.0537e-01,  3.0164e+00,  5.5756e-01,  ..., -1.6107e+00,
           6.8961e-01, -2.3680e-01],
         [ 9.2635e-02,  1.0857e+00,  3.9996e-01,  ..., -2.2071e+00,
           2.7688e-01, -1.0296e+00],
         ...,
         [ 1.3676e-01,  3.8326e+00,  2.1992e-02,  ..., -2.0489e+00,
          -4.9750e-03, -1.3987e+00],
         [ 7.5222e-02,  5.2633e+00,  4.4908e-01,  ..., -3.6859e-01,
           1.1842e-02, -1.1987e+00],
         [ 1.6145e-01,  8.8956e+00,  3.7376e-01,  ..., -2.6341e+00,
           2.5778e+00, -8.8550e-01]]], device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  2
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0752,  5.2633,  0.4491,  ..., -0.3686,  0.0118, -1.1987],
         [ 0.1615,  8.8956,  0.3738,  ..., -2.6341,  2.5778, -0.8855],
         [ 0.1676,  2.8943,  0.0351,  ..., -1.0660, -0.7304, -1.0837]]],
       device='cuda:0')
action =  tensor(35505, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1615,  8.8956,  0.3738,  ..., -2.6341,  2.5778, -0.8855],
         [ 0.1676,  2.8943,  0.0351,  ..., -1.0660, -0.7304, -1.0837],
         [ 0.1856,  1.6241,  0.2757,  ..., -1.4170,  3.4665, -1.6054]]],
       device='cuda:0')
action =  tensor(3662, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1676,  2.8943,  0.0351,  ..., -1.0660, -0.7304, -1.0837],
         [ 0.1856,  1.6241,  0.2757,  ..., -1.4170,  3.4665, -1.6054],
         [ 0.1269,  3.7660,  0.5669,  ...,  0.4105, -0.7705, -2.3995]]],
       device='cuda:0')
action =  tensor(2527, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1856,  1.6241,  0.2757,  ..., -1.4170,  3.4665, -1.6054],
         [ 0.1269,  3.7660,  0.5669,  ...,  0.4105, -0.7705, -2.3995],
         [ 0.0840,  3.5453,  0.1771,  ..., -0.0677, -1.1984, -0.5568]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1269,  3.7660,  0.5669,  ...,  0.4105, -0.7705, -2.3995],
         [ 0.0840,  3.5453,  0.1771,  ..., -0.0677, -1.1984, -0.5568],
         [ 0.1850,  1.5598, -0.1121,  ..., -0.8210,  0.8640, -1.5501]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0840,  3.5453,  0.1771,  ..., -0.0677, -1.1984, -0.5568],
         [ 0.1850,  1.5598, -0.1121,  ..., -0.8210,  0.8640, -1.5501],
         [ 0.1035,  3.0495,  0.4141,  ..., -1.4633,  1.5872, -2.6015]]],
       device='cuda:0')
action =  tensor(20447, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1850,  1.5598, -0.1121,  ..., -0.8210,  0.8640, -1.5501],
         [ 0.1035,  3.0495,  0.4141,  ..., -1.4633,  1.5872, -2.6015],
         [ 0.0739,  2.6160,  0.5415,  ..., -1.1765, -1.0441, -0.6593]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1035,  3.0495,  0.4141,  ..., -1.4633,  1.5872, -2.6015],
         [ 0.0739,  2.6160,  0.5415,  ..., -1.1765, -1.0441, -0.6593],
         [ 0.1409,  2.3120,  0.0044,  ..., -0.1775,  2.0634, -0.8979]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0739,  2.6160,  0.5415,  ..., -1.1765, -1.0441, -0.6593],
         [ 0.1409,  2.3120,  0.0044,  ..., -0.1775,  2.0634, -0.8979],
         [ 0.1298,  2.6366,  0.7689,  ..., -0.0549,  2.6370, -1.8528]]],
       device='cuda:0')
action =  tensor(1768, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1409,  2.3120,  0.0044,  ..., -0.1775,  2.0634, -0.8979],
         [ 0.1298,  2.6366,  0.7689,  ..., -0.0549,  2.6370, -1.8528],
         [ 0.1323,  3.1038,  0.7756,  ...,  0.6054,  1.1154, -2.0141]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1298,  2.6366,  0.7689,  ..., -0.0549,  2.6370, -1.8528],
         [ 0.1323,  3.1038,  0.7756,  ...,  0.6054,  1.1154, -2.0141],
         [ 0.0882,  4.2989,  0.8499,  ..., -0.5258,  0.6303, -1.1796]]],
       device='cuda:0')
action =  tensor(37440, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1323,  3.1038,  0.7756,  ...,  0.6054,  1.1154, -2.0141],
         [ 0.0882,  4.2989,  0.8499,  ..., -0.5258,  0.6303, -1.1796],
         [ 0.0789,  3.7631,  0.1044,  ..., -0.9107, -0.9692, -0.7101]]],
       device='cuda:0')
action =  tensor(208, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0882,  4.2989,  0.8499,  ..., -0.5258,  0.6303, -1.1796],
         [ 0.0789,  3.7631,  0.1044,  ..., -0.9107, -0.9692, -0.7101],
         [ 0.1695,  2.7634, -0.1094,  ...,  0.1997,  0.7539, -1.3790]]],
       device='cuda:0')
action =  tensor(233, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0789,  3.7631,  0.1044,  ..., -0.9107, -0.9692, -0.7101],
         [ 0.1695,  2.7634, -0.1094,  ...,  0.1997,  0.7539, -1.3790],
         [ 0.1084,  3.7891,  0.3651,  ..., -0.5349, -1.7712, -3.9136]]],
       device='cuda:0')
action =  tensor(16567, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1695,  2.7634, -0.1094,  ...,  0.1997,  0.7539, -1.3790],
         [ 0.1084,  3.7891,  0.3651,  ..., -0.5349, -1.7712, -3.9136],
         [ 0.1092,  3.4685,  0.8476,  ..., -1.0078,  0.5364, -2.8988]]],
       device='cuda:0')
action =  tensor(788, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1084,  3.7891,  0.3651,  ..., -0.5349, -1.7712, -3.9136],
         [ 0.1092,  3.4685,  0.8476,  ..., -1.0078,  0.5364, -2.8988],
         [ 0.1502,  3.2022,  0.0252,  ..., -0.0909,  0.7795, -0.8504]]],
       device='cuda:0')
action =  tensor(121, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1092,  3.4685,  0.8476,  ..., -1.0078,  0.5364, -2.8988],
         [ 0.1502,  3.2022,  0.0252,  ..., -0.0909,  0.7795, -0.8504],
         [ 0.2000,  3.1632,  0.4044,  ...,  0.7475,  0.1327, -2.8464]]],
       device='cuda:0')
action =  tensor(112, device='cuda:0')
reward =  3
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1502,  3.2022,  0.0252,  ..., -0.0909,  0.7795, -0.8504],
         [ 0.2000,  3.1632,  0.4044,  ...,  0.7475,  0.1327, -2.8464],
         [ 0.1564,  0.7083,  0.5038,  ...,  0.0886,  2.0080,  2.4113]]],
       device='cuda:0')
action =  tensor(692, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.2000,  3.1632,  0.4044,  ...,  0.7475,  0.1327, -2.8464],
         [ 0.1564,  0.7083,  0.5038,  ...,  0.0886,  2.0080,  2.4113],
         [ 0.1531,  1.4058,  0.0125,  ..., -1.3735,  0.6882,  1.2053]]],
       device='cuda:0')
action =  tensor(109, device='cuda:0')
reward =  4
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1564,  0.7083,  0.5038,  ...,  0.0886,  2.0080,  2.4113],
         [ 0.1531,  1.4058,  0.0125,  ..., -1.3735,  0.6882,  1.2053],
         [ 0.1371,  1.7545,  0.3788,  ..., -0.4025,  1.7039,  1.7763]]],
       device='cuda:0')
action =  tensor(14567, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1531,  1.4058,  0.0125,  ..., -1.3735,  0.6882,  1.2053],
         [ 0.1371,  1.7545,  0.3788,  ..., -0.4025,  1.7039,  1.7763],
         [ 0.1339,  1.9980, -0.5037,  ..., -0.4050,  0.1958, -0.1234]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1371,  1.7545,  0.3788,  ..., -0.4025,  1.7039,  1.7763],
         [ 0.1339,  1.9980, -0.5037,  ..., -0.4050,  0.1958, -0.1234],
         [ 0.0600,  4.0287, -0.0449,  ..., -0.1526,  0.2049, -0.0468]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1339,  1.9980, -0.5037,  ..., -0.4050,  0.1958, -0.1234],
         [ 0.0600,  4.0287, -0.0449,  ..., -0.1526,  0.2049, -0.0468],
         [ 0.1899, 10.4764,  0.1290,  ..., -1.2631,  2.7059, -2.5921]]],
       device='cuda:0')
action =  tensor(16036, device='cuda:0')
reward =  5
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.0600,  4.0287, -0.0449,  ..., -0.1526,  0.2049, -0.0468],
         [ 0.1899, 10.4764,  0.1290,  ..., -1.2631,  2.7059, -2.5921],
         [ 0.1844,  4.5468, -0.1481,  ..., -0.1534, -0.6444, -1.3256]]],
       device='cuda:0')
action =  tensor(649, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1899, 10.4764,  0.1290,  ..., -1.2631,  2.7059, -2.5921],
         [ 0.1844,  4.5468, -0.1481,  ..., -0.1534, -0.6444, -1.3256],
         [ 0.2052,  1.5957, -0.3688,  ..., -1.8479,  1.9549,  0.1804]]],
       device='cuda:0')
action =  tensor(126, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1844,  4.5468, -0.1481,  ..., -0.1534, -0.6444, -1.3256],
         [ 0.2052,  1.5957, -0.3688,  ..., -1.8479,  1.9549,  0.1804],
         [ 0.1299,  3.1697, -0.1307,  ...,  0.6427,  1.0337,  0.3301]]],
       device='cuda:0')
action =  tensor(138, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.2052,  1.5957, -0.3688,  ..., -1.8479,  1.9549,  0.1804],
         [ 0.1299,  3.1697, -0.1307,  ...,  0.6427,  1.0337,  0.3301],
         [ 0.1818,  1.2227,  0.2763,  ..., -0.4653,  1.2126,  0.2470]]],
       device='cuda:0')
action =  tensor(508, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1299,  3.1697, -0.1307,  ...,  0.6427,  1.0337,  0.3301],
         [ 0.1818,  1.2227,  0.2763,  ..., -0.4653,  1.2126,  0.2470],
         [ 0.2036,  2.3891, -0.0465,  ...,  0.5811,  0.4054, -1.2007]]],
       device='cuda:0')
action =  tensor(114, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1818,  1.2227,  0.2763,  ..., -0.4653,  1.2126,  0.2470],
         [ 0.2036,  2.3891, -0.0465,  ...,  0.5811,  0.4054, -1.2007],
         [ 0.2008,  1.5550,  0.5049,  ..., -0.3898,  1.8381,  0.2133]]],
       device='cuda:0')
action =  tensor(349, device='cuda:0')
reward =  6
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.2036,  2.3891, -0.0465,  ...,  0.5811,  0.4054, -1.2007],
         [ 0.2008,  1.5550,  0.5049,  ..., -0.3898,  1.8381,  0.2133],
         [ 0.1150,  3.8071,  0.4790,  ..., -1.1949,  0.5306, -0.0073]]],
       device='cuda:0')
action =  tensor(4017, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.2008,  1.5550,  0.5049,  ..., -0.3898,  1.8381,  0.2133],
         [ 0.1150,  3.8071,  0.4790,  ..., -1.1949,  0.5306, -0.0073],
         [ 0.1855,  3.0298, -0.1518,  ..., -0.1555,  2.8113, -1.7446]]],
       device='cuda:0')
action =  tensor(110, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1150,  3.8071,  0.4790,  ..., -1.1949,  0.5306, -0.0073],
         [ 0.1855,  3.0298, -0.1518,  ..., -0.1555,  2.8113, -1.7446],
         [ 0.0652,  4.4526, -0.0837,  ..., -0.4890,  0.2239, -0.2973]]],
       device='cuda:0')
action =  tensor(107, device='cuda:0')
reward =  7
logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1855,  3.0298, -0.1518,  ..., -0.1555,  2.8113, -1.7446],
         [ 0.0652,  4.4526, -0.0837,  ..., -0.4890,  0.2239, -0.2973],
         [ 0.2017, 11.1215, -0.2666,  ..., -1.0614,  2.7723, -1.3759]]],
       device='cuda:0')
action =  tensor(1, device='cuda:0')
reward =  7
Two Greenpeace campaigners unfurled a flag showing BP logo smudged in oil and the words . BP pledges $ 500m -LRB- # 346m -RRB- to study the spill . BP says it will try a top kill .
last_state =  tensor([ 0.2017, 11.1215, -0.2666,  ..., -1.0614,  2.7723, -1.3759],
       device='cuda:0')
final_logits =  tensor([[[ 0.1743,  2.3939,  0.7091,  ..., -2.7250,  2.4976, -0.1840],
         [ 0.1054,  3.0164,  0.5576,  ..., -1.6107,  0.6896, -0.2368],
         [ 0.0926,  1.0857,  0.4000,  ..., -2.2071,  0.2769, -1.0296],
         ...,
         [ 0.1855,  3.0298, -0.1518,  ..., -0.1555,  2.8113, -1.7446],
         [ 0.0652,  4.4526, -0.0837,  ..., -0.4890,  0.2239, -0.2973],
         [ 0.2017, 11.1215, -0.2666,  ..., -1.0614,  2.7723, -1.3759]]],
       device='cuda:0', grad_fn=<AddBackward0>)
distribution =  [Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103])), Categorical(probs: torch.Size([96103]), logits: torch.Size([96103]))]
log_probs before cat =  [tensor([-2.1883], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0583], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6676], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6490], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3449], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3746], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1939], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9767], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6610], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3383], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6798], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0705], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1341], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0804], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9284], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1653], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1462], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9514], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1548], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.5289], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.5037], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1853], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2216], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2988], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4959], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2155], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0194], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4859], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0980], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8412], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0255], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0438], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.2728], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0878], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1398], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4364], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.9354], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1556], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6423], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.6328], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8957], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.0983], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.1369], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6079], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.3728], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4152], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.3603], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.8235], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.6711], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.4844], device='cuda:0', grad_fn=<SelectBackward>), tensor([-1.8072], device='cuda:0', grad_fn=<SelectBackward>), tensor([-0.1076], device='cuda:0', grad_fn=<SelectBackward>), tensor([-2.1478], device='cuda:0', grad_fn=<SelectBackward>)]
log_probs =  tensor([-2.1883, -0.0583, -0.6676, -0.6490, -0.3449, -0.3746, -0.1939, -0.9767,
        -0.6610, -0.3383, -0.6798, -0.0705, -0.1341, -0.0804, -0.9284, -0.1653,
        -0.1462, -0.9514, -0.1548, -1.5289, -0.5037, -0.1853, -0.2216, -0.2988,
        -0.4959, -0.2155, -0.0194, -0.4859, -0.0980, -0.8412, -0.0255, -0.0438,
        -0.2728, -0.0878, -0.1398, -0.4364, -0.9354, -0.1556, -0.6423, -0.6328,
        -0.8957, -0.0983, -2.1369, -1.6079, -0.3728, -0.4152, -1.3603, -0.8235,
        -1.6711, -0.4844, -1.8072, -0.1076, -2.1478], device='cuda:0',
       grad_fn=<CatBackward>)
rewards =  tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,
        2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,
        3., 4., 4., 5., 5., 5., 5., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7.],
       device='cuda:0')
log_probs size =  torch.Size([53])
values size =  torch.Size([53])
returns size =  torch.Size([53])
advantages =  tensor([-0.0340, -0.0340, -0.0340, -0.0340, -0.0340, -0.0340, -0.0340, -0.0340,
         0.9660,  0.9660,  0.9660,  0.9660,  0.9660,  1.9660,  1.9660,  1.9660,
         1.9660,  1.9660,  1.9660,  1.9660,  2.9660,  2.9660,  2.9660,  2.9660,
         2.9660,  2.9660,  2.9660,  2.9660,  2.9660,  2.9660,  2.9660,  2.9660,
         2.9660,  2.9660,  2.9660,  2.9660,  2.9660,  3.9660,  3.9660,  4.9660,
         4.9660,  4.9660,  4.9660,  5.9660,  5.9660,  5.9660,  5.9660,  5.9660,
         5.9660,  6.9660,  6.9660,  6.9660,  6.9660], device='cuda:0')
actor_loss =  tensor(2.1881, device='cuda:0', grad_fn=<MeanBackward0>)
critic_loss =  tensor(719.0410, device='cuda:0', grad_fn=<MseLossBackward>)
final reward =  7
